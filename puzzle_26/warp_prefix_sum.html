<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>üî¢ warp.prefix_sum() Scan Operations - Mojo üî• GPU Puzzles</title>


        <!-- Custom HTML head -->
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,100..700;1,100..700&display=swap"
            rel="stylesheet">
        
        <script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
        
        <link rel="stylesheet" href="../theme/css/custom.css">
        <link rel="stylesheet" href="../theme/css/highlight.css">
        <link rel="stylesheet" id="theme">
        
        <!-- Additional meta tags -->
        <meta property="og:title" content="Mojoüî• GPU Puzzles">
        <meta property="og:description" content="Learn GPU Programming in Mojoüî• Through Interactive Puzzles">
        <meta property="og:image" content="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">
        <meta property="og:url" content="https://puzzles.modular.com/">
        <meta name="twitter:card" content="summary">
        <meta name="twitter:image:alt" content="Mojo GPU Puzzles Logo">
        <meta name="twitter:title" content="Mojoüî• GPU Puzzles">
        <meta name="twitter:description" content="Learn GPU Programming in Mojoüî• Through Interactive Puzzles">
        <meta name="twitter:image" content="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">
        <link rel="icon" type="image/png" href="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&display=swap" rel="stylesheet">

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../theme/css/custom.css">
        <link rel="stylesheet" href="../theme/css/highlight.css">
        <link rel="stylesheet" href="../theme/css/tabs.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "ayu";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <button class="collapse-sidebar" aria-label="Collapse sidebar"></button>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Toggle color mode and talk to us buttons -->
        <script>
            document.addEventListener('click', function (event) {
                if (!event.target.matches('.theme-toggle')) return;
                event.preventDefault();
                const prevTheme = theme;
                html.classList.remove(theme);
                const newTheme = prevTheme === 'ayu' ? 'light' : 'ayu'
                html.classList.add(newTheme);
                theme = newTheme
                localStorage.setItem('mdbook-theme', theme);
            }, false);
            document.addEventListener('click', function() {
                if (!event.target.matches('.log-in')) return;
                event.preventDefault();
                window.amplitude.logEvent('LoginClickedFromPuzzles');
                window.open('https://developer.modular.com', '_blank');
            });
        </script>

        <div class="page-header">
            <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                <i class="fa fa-bars"></i>
            </label>
            <div id="menu-bar" class="menu-bar">
                <div class="left-buttons">
                    <div class="logo-section">
                        <a class="desktop-logo-link" href="https://modular.com"></a>
                        <a class="mobile-logo-link" href="https://builds.modular.com"></a>
                        <div class="slash">/</div>
                        <a class="internal-link" ref="/">Puzzles</a>
                    </div>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Dark</button></li>
                        </ul>
                    </div>
                <div class="right-buttons">
                    <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                        <i class="fa fa-search"></i>
                    </button>
                    <button id="theme-toggle" class="icon-button theme-toggle-btn" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="false" aria-expanded="false">
                        <i class="theme-toggle"></i>
                    </button>
                    <a class="menu-btn print" href="../print.html" title="Print this book" aria-label="Print this book">
                        <i id="print-button" class="fa fa-print"></i>
                    </a>
                    <a class="menu-btn" href="https://github.com/modular/mojo-gpu-puzzles" title="Git repository" aria-label="Git repository">
                        <i id="git-repository-button" class="fa fa-github"></i>
                    </a>
                </div>
            </div>
        </div>

        <div id="page-wrapper" class="page-wrapper">
            <div class="page">

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <div id="content" class="content">
                    <main>
                        <h1 id="warpprefix_sum-hardware-optimized-parallel-scan"><a class="header" href="#warpprefix_sum-hardware-optimized-parallel-scan"><code>warp.prefix_sum()</code> Hardware-Optimized Parallel Scan</a></h1>
<p>For warp-level parallel scan operations we can use <code>prefix_sum()</code> to replace complex shared memory algorithms with hardware-optimized primitives. This powerful operation enables efficient cumulative computations, parallel partitioning, and advanced coordination algorithms that would otherwise require dozens of lines of shared memory and synchronization code.</p>
<p><strong>Key insight:</strong> <em>The <a href="https://docs.modular.com/mojo/stdlib/gpu/warp/prefix_sum">prefix_sum()</a> operation leverages hardware-accelerated parallel scan to compute cumulative operations across warp lanes with \(O(\log n)\) complexity, replacing complex multi-phase algorithms with single function calls.</em></p>
<blockquote>
<p><strong>What is parallel scan?</strong> <a href="https://en.wikipedia.org/wiki/Prefix_sum">Parallel scan (prefix sum)</a> is a fundamental parallel primitive that computes cumulative operations across data elements. For addition, it transforms <code>[a, b, c, d]</code> into <code>[a, a+b, a+b+c, a+b+c+d]</code>. This operation is essential for parallel algorithms like stream compaction, quicksort partitioning, and parallel sorting.</p>
</blockquote>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key concepts</a></h2>
<p>In this puzzle, you‚Äôll learn:</p>
<ul>
<li><strong>Hardware-optimized parallel scan</strong> with <code>prefix_sum()</code></li>
<li><strong>Inclusive vs exclusive prefix sum</strong> patterns</li>
<li><strong>Warp-level stream compaction</strong> for data reorganization</li>
<li><strong>Advanced parallel partitioning</strong> combining multiple warp primitives</li>
<li><strong>Single-warp algorithm optimization</strong> replacing complex shared memory</li>
</ul>
<p>This transforms multi-phase shared memory algorithms into elegant single-function calls, enabling efficient parallel scan operations without explicit synchronization.</p>
<h2 id="1-warp-inclusive-prefix-sum"><a class="header" href="#1-warp-inclusive-prefix-sum">1. Warp inclusive prefix sum</a></h2>
<h3 id="configuration"><a class="header" href="#configuration">Configuration</a></h3>
<ul>
<li>Vector size: <code>SIZE = WARP_SIZE</code> (32 or 64 depending on GPU)</li>
<li>Grid configuration: <code>(1, 1)</code> blocks per grid</li>
<li>Block configuration: <code>(WARP_SIZE, 1)</code> threads per block</li>
<li>Data type: <code>DType.float32</code></li>
<li>Layout: <code>Layout.row_major(SIZE)</code> (1D row-major)</li>
</ul>
<h3 id="the-prefix_sum-advantage"><a class="header" href="#the-prefix_sum-advantage">The <code>prefix_sum</code> advantage</a></h3>
<p>Traditional prefix sum requires complex multi-phase shared memory algorithms. In <a href="../puzzle_14/puzzle_14.html">Puzzle 14</a>, we implemented this the hard way with explicit shared memory management:</p>
<pre><code class="language-mojo">fn prefix_sum_simple[
    layout: Layout
](
    output: LayoutTensor[dtype, layout, MutAnyOrigin],
    a: LayoutTensor[dtype, layout, ImmutAnyOrigin],
    size: Int,
):
    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x
    shared = LayoutTensor[
        dtype,
        Layout.row_major(TPB),
        MutAnyOrigin,
        address_space = AddressSpace.SHARED,
    ].stack_allocation()
    if global_i &lt; size:
        shared[local_i] = a[global_i]

    barrier()

    offset = 1
    for i in range(Int(log2(Scalar[dtype](TPB)))):
        var current_val: output.element_type = 0
        if local_i &gt;= offset and local_i &lt; size:
            current_val = shared[local_i - offset]  # read

        barrier()
        if local_i &gt;= offset and local_i &lt; size:
            shared[local_i] += current_val

        barrier()
        offset *= 2

    if global_i &lt; size:
        output[global_i] = shared[local_i]


</code></pre>
<p><strong>Problems with traditional approach:</strong></p>
<ul>
<li><strong>Memory overhead</strong>: Requires shared memory allocation</li>
<li><strong>Multiple barriers</strong>: Complex multi-phase synchronization</li>
<li><strong>Complex indexing</strong>: Manual stride calculation and boundary checking</li>
<li><strong>Poor scaling</strong>: \(O(\log n)\) phases with barriers between each</li>
</ul>
<p>With <code>prefix_sum()</code>, parallel scan becomes trivial:</p>
<pre><code class="language-mojo"># Hardware-optimized approach - single function call!
current_val = input[global_i]
scan_result = prefix_sum[exclusive=False](current_val)
output[global_i] = scan_result
</code></pre>
<p><strong>Benefits of prefix_sum:</strong></p>
<ul>
<li><strong>Zero memory overhead</strong>: Hardware-accelerated computation</li>
<li><strong>No synchronization</strong>: Single atomic operation</li>
<li><strong>Hardware optimized</strong>: Leverages specialized scan units</li>
<li><strong>Perfect scaling</strong>: Works for any <code>WARP_SIZE</code> (32, 64, etc.)</li>
</ul>
<h3 id="code-to-complete"><a class="header" href="#code-to-complete">Code to complete</a></h3>
<p>Implement inclusive prefix sum using the hardware-optimized <code>prefix_sum()</code> primitive.</p>
<p><strong>Mathematical operation:</strong> Compute cumulative sum where each lane gets the sum of all elements up to and including its position:
\[\Large \text{output}[i] = \sum_{j=0}^{i} \text{input}[j]\]</p>
<p>This transforms input data <code>[1, 2, 3, 4, 5, ...]</code> into cumulative sums <code>[1, 3, 6, 10, 15, ...]</code>, where each position contains the sum of all previous elements plus itself.</p>
<pre><code class="language-mojo">fn warp_inclusive_prefix_sum[
    layout: Layout, size: Int
](
    output: LayoutTensor[mut=True, dtype, layout],
    input: LayoutTensor[mut=False, dtype, layout],
):
    """
    Inclusive prefix sum using warp primitive:
    Each thread gets sum of all elements up to and including its position.
    Compare this to Puzzle 12's complex shared memory + barrier approach.

    Puzzle 12 approach:
    - Shared memory allocation
    - Multiple barrier synchronizations
    - Log(n) iterations with manual tree reduction
    - Complex multi-phase algorithm

    Warp prefix_sum approach:
    - Single function call!
    - Hardware-optimized parallel scan
    - Automatic synchronization
    - O(log n) complexity, but implemented in hardware.

    NOTE: This implementation only works correctly within a single warp (WARP_SIZE threads).
    For multi-warp scenarios, additional coordination would be needed.
    """
    global_i = block_dim.x * block_idx.x + thread_idx.x

    # FILL ME IN (roughly 4 lines)


</code></pre>
<p><a href="https://github.com/modular/mojo-gpu-puzzles/blob/main/problems/p26/p26.mojo" class="filename">View full file: problems/p26/p26.mojo</a></p>
<details>
<summary><strong>Tips</strong></summary>
<div class="solution-tips">
<h3 id="1-understanding-prefix_sum-parameters"><a class="header" href="#1-understanding-prefix_sum-parameters">1. <strong>Understanding prefix_sum parameters</strong></a></h3>
<p>The <code>prefix_sum()</code> function has an important template parameter that controls the scan type.</p>
<p><strong>Key questions:</strong></p>
<ul>
<li>What‚Äôs the difference between inclusive and exclusive prefix sum?</li>
<li>Which parameter controls this behavior?</li>
<li>For inclusive scan, what should each lane output?</li>
</ul>
<p><strong>Hint</strong>: Look at the function signature and consider what ‚Äúinclusive‚Äù means for cumulative operations.</p>
<h3 id="2-single-warp-limitation"><a class="header" href="#2-single-warp-limitation">2. <strong>Single warp limitation</strong></a></h3>
<p>This hardware primitive only works within a single warp. Consider the implications.</p>
<p><strong>Think about:</strong></p>
<ul>
<li>What happens if you have multiple warps?</li>
<li>Why is this limitation important to understand?</li>
<li>How would you extend this to multi-warp scenarios?</li>
</ul>
<h3 id="3-data-type-considerations"><a class="header" href="#3-data-type-considerations">3. <strong>Data type considerations</strong></a></h3>
<p>The <code>prefix_sum</code> function may require specific data types for optimal performance.</p>
<p><strong>Consider:</strong></p>
<ul>
<li>What data type does your input use?</li>
<li>Does <code>prefix_sum</code> expect a specific scalar type?</li>
<li>How do you handle type conversions if needed?</li>
</ul>
</div>
</details>
<p><strong>Test the warp inclusive prefix sum:</strong></p>
<div class="code-tabs" data-tab-group="package-manager">
  <div class="tab-buttons">
    <button class="tab-button">pixi NVIDIA (default)</button>
    <button class="tab-button">pixi AMD</button>
    <button class="tab-button">pixi Apple</button>
    <button class="tab-button">uv</button>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">pixi run p26 --prefix-sum
</code></pre>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">pixi run -e amd p26 --prefix-sum
</code></pre>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">pixi run -e apple p26 --prefix-sum
</code></pre>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">uv run poe p26 --prefix-sum
</code></pre>
  </div>
</div>
<p>Expected output when solved:</p>
<pre><code class="language-txt">WARP_SIZE:  32
SIZE:  32
output: [1.0, 3.0, 6.0, 10.0, 15.0, 21.0, 28.0, 36.0, 45.0, 55.0, 66.0, 78.0, 91.0, 105.0, 120.0, 136.0, 153.0, 171.0, 190.0, 210.0, 231.0, 253.0, 276.0, 300.0, 325.0, 351.0, 378.0, 406.0, 435.0, 465.0, 496.0, 528.0]
expected: [1.0, 3.0, 6.0, 10.0, 15.0, 21.0, 28.0, 36.0, 45.0, 55.0, 66.0, 78.0, 91.0, 105.0, 120.0, 136.0, 153.0, 171.0, 190.0, 210.0, 231.0, 253.0, 276.0, 300.0, 325.0, 351.0, 378.0, 406.0, 435.0, 465.0, 496.0, 528.0]
‚úÖ Warp inclusive prefix sum test passed!
</code></pre>
<h3 id="solution"><a class="header" href="#solution">Solution</a></h3>
<details class="solution-details">
<summary></summary>
<pre><code class="language-mojo">fn warp_inclusive_prefix_sum[
    layout: Layout, size: Int
](
    output: LayoutTensor[mut=True, dtype, layout],
    input: LayoutTensor[mut=False, dtype, layout],
):
    """
    Inclusive prefix sum using warp primitive: Each thread gets sum of all elements up to and including its position.
    Compare this to Puzzle 12's complex shared memory + barrier approach.

    Puzzle 12 approach:
    - Shared memory allocation
    - Multiple barrier synchronizations
    - Log(n) iterations with manual tree reduction
    - Complex multi-phase algorithm

    Warp prefix_sum approach:
    - Single function call!
    - Hardware-optimized parallel scan
    - Automatic synchronization
    - O(log n) complexity, but implemented in hardware.

    NOTE: This implementation only works correctly within a single warp (WARP_SIZE threads).
    For multi-warp scenarios, additional coordination would be needed.
    """
    global_i = block_dim.x * block_idx.x + thread_idx.x

    if global_i &lt; size:
        current_val = input[global_i]

        # This one call replaces ~30 lines of complex shared memory logic from Puzzle 12!
        # But it only works within the current warp (WARP_SIZE threads)
        scan_result = prefix_sum[exclusive=False](
            rebind[Scalar[dtype]](current_val)
        )

        output[global_i] = scan_result


</code></pre>
<div class="solution-explanation">
<p>This solution demonstrates how <code>prefix_sum()</code> replaces complex multi-phase algorithms with a single hardware-optimized function call.</p>
<p><strong>Algorithm breakdown:</strong></p>
<pre><code class="language-mojo">if global_i &lt; size:
    current_val = input[global_i]

    # This one call replaces ~30 lines of complex shared memory logic from Puzzle 14!
    # But it only works within the current warp (WARP_SIZE threads)
    scan_result = prefix_sum[exclusive=False](
        rebind[Scalar[dtype]](current_val)
    )

    output[global_i] = scan_result
</code></pre>
<p><strong>SIMT execution deep dive:</strong></p>
<pre><code>Input: [1, 2, 3, 4, 5, 6, 7, 8, ...]

Cycle 1: All lanes load their values simultaneously
  Lane 0: current_val = 1
  Lane 1: current_val = 2
  Lane 2: current_val = 3
  Lane 3: current_val = 4
  ...
  Lane 31: current_val = 32

Cycle 2: prefix_sum[exclusive=False] executes (hardware-accelerated)
  Lane 0: scan_result = 1 (sum of elements 0 to 0)
  Lane 1: scan_result = 3 (sum of elements 0 to 1: 1+2)
  Lane 2: scan_result = 6 (sum of elements 0 to 2: 1+2+3)
  Lane 3: scan_result = 10 (sum of elements 0 to 3: 1+2+3+4)
  ...
  Lane 31: scan_result = 528 (sum of elements 0 to 31)

Cycle 3: Store results
  Lane 0: output[0] = 1
  Lane 1: output[1] = 3
  Lane 2: output[2] = 6
  Lane 3: output[3] = 10
  ...
</code></pre>
<p><strong>Mathematical insight:</strong> This implements the inclusive prefix sum operation:
\[\Large \text{output}[i] = \sum_{j=0}^{i} \text{input}[j]\]</p>
<p><strong>Comparison with Puzzle 14‚Äôs approach:</strong></p>
<ul>
<li><strong><a href="../puzzle_14/puzzle_14.html">Puzzle 14</a></strong>: ~30 lines of shared memory + multiple barriers + complex indexing</li>
<li><strong>Warp primitive</strong>: 1 function call with hardware acceleration</li>
<li><strong>Performance</strong>: Same \(O(\log n)\) complexity, but implemented in specialized hardware</li>
<li><strong>Memory</strong>: Zero shared memory usage vs explicit allocation</li>
</ul>
<p><strong>Evolution from Puzzle 12:</strong> This demonstrates the power of modern GPU architectures - what required careful manual implementation in Puzzle 12 is now a single hardware-accelerated primitive. The warp-level <code>prefix_sum()</code> gives you the same algorithmic benefits with zero implementation complexity.</p>
<p><strong>Why prefix_sum is superior:</strong></p>
<ol>
<li><strong>Hardware acceleration</strong>: Dedicated scan units on modern GPUs</li>
<li><strong>Zero memory overhead</strong>: No shared memory allocation required</li>
<li><strong>Automatic synchronization</strong>: No explicit barriers needed</li>
<li><strong>Perfect scaling</strong>: Works optimally for any <code>WARP_SIZE</code></li>
</ol>
<p><strong>Performance characteristics:</strong></p>
<ul>
<li><strong>Latency</strong>: ~1-2 cycles (hardware scan units)</li>
<li><strong>Bandwidth</strong>: Zero memory traffic (register-only operation)</li>
<li><strong>Parallelism</strong>: All <code>WARP_SIZE</code> lanes participate simultaneously</li>
<li><strong>Scalability</strong>: \(O(\log n)\) complexity with hardware optimization</li>
</ul>
<p><strong>Important limitation</strong>: This primitive only works within a single warp. For multi-warp scenarios, you would need additional coordination between warps.</p>
</div>
</details>
<h2 id="2-warp-partition"><a class="header" href="#2-warp-partition">2. Warp partition</a></h2>
<h3 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h3>
<ul>
<li>Vector size: <code>SIZE = WARP_SIZE</code> (32 or 64 depending on GPU)</li>
<li>Grid configuration: <code>(1, 1)</code> blocks per grid</li>
<li>Block configuration: <code>(WARP_SIZE, 1)</code> threads per block</li>
</ul>
<h3 id="code-to-complete-1"><a class="header" href="#code-to-complete-1">Code to complete</a></h3>
<p>Implement single-warp parallel partitioning using BOTH <code>shuffle_xor</code> AND <code>prefix_sum</code> primitives.</p>
<p><strong>Mathematical operation:</strong> Partition elements around a pivot value, placing elements <code>&lt; pivot</code> on the left and elements <code>&gt;= pivot</code> on the right:
\[\Large \text{output} = [\text{elements} &lt; \text{pivot}] \,|\, [\text{elements} \geq \text{pivot}]\]</p>
<p><strong>Advanced algorithm:</strong> This combines two sophisticated warp primitives:</p>
<ol>
<li><strong><code>shuffle_xor()</code></strong>: Butterfly pattern for warp-level reduction (count left elements)</li>
<li><strong><code>prefix_sum()</code></strong>: Exclusive scan for position calculation within partitions</li>
</ol>
<p>This demonstrates the power of combining multiple warp primitives for complex parallel algorithms within a single warp.</p>
<pre><code class="language-mojo">fn warp_partition[
    layout: Layout, size: Int
](
    output: LayoutTensor[mut=True, dtype, layout],
    input: LayoutTensor[mut=False, dtype, layout],
    pivot: Float32,
):
    """
    Single-warp parallel partitioning using BOTH shuffle_xor AND prefix_sum.
    This implements a warp-level quicksort partition step that places elements &lt; pivot
    on the left and elements &gt;= pivot on the right.

    ALGORITHM COMPLEXITY - combines two advanced warp primitives:
    1. shuffle_xor(): Butterfly pattern for warp-level reductions
    2. prefix_sum(): Warp-level exclusive scan for position calculation.

    This demonstrates the power of warp primitives for sophisticated parallel algorithms
    within a single warp (works for any WARP_SIZE: 32, 64, etc.).

    Example with pivot=5:
    Input:  [3, 7, 1, 8, 2, 9, 4, 6]
    Result: [3, 1, 2, 4, 7, 8, 9, 6] (&lt; pivot | &gt;= pivot).
    """
    global_i = block_dim.x * block_idx.x + thread_idx.x

    if global_i &lt; size:
        current_val = input[global_i]

        # FILL ME IN (roughly 13 lines)


</code></pre>
<details>
<summary><strong>Tips</strong></summary>
<div class="solution-tips">
<h3 id="1-multi-phase-algorithm-structure"><a class="header" href="#1-multi-phase-algorithm-structure">1. <strong>Multi-phase algorithm structure</strong></a></h3>
<p>This algorithm requires several coordinated phases. Think about the logical steps needed for partitioning.</p>
<p><strong>Key phases to consider:</strong></p>
<ul>
<li>How do you identify which elements belong to which partition?</li>
<li>How do you calculate positions within each partition?</li>
<li>How do you determine the total size of the left partition?</li>
<li>How do you write elements to their final positions?</li>
</ul>
<h3 id="2-predicate-creation"><a class="header" href="#2-predicate-creation">2. <strong>Predicate creation</strong></a></h3>
<p>You need to create boolean predicates to identify partition membership.</p>
<p><strong>Think about:</strong></p>
<ul>
<li>How do you represent ‚Äúthis element belongs to the left partition‚Äù?</li>
<li>How do you represent ‚Äúthis element belongs to the right partition‚Äù?</li>
<li>What data type should you use for predicates that work with <code>prefix_sum</code>?</li>
</ul>
<h3 id="3-combining-shuffle_xor-and-prefix_sum"><a class="header" href="#3-combining-shuffle_xor-and-prefix_sum">3. <strong>Combining shuffle_xor and prefix_sum</strong></a></h3>
<p>This algorithm uses both warp primitives for different purposes.</p>
<p><strong>Consider:</strong></p>
<ul>
<li>What is <code>shuffle_xor</code> used for in this context?</li>
<li>What is <code>prefix_sum</code> used for in this context?</li>
<li>How do these two operations work together?</li>
</ul>
<h3 id="4-position-calculation"><a class="header" href="#4-position-calculation">4. <strong>Position calculation</strong></a></h3>
<p>The trickiest part is calculating where each element should be written in the output.</p>
<p><strong>Key insights:</strong></p>
<ul>
<li>Left partition elements: What determines their final position?</li>
<li>Right partition elements: How do you offset them correctly?</li>
<li>How do you combine local positions with partition boundaries?</li>
</ul>
</div>
</details>
<p><strong>Test the warp partition:</strong></p>
<div class="code-tabs" data-tab-group="package-manager">
  <div class="tab-buttons">
    <button class="tab-button">uv</button>
    <button class="tab-button">pixi</button>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">uv run poe p26 --partition
</code></pre>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">pixi run p26 --partition
</code></pre>
  </div>
</div>
<p>Expected output when solved:</p>
<pre><code class="language-txt">WARP_SIZE:  32
SIZE:  32
output: HostBuffer([3.0, 1.0, 2.0, 4.0, 0.0, 3.0, 1.0, 4.0, 3.0, 1.0, 2.0, 4.0, 0.0, 3.0, 1.0, 4.0, 7.0, 8.0, 9.0, 6.0, 10.0, 11.0, 12.0, 13.0, 7.0, 8.0, 9.0, 6.0, 10.0, 11.0, 12.0, 13.0])
expected: HostBuffer([3.0, 1.0, 2.0, 4.0, 0.0, 3.0, 1.0, 4.0, 3.0, 1.0, 2.0, 4.0, 0.0, 3.0, 1.0, 4.0, 7.0, 8.0, 9.0, 6.0, 10.0, 11.0, 12.0, 13.0, 7.0, 8.0, 9.0, 6.0, 10.0, 11.0, 12.0, 13.0])
pivot: 5.0
‚úÖ Warp partition test passed!
</code></pre>
<h3 id="solution-1"><a class="header" href="#solution-1">Solution</a></h3>
<details class="solution-details">
<summary></summary>
<pre><code class="language-mojo">fn warp_partition[
    layout: Layout, size: Int
](
    output: LayoutTensor[mut=True, dtype, layout],
    input: LayoutTensor[mut=False, dtype, layout],
    pivot: Float32,
):
    """
    Single-warp parallel partitioning using BOTH shuffle_xor AND prefix_sum.
    This implements a warp-level quicksort partition step that places elements &lt; pivot
    on the left and elements &gt;= pivot on the right.

    ALGORITHM COMPLEXITY - combines two advanced warp primitives:
    1. shuffle_xor(): Butterfly pattern for warp-level reductions
    2. prefix_sum(): Warp-level exclusive scan for position calculation.

    This demonstrates the power of warp primitives for sophisticated parallel algorithms
    within a single warp (works for any WARP_SIZE: 32, 64, etc.).

    Example with pivot=5:
    Input:  [3, 7, 1, 8, 2, 9, 4, 6]
    Result: [3, 1, 2, 4, 7, 8, 9, 6] (&lt; pivot | &gt;= pivot).
    """
    global_i = block_dim.x * block_idx.x + thread_idx.x

    if global_i &lt; size:
        current_val = input[global_i]

        # Phase 1: Create warp-level predicates
        predicate_left = Float32(1.0) if current_val &lt; pivot else Float32(0.0)
        predicate_right = Float32(1.0) if current_val &gt;= pivot else Float32(0.0)

        # Phase 2: Warp-level prefix sum to get positions within warp
        warp_left_pos = prefix_sum[exclusive=True](predicate_left)
        warp_right_pos = prefix_sum[exclusive=True](predicate_right)

        # Phase 3: Get total left count using shuffle_xor reduction
        warp_left_total = predicate_left

        # Butterfly reduction to get total across the warp: dynamic for any WARP_SIZE
        offset = WARP_SIZE // 2
        while offset &gt; 0:
            warp_left_total += shuffle_xor(warp_left_total, offset)
            offset //= 2

        # Phase 4: Write to output positions
        if current_val &lt; pivot:
            # Left partition: use warp-level position
            output[Int(warp_left_pos)] = current_val
        else:
            # Right partition: offset by total left count + right position
            output[Int(warp_left_total + warp_right_pos)] = current_val


</code></pre>
<div class="solution-explanation">
<p>This solution demonstrates advanced coordination between multiple warp primitives to implement sophisticated parallel algorithms.</p>
<p><strong>Complete algorithm analysis:</strong></p>
<pre><code class="language-mojo">if global_i &lt; size:
    current_val = input[global_i]

    # Phase 1: Create warp-level predicates
    predicate_left = Float32(1.0) if current_val &lt; pivot else Float32(0.0)
    predicate_right = Float32(1.0) if current_val &gt;= pivot else Float32(0.0)

    # Phase 2: Warp-level prefix sum to get positions within warp
    warp_left_pos = prefix_sum[exclusive=True](predicate_left)
    warp_right_pos = prefix_sum[exclusive=True](predicate_right)

    # Phase 3: Get total left count using shuffle_xor reduction
    warp_left_total = predicate_left

    # Butterfly reduction to get total across the warp: dynamic for any WARP_SIZE
    offset = WARP_SIZE // 2
    while offset &gt; 0:
        warp_left_total += shuffle_xor(warp_left_total, offset)
        offset //= 2

    # Phase 4: Write to output positions
    if current_val &lt; pivot:
        # Left partition: use warp-level position
        output[Int(warp_left_pos)] = current_val
    else:
        # Right partition: offset by total left count + right position
        output[Int(warp_left_total + warp_right_pos)] = current_val
</code></pre>
<p><strong>Multi-phase execution trace (8-lane example, pivot=5, values [3,7,1,8,2,9,4,6]):</strong></p>
<pre><code>Initial state:
  Lane 0: current_val=3 (&lt; 5)  Lane 1: current_val=7 (&gt;= 5)
  Lane 2: current_val=1 (&lt; 5)  Lane 3: current_val=8 (&gt;= 5)
  Lane 4: current_val=2 (&lt; 5)  Lane 5: current_val=9 (&gt;= 5)
  Lane 6: current_val=4 (&lt; 5)  Lane 7: current_val=6 (&gt;= 5)

Phase 1: Create predicates
  Lane 0: predicate_left=1.0, predicate_right=0.0
  Lane 1: predicate_left=0.0, predicate_right=1.0
  Lane 2: predicate_left=1.0, predicate_right=0.0
  Lane 3: predicate_left=0.0, predicate_right=1.0
  Lane 4: predicate_left=1.0, predicate_right=0.0
  Lane 5: predicate_left=0.0, predicate_right=1.0
  Lane 6: predicate_left=1.0, predicate_right=0.0
  Lane 7: predicate_left=0.0, predicate_right=1.0

Phase 2: Exclusive prefix sum for positions
  warp_left_pos:  [0, 0, 1, 1, 2, 2, 3, 3]
  warp_right_pos: [0, 0, 0, 1, 1, 2, 2, 3]

Phase 3: Butterfly reduction for left total
  Initial: [1, 0, 1, 0, 1, 0, 1, 0]
  After reduction: all lanes have warp_left_total = 4

Phase 4: Write to output positions
  Lane 0: current_val=3 &lt; pivot ‚Üí output[0] = 3
  Lane 1: current_val=7 &gt;= pivot ‚Üí output[4+0] = output[4] = 7
  Lane 2: current_val=1 &lt; pivot ‚Üí output[1] = 1
  Lane 3: current_val=8 &gt;= pivot ‚Üí output[4+1] = output[5] = 8
  Lane 4: current_val=2 &lt; pivot ‚Üí output[2] = 2
  Lane 5: current_val=9 &gt;= pivot ‚Üí output[4+2] = output[6] = 9
  Lane 6: current_val=4 &lt; pivot ‚Üí output[3] = 4
  Lane 7: current_val=6 &gt;= pivot ‚Üí output[4+3] = output[7] = 6

Final result: [3, 1, 2, 4, 7, 8, 9, 6] (&lt; pivot | &gt;= pivot)
</code></pre>
<p><strong>Mathematical insight:</strong> This implements parallel partitioning with dual warp primitives:
\[\Large \begin{align}
\text{left\_pos}[i] &amp;= \text{prefix\<em>sum}</em>{\text{exclusive}}(\text{predicate\_left}[i]) \\
\text{right\_pos}[i] &amp;= \text{prefix\<em>sum}</em>{\text{exclusive}}(\text{predicate\_right}[i]) \\
\text{left\_total} &amp;= \text{butterfly\_reduce}(\text{predicate\_left}) \\
\text{final\_pos}[i] &amp;= \begin{cases}
\text{left\_pos}[i] &amp; \text{if } \text{input}[i] &lt; \text{pivot} \\
\text{left\_total} + \text{right\_pos}[i] &amp; \text{if } \text{input}[i] \geq \text{pivot}
\end{cases}
\end{align}\]</p>
<p><strong>Why this multi-primitive approach works:</strong></p>
<ol>
<li><strong>Predicate creation</strong>: Identifies partition membership for each element</li>
<li><strong>Exclusive prefix sum</strong>: Calculates relative positions within each partition</li>
<li><strong>Butterfly reduction</strong>: Computes partition boundary (total left count)</li>
<li><strong>Coordinated write</strong>: Combines local positions with global partition structure</li>
</ol>
<p><strong>Algorithm complexity:</strong></p>
<ul>
<li><strong>Phase 1</strong>: \(O(1)\) - Predicate creation</li>
<li><strong>Phase 2</strong>: \(O(\log n)\) - Hardware-accelerated prefix sum</li>
<li><strong>Phase 3</strong>: \(O(\log n)\) - Butterfly reduction with <code>shuffle_xor</code></li>
<li><strong>Phase 4</strong>: \(O(1)\) - Coordinated write</li>
<li><strong>Total</strong>: \(O(\log n)\) with excellent constants</li>
</ul>
<p><strong>Performance characteristics:</strong></p>
<ul>
<li><strong>Communication steps</strong>: \(2 \times \log_2(\text{WARP_SIZE})\) (prefix sum + butterfly reduction)</li>
<li><strong>Memory efficiency</strong>: Zero shared memory, all register-based</li>
<li><strong>Parallelism</strong>: All lanes active throughout algorithm</li>
<li><strong>Scalability</strong>: Works for any <code>WARP_SIZE</code> (32, 64, etc.)</li>
</ul>
<p><strong>Practical applications:</strong> This pattern is fundamental to:</p>
<ul>
<li><strong>Quicksort partitioning</strong>: Core step in parallel sorting algorithms</li>
<li><strong>Stream compaction</strong>: Removing null/invalid elements from data streams</li>
<li><strong>Parallel filtering</strong>: Separating data based on complex predicates</li>
<li><strong>Load balancing</strong>: Redistributing work based on computational requirements</li>
</ul>
</div>
</details>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>The <code>prefix_sum()</code> primitive enables hardware-accelerated parallel scan operations that replace complex multi-phase algorithms with single function calls. Through these two problems, you‚Äôve learned:</p>
<h3 id="core-prefix-sum-patterns"><a class="header" href="#core-prefix-sum-patterns"><strong>Core Prefix Sum Patterns</strong></a></h3>
<ol>
<li>
<p><strong>Inclusive Prefix Sum</strong> (<code>prefix_sum[exclusive=False]</code>):</p>
<ul>
<li>Hardware-accelerated cumulative operations</li>
<li>Replaces ~30 lines of shared memory code with single function call</li>
<li>\(O(\log n)\) complexity with specialized hardware optimization</li>
</ul>
</li>
<li>
<p><strong>Advanced Multi-Primitive Coordination</strong> (combining <code>prefix_sum</code> + <code>shuffle_xor</code>):</p>
<ul>
<li>Sophisticated parallel algorithms within single warp</li>
<li>Exclusive scan for position calculation + butterfly reduction for totals</li>
<li>Complex partitioning operations with optimal parallel efficiency</li>
</ul>
</li>
</ol>
<h3 id="key-algorithmic-insights"><a class="header" href="#key-algorithmic-insights"><strong>Key Algorithmic Insights</strong></a></h3>
<p><strong>Hardware Acceleration Benefits:</strong></p>
<ul>
<li><code>prefix_sum()</code> leverages dedicated scan units on modern GPUs</li>
<li>Zero shared memory overhead compared to traditional approaches</li>
<li>Automatic synchronization without explicit barriers</li>
</ul>
<p><strong>Multi-Primitive Coordination:</strong></p>
<pre><code class="language-mojo"># Phase 1: Create predicates for partition membership
predicate = 1.0 if condition else 0.0

# Phase 2: Use prefix_sum for local positions
local_pos = prefix_sum[exclusive=True](predicate)

# Phase 3: Use shuffle_xor for global totals
global_total = butterfly_reduce(predicate)

# Phase 4: Combine for final positioning
final_pos = local_pos + partition_offset
</code></pre>
<p><strong>Performance Advantages:</strong></p>
<ul>
<li><strong>Hardware optimization</strong>: Specialized scan units vs software implementation</li>
<li><strong>Memory efficiency</strong>: Register-only operations vs shared memory allocation</li>
<li><strong>Scalable complexity</strong>: \(O(\log n)\) with hardware acceleration</li>
<li><strong>Single-warp optimization</strong>: Perfect for algorithms within <code>WARP_SIZE</code> limits</li>
</ul>
<h3 id="practical-applications"><a class="header" href="#practical-applications"><strong>Practical Applications</strong></a></h3>
<p>These prefix sum patterns are fundamental to:</p>
<ul>
<li><strong>Parallel scan operations</strong>: Cumulative sums, products, min/max scans</li>
<li><strong>Stream compaction</strong>: Parallel filtering and data reorganization</li>
<li><strong>Quicksort partitioning</strong>: Core parallel sorting algorithm building block</li>
<li><strong>Parallel algorithms</strong>: Load balancing, work distribution, data restructuring</li>
</ul>
<p>The combination of <code>prefix_sum()</code> and <code>shuffle_xor()</code> demonstrates how modern GPU warp primitives can implement sophisticated parallel algorithms with minimal code complexity and optimal performance characteristics.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../puzzle_26/warp_shuffle_xor.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../puzzle_27/puzzle_27.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../puzzle_26/warp_shuffle_xor.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../puzzle_27/puzzle_27.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../theme/mojolang.js"></script>
        <script src="../theme/sidebar.js"></script>
        <script src="../theme/solution.js"></script>
        <script src="../theme/init-amplitude.js"></script>
        <script src="../theme/tabs.js"></script>


    </div>
    </body>
</html>
