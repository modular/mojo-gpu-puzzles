<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>📊 Benchmarking in Mojo - Mojo 🔥 GPU Puzzles</title>


        <!-- Custom HTML head -->
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,100..700;1,100..700&display=swap"
            rel="stylesheet">
        
        <script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
        
        <link rel="stylesheet" href="../theme/css/custom.css">
        <link rel="stylesheet" href="../theme/css/highlight.css">
        <link rel="stylesheet" id="theme">
        
        <!-- Additional meta tags -->
        <meta property="og:title" content="Mojo🔥 GPU Puzzles">
        <meta property="og:description" content="Learn GPU Programming in Mojo🔥 Through Interactive Puzzles">
        <meta property="og:image" content="..//puzzles_images/puzzle-mark.svg">
        <meta property="og:url" content="https://builds.modular.com/puzzles">
        <meta name="twitter:card" content="summary">
        <meta name="twitter:image:alt" content="Mojo GPU Puzzles Logo">
        <meta name="twitter:title" content="Mojo🔥 GPU Puzzles">
        <meta name="twitter:description" content="Learn GPU Programming in Mojo🔥 Through Interactive Puzzles">
        <meta name="twitter:image" content="..//puzzles_images/puzzle-mark.svg">
        <link rel="icon" type="image/png" href="..//puzzles_images/puzzle-mark.svg">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&display=swap" rel="stylesheet">

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../theme/css/custom.css">
        <link rel="stylesheet" href="../theme/css/highlight.css">
        <link rel="stylesheet" href="../theme/css/tabs.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "ayu";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <button class="collapse-sidebar" aria-label="Collapse sidebar"></button>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Toggle color mode and talk to us buttons -->
        <script>
            document.addEventListener('click', function (event) {
                if (!event.target.matches('.theme-toggle')) return;
                event.preventDefault();
                const prevTheme = theme;
                html.classList.remove(theme);
                const newTheme = prevTheme === 'ayu' ? 'light' : 'ayu'
                html.classList.add(newTheme);
                theme = newTheme
                localStorage.setItem('mdbook-theme', theme);
            }, false);
            document.addEventListener('click', function() {
                if (!event.target.matches('.log-in')) return;
                event.preventDefault();
                window.amplitude.logEvent('LoginClickedFromPuzzles');
                window.open('https://developer.modular.com', '_blank');
            });
        </script>

        <div class="page-header">
            <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                <i class="fa fa-bars"></i>
            </label>
            <div id="menu-bar" class="menu-bar">
                <div class="left-buttons">
                    <div class="logo-section">
                        <a class="desktop-logo-link" href="https://modular.com"></a>
                        <a class="mobile-logo-link" href="https://builds.modular.com"></a>
                        <div class="slash">/</div>
                        <a class="internal-link" ref="/">Puzzles</a>
                    </div>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Dark</button></li>
                        </ul>
                    </div>
                <div class="menu-links">
                    <li><a href="https://docs.modular.com/max/get-started/" target="_blank"><div>Product</div></a></li>
                    <li><a href="https://www.modular.com/max/solutions/agent" target="_blank">Solutions</a></li>
                    <li><a href="https://builds.modular.com/?category=featured" target="_blank">Resources</a></li>
                    <li><a href="https://www.modular.com/company/about" target="_blank">Company</a></li>
                    <li><a href="https://www.modular.com/pricing" target="_blank">Pricing</a></li>
                    <li><a href="https://docs.modular.com" target="_blank">Docs</a></li>
                    <li><a href="https://www.modular.com/blog" target="_blank">Blog</a></li>
                </div>
                <div class="right-buttons">
                    <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                        <i class="fa fa-search"></i>
                    </button>
                    <button id="theme-toggle" class="icon-button theme-toggle-btn" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="false" aria-expanded="false">
                        <i class="theme-toggle"></i>
                    </button>
                    <a class="menu-btn print" href="../print.html" title="Print this book" aria-label="Print this book">
                        <i id="print-button" class="fa fa-print"></i>
                    </a>
                    <a class="menu-btn" href="https://github.com/modular/mojo-gpu-puzzles" title="Git repository" aria-label="Git repository">
                        <i id="git-repository-button" class="fa fa-github"></i>
                    </a>
                    <button class="secondary-btn log-in">Log in</button>
                </div>
            </div>
        </div>

        <div id="page-wrapper" class="page-wrapper">
            <div class="page">

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <div id="content" class="content">
                    <main>
                        <h1 id="-benchmarking---performance-analysis-and-optimization"><a class="header" href="#-benchmarking---performance-analysis-and-optimization">📊 Benchmarking - Performance Analysis and Optimization</a></h1>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>After mastering <strong>elementwise</strong>, <strong>tiled</strong>, <strong>manual vectorization</strong>, and <strong>Mojo vectorize</strong> patterns, it’s time to measure their actual performance. This guide explains how to use the built-in benchmarking system in <code>p20.mojo</code> to scientifically compare these approaches and understand their performance characteristics.</p>
<p><strong>Key insight:</strong> <em>Theoretical analysis is valuable, but empirical benchmarking reveals the true performance story on your specific hardware.</em></p>
<h2 id="running-benchmarks"><a class="header" href="#running-benchmarks">Running benchmarks</a></h2>
<p>To execute the comprehensive benchmark suite:</p>
<div class="code-tabs" data-tab-group="package-manager">
  <div class="tab-buttons">
    <button class="tab-button">uv</button>
    <button class="tab-button">pixi</button>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">uv run poe p20 --benchmark
</code></pre>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">pixi run p20 --benchmark
</code></pre>
  </div>
</div>
<p>Your output will show performance measurements for each pattern:</p>
<pre><code class="language-txt">SIZE: 1024
simd_width: 4
Running P20 GPU Benchmarks...
SIMD width: 4
--------------------------------------------------------------------------------
Testing SIZE=16, TILE=4
Running elementwise_16_4
Running tiled_16_4
Running manual_vectorized_16_4
Running vectorized_16_4
--------------------------------------------------------------------------------
Testing SIZE=128, TILE=16
Running elementwise_128_16
Running tiled_128_16
Running manual_vectorized_128_16
Testing SIZE=128, TILE=16, Vectorize within tiles
Running vectorized_128_16
--------------------------------------------------------------------------------
Testing SIZE=1048576 (1M), TILE=1024
Running elementwise_1M_1024
Running tiled_1M_1024
Running manual_vectorized_1M_1024
Running vectorized_1M_1024
----------------------------------------------------------
| name                      | met (ms)           | iters |
----------------------------------------------------------
| elementwise_16_4          | 4.59953155         | 100   |
| tiled_16_4                | 3.16459014         | 100   |
| manual_vectorized_16_4    | 4.60563415         | 100   |
| vectorized_16_4           | 3.15671539         | 100   |
| elementwise_128_16        | 3.1611135375       | 80    |
| tiled_128_16              | 3.1669656300000004 | 100   |
| manual_vectorized_128_16  | 3.1609855625       | 80    |
| vectorized_128_16         | 3.16142578         | 100   |
| elementwise_1M_1024       | 11.338706742857143 | 70    |
| tiled_1M_1024             | 12.044989871428571 | 70    |
| manual_vectorized_1M_1024 | 15.749412314285713 | 70    |
| vectorized_1M_1024        | 13.377229          | 100   |
----------------------------------------------------------

Benchmarks completed!
</code></pre>
<h2 id="benchmark-configuration"><a class="header" href="#benchmark-configuration">Benchmark configuration</a></h2>
<p>The benchmarking system uses Mojo’s built-in <code>benchmark</code> module with carefully chosen parameters:</p>
<pre><code class="language-mojo">bench_config = BenchConfig(max_iters=10, min_warmuptime_secs=0.2)
</code></pre>
<p><strong>Configuration explanation:</strong></p>
<ul>
<li><strong><code>max_iters=10</code></strong>: Runs each benchmark up to 10 times for statistical reliability</li>
<li><strong><code>min_warmuptime_secs=0.2</code></strong>: Ensures GPU is warmed up before measurement begins</li>
<li><strong>Automatic calibration</strong>: Framework automatically determines optimal iteration count</li>
</ul>
<h2 id="benchmarking-implementation-deep-dive"><a class="header" href="#benchmarking-implementation-deep-dive">Benchmarking implementation deep dive</a></h2>
<h3 id="1-mojo-benchmark-module-architecture"><a class="header" href="#1-mojo-benchmark-module-architecture">1. <strong>Mojo benchmark module architecture</strong></a></h3>
<p>The benchmarking system relies on Mojo’s built-in <code>benchmark</code> module:</p>
<pre><code class="language-mojo">from benchmark import (
    Bench,
    BenchConfig,
    Bencher,
    BenchId,
    keep
)
</code></pre>
<p><strong>Key components:</strong></p>
<ul>
<li><strong><code>Bench</code></strong>: The main benchmarking orchestrator that manages multiple benchmark runs</li>
<li><strong><code>BenchConfig</code></strong>: Specifies parameters like iteration counts and warmup time</li>
<li><strong><code>Bencher</code></strong>: Executes individual benchmark iterations and collects timing data</li>
<li><strong><code>BenchId</code></strong>: Provides unique names for benchmark identification and reporting</li>
<li><strong><code>keep</code></strong>: Hints the compiler to not optimize a variable away. This is important for correct benchmarking.</li>
</ul>
<h3 id="2-parameterized-benchmark-functions"><a class="header" href="#2-parameterized-benchmark-functions">2. <strong>Parameterized benchmark functions</strong></a></h3>
<p>Each pattern has a dedicated benchmark function using compile-time parameterization:</p>
<pre><code class="language-mojo">@parameter
@always_inline
fn benchmark_elementwise_parameterized[
    test_size: Int, tile_size: Int
](mut b: Bencher) raises:
    # Implementation follows...
</code></pre>
<p><strong>Why parameterized functions?</strong></p>
<ul>
<li><strong>Compile-time specialization</strong>: Each <code>test_size</code> and <code>tile_size</code> combination generates optimized code</li>
<li><strong>Zero abstraction cost</strong>: No runtime parameter overhead</li>
<li><strong>Type safety</strong>: Ensures consistent parameter usage across benchmarks</li>
<li><strong>Performance isolation</strong>: Each combination is independently optimized</li>
</ul>
<h3 id="3-workflow-pattern-implementation"><a class="header" href="#3-workflow-pattern-implementation">3. <strong>Workflow pattern implementation</strong></a></h3>
<p>Each benchmark follows a consistent nested function pattern:</p>
<pre><code class="language-mojo">@parameter
@always_inline
fn benchmark_pattern_parameterized[test_size: Int, tile_size: Int](mut b: Bencher) raises:
    @parameter
    @always_inline
    fn pattern_workflow(ctx: DeviceContext) raises:
        # 1. Setup phase: Create buffers and tensors
        alias layout = Layout.row_major(test_size)
        out = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)
        a = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)
        b_buf = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)

        # 2. Data initialization phase
        with a.map_to_host() as a_host, b_buf.map_to_host() as b_host:
            for i in range(test_size):
                a_host[i] = 2 * i
                b_host[i] = 2 * i + 1

        # 3. Tensor creation phase
        a_tensor = LayoutTensor[mut=False, dtype, layout](a.unsafe_ptr())
        b_tensor = LayoutTensor[mut=False, dtype, layout](b_buf.unsafe_ptr())
        out_tensor = LayoutTensor[mut=True, dtype, layout](out.unsafe_ptr())

        # 4. Actual computation being benchmarked
        pattern_function[layout, dtype, SIMD_WIDTH, rank, test_size](
            out_tensor, a_tensor, b_tensor, ctx
        )

        # 5. Prevent compiler optimization - Critical for accurate benchmarking!
        keep(out.unsafe_ptr())

        # 6. Synchronization to ensure completion
        ctx.synchronize()

    # 7. Benchmark execution
    bench_ctx = DeviceContext()
    b.iter_custom[pattern_workflow](bench_ctx)
</code></pre>
<p><strong>Workflow phases explained:</strong></p>
<h4 id="setup-phase-steps-1-3"><a class="header" href="#setup-phase-steps-1-3"><strong>Setup phase (steps 1-3):</strong></a></h4>
<ul>
<li><strong>Buffer allocation</strong>: <code>ctx.enqueue_create_buffer[dtype](test_size)</code> allocates GPU memory</li>
<li><strong>Initialization</strong>: <code>enqueue_fill(0)</code> zeros out the memory</li>
<li><strong>Data preparation</strong>: Maps to host memory for data initialization</li>
<li><strong>Tensor wrapping</strong>: Creates <code>LayoutTensor</code> views for the algorithms</li>
</ul>
<h4 id="computation-phase-step-4"><a class="header" href="#computation-phase-step-4"><strong>Computation phase (step 4):</strong></a></h4>
<ul>
<li><strong>Isolated execution</strong>: Only the algorithm computation is timed</li>
<li><strong>Consistent parameters</strong>: Same data layout and size across all patterns</li>
<li><strong>GPU targeting</strong>: All algorithms use <code>target="gpu"</code> for fair comparison</li>
</ul>
<h4 id="compiler-optimization-prevention-step-5"><a class="header" href="#compiler-optimization-prevention-step-5"><strong>Compiler optimization prevention (step 5):</strong></a></h4>
<ul>
<li><strong><code>keep(out.unsafe_ptr())</code></strong>: Critical function that prevents dead code elimination</li>
<li><strong>Why it’s needed</strong>: Without <code>keep</code>, the compiler might optimize away the entire computation since the result isn’t “used”</li>
<li><strong>GPU-specific concern</strong>: GPU kernels are asynchronous, making optimization detection more complex</li>
<li><strong>Placement importance</strong>: Must be after computation but before synchronization</li>
</ul>
<h4 id="synchronization-phase-step-6"><a class="header" href="#synchronization-phase-step-6"><strong>Synchronization phase (step 6):</strong></a></h4>
<ul>
<li><strong>Completion guarantee</strong>: <code>ctx.synchronize()</code> ensures GPU work completes</li>
<li><strong>Accurate timing</strong>: Prevents timing of incomplete GPU operations</li>
</ul>
<h3 id="4-custom-iteration-measurement"><a class="header" href="#4-custom-iteration-measurement">4. <strong>Custom iteration measurement</strong></a></h3>
<p>The key to accurate GPU benchmarking is the <code>iter_custom</code> approach:</p>
<pre><code class="language-mojo">b.iter_custom[pattern_workflow](bench_ctx)
</code></pre>
<p><strong>Why <code>iter_custom</code>?</strong></p>
<ul>
<li><strong>GPU context management</strong>: Handles DeviceContext lifecycle properly</li>
<li><strong>Memory management</strong>: Ensures proper buffer cleanup between iterations</li>
<li><strong>Synchronization</strong>: Handles GPU-CPU synchronization automatically</li>
<li><strong>Overhead isolation</strong>: Separates setup cost from computation cost</li>
</ul>
<p><strong>Comparison with standard iteration:</strong></p>
<pre><code class="language-mojo">// Standard (problematic for GPU):
b.iter[some_function]()  // No GPU context management

// Custom (optimal for GPU):
b.iter_custom[gpu_workflow](device_context)  // Proper GPU lifecycle
</code></pre>
<h3 id="5-benchmark-orchestration"><a class="header" href="#5-benchmark-orchestration">5. <strong>Benchmark orchestration</strong></a></h3>
<p>The main benchmarking sequence follows a structured approach:</p>
<pre><code class="language-mojo">bench_config = BenchConfig(max_iters=10, min_warmuptime_secs=0.2)
bench = Bench(bench_config)

// Register benchmarks with unique IDs
bench.bench_function[benchmark_elementwise_parameterized[16, 4]](
    BenchId("elementwise_16_4")
)
bench.bench_function[benchmark_tiled_parameterized[16, 4]](
    BenchId("tiled_16_4")
)

// Execute and report
print(bench)  // Automatic results table generation
</code></pre>
<p><strong>Orchestration benefits:</strong></p>
<ul>
<li><strong>Centralized configuration</strong>: Single config applies to all benchmarks</li>
<li><strong>Automatic result collection</strong>: Framework handles timing and statistics</li>
<li><strong>Consistent reporting</strong>: Uniform output format across all patterns</li>
<li><strong>Statistical reliability</strong>: Multiple iterations with automatic outlier handling</li>
</ul>
<h3 id="6-memory-and-synchronization-considerations"><a class="header" href="#6-memory-and-synchronization-considerations">6. <strong>Memory and synchronization considerations</strong></a></h3>
<h4 id="critical-role-of-keep-in-gpu-benchmarking"><a class="header" href="#critical-role-of-keep-in-gpu-benchmarking"><strong>Critical role of <code>keep()</code> in GPU benchmarking:</strong></a></h4>
<pre><code class="language-mojo">keep(out.unsafe_ptr())  // Prevents dead code elimination
</code></pre>
<p><strong>The optimization problem:</strong>
Modern compilers are aggressive about eliminating “unused” computations. In our benchmarks:</p>
<pre><code class="language-mojo">// Without keep(), compiler might see:
pattern_function(out_tensor, a_tensor, b_tensor, ctx)
// Result never read -&gt; entire computation eliminated!
</code></pre>
<p><strong>Why <code>keep()</code> is essential:</strong></p>
<ul>
<li><strong>Dead code elimination</strong>: Compiler sees output buffer is never read and might skip the computation</li>
<li><strong>GPU complexity</strong>: Asynchronous kernel launches make optimization detection harder</li>
<li><strong>Benchmark accuracy</strong>: Without <code>keep</code>, you might be measuring nothing instead of the algorithm</li>
<li><strong>Strategic placement</strong>: Must be after computation but before synchronization to be effective</li>
</ul>
<p><strong>What <code>keep()</code> does:</strong></p>
<ul>
<li><strong>Hints to compiler</strong>: “This memory location contains important data, don’t optimize away”</li>
<li><strong>Zero runtime cost</strong>: Pure compile-time hint, no performance impact</li>
<li><strong>Prevents false results</strong>: Ensures actual work is measured, not optimized-away code</li>
</ul>
<p><strong>Real-world impact:</strong>
Without <code>keep()</code>, all our benchmark results might show unrealistically fast times (measuring empty kernels) or even CUDA errors from eliminated GPU operations.</p>
<h4 id="buffer-lifecycle-management"><a class="header" href="#buffer-lifecycle-management"><strong>Buffer lifecycle management:</strong></a></h4>
<pre><code class="language-mojo">// Each iteration creates fresh buffers
out = ctx.enqueue_create_buffer[dtype](test_size).enqueue_fill(0)
// Automatic cleanup when out goes out of scope
</code></pre>
<p><strong>Why fresh buffers per iteration?</strong></p>
<ul>
<li><strong>Cache neutrality</strong>: Prevents cache warming from affecting results</li>
<li><strong>Memory pressure testing</strong>: Tests allocation overhead realistically</li>
<li><strong>Consistent starting state</strong>: Each iteration starts with identical conditions</li>
</ul>
<h4 id="gpu-synchronization-strategy"><a class="header" href="#gpu-synchronization-strategy"><strong>GPU synchronization strategy:</strong></a></h4>
<pre><code class="language-mojo">ctx.synchronize()  // Critical for accurate timing
</code></pre>
<p><strong>GPU timing challenges:</strong></p>
<ul>
<li><strong>Asynchronous execution</strong>: GPU kernels launch asynchronously</li>
<li><strong>Pipelined operations</strong>: Multiple kernels may overlap</li>
<li><strong>Memory transfers</strong>: Host-device transfers add complexity</li>
</ul>
<p><strong>How <code>synchronize()</code> solves this:</strong></p>
<ul>
<li><strong>Completion guarantee</strong>: Ensures all GPU work finishes before timing stops</li>
<li><strong>Accurate measurement</strong>: Captures actual computation time, not launch time</li>
<li><strong>Cross-platform consistency</strong>: Works across different GPU vendors/drivers</li>
</ul>
<h3 id="7-parameterization-strategy"><a class="header" href="#7-parameterization-strategy">7. <strong>Parameterization strategy</strong></a></h3>
<p>The benchmark tests specific size combinations:</p>
<pre><code class="language-mojo">// Small problem: Tests overhead characteristics
benchmark_pattern_parameterized[16, 4]

// Medium problem: Tests scaling and cache behavior
benchmark_pattern_parameterized[128, 16]
</code></pre>
<p><strong>Size selection rationale:</strong></p>
<ul>
<li><strong>SIZE=16, TILE=4</strong>: Minimal GPU utilization, overhead-dominated</li>
<li><strong>SIZE=128, TILE=16</strong>: Better GPU utilization, cache effects visible</li>
<li><strong>Power-of-2 sizes</strong>: Aligned with GPU memory architecture</li>
<li><strong>Tile size relationships</strong>: Tests different thread-to-work ratios</li>
</ul>
<h3 id="8-result-aggregation-and-reporting"><a class="header" href="#8-result-aggregation-and-reporting">8. <strong>Result aggregation and reporting</strong></a></h3>
<p>The framework automatically generates the results table:</p>
<pre><code class="language-mojo">print(bench)  // Triggers result compilation and display
</code></pre>
<p><strong>What happens during result compilation:</strong></p>
<ul>
<li><strong>Statistical analysis</strong>: Calculates mean, best, and deviation across iterations</li>
<li><strong>Outlier filtering</strong>: Removes statistical outliers for more reliable results</li>
<li><strong>Format standardization</strong>: Converts timing to consistent units (milliseconds)</li>
<li><strong>Tabular output</strong>: Generates the formatted results table</li>
</ul>
<p><strong>Result interpretation framework:</strong></p>
<ul>
<li><strong>Total execution time</strong>: <code>met (ms)</code> shows cumulative time for all iterations</li>
<li><strong>Iteration count</strong>: <code>iters</code> shows how many times each benchmark ran</li>
<li><strong>Relative comparison</strong>: Framework enables direct pattern-to-pattern comparison</li>
</ul>
<p>This implementation demonstrates Mojo’s sophisticated approach to performance measurement, combining compile-time optimization with runtime flexibility for accurate GPU benchmarking.</p>
<h2 id="test-scenarios"><a class="header" href="#test-scenarios">Test scenarios</a></h2>
<p>The benchmark suite tests three different scenarios to reveal performance characteristics across various problem sizes:</p>
<h3 id="1-small-problem-size-size16-tile4"><a class="header" href="#1-small-problem-size-size16-tile4">1. Small problem size (SIZE=16, TILE=4)</a></h3>
<pre><code class="language-mojo">benchmark_elementwise_parameterized[16, 4]
benchmark_tiled_parameterized[16, 4]
benchmark_manual_vectorized_parameterized[16, 4]
benchmark_vectorized_parameterized[16, 4]
</code></pre>
<p><strong>Purpose:</strong></p>
<ul>
<li>Tests behavior with minimal GPU utilization</li>
<li>Reveals overhead costs and launch characteristics of different approaches</li>
<li>Shows which patterns work best for tiny workloads</li>
</ul>
<p><strong>Observed characteristics:</strong></p>
<ul>
<li>Launch overhead dominates computation time (~3-4ms baseline)</li>
<li>Tiled/vectorize patterns show lower overhead (~3.16ms)</li>
<li>Elementwise/manual show higher overhead (~4.6ms)</li>
</ul>
<h3 id="2-medium-problem-size-size128-tile16"><a class="header" href="#2-medium-problem-size-size128-tile16">2. Medium problem size (SIZE=128, TILE=16)</a></h3>
<pre><code class="language-mojo">benchmark_elementwise_parameterized[128, 16]
benchmark_tiled_parameterized[128, 16]
benchmark_manual_vectorized_parameterized[128, 16]
benchmark_vectorized_parameterized[128, 16]
</code></pre>
<p><strong>Purpose:</strong></p>
<ul>
<li>Transition zone between overhead-dominated and computation-dominated</li>
<li>Tests moderate GPU utilization</li>
<li>All patterns converge to similar performance</li>
</ul>
<p><strong>Observed characteristics:</strong></p>
<ul>
<li>All patterns perform similarly (~3.16ms)</li>
<li>Launch overhead still significant relative to computation</li>
<li>Pattern differences begin to emerge but remain subtle</li>
</ul>
<h3 id="3-large-problem-size-size1048576-tile1024"><a class="header" href="#3-large-problem-size-size1048576-tile1024">3. Large problem size (SIZE=1,048,576, TILE=1024)</a></h3>
<pre><code class="language-mojo">benchmark_elementwise_parameterized[1048576, 1024]
benchmark_tiled_parameterized[1048576, 1024]
benchmark_manual_vectorized_parameterized[1048576, 1024]
benchmark_vectorized_parameterized[1048576, 1024]
</code></pre>
<p><strong>Purpose:</strong></p>
<ul>
<li>Tests real GPU workloads with significant computation</li>
<li>Reveals true algorithmic performance differences</li>
<li>Memory bandwidth becomes the primary factor</li>
</ul>
<p><strong>Observed characteristics:</strong></p>
<ul>
<li>Meaningful performance scaling (11-15ms, 3× slower than small problems)</li>
<li>Clear pattern differentiation emerges</li>
<li>Elementwise fastest (~11.3ms), manual vectorized slowest (~15.7ms)</li>
<li>Framework adapts iteration counts (70 vs 100) based on execution time</li>
</ul>
<h2 id="understanding-benchmark-results"><a class="header" href="#understanding-benchmark-results">Understanding benchmark results</a></h2>
<h3 id="interpreting-the-output"><a class="header" href="#interpreting-the-output">Interpreting the output</a></h3>
<p>Each benchmark result shows:</p>
<pre><code class="language-txt">| name                     | met (ms)           | iters |
| elementwise_16_4         | 3.15463684         | 100   |
</code></pre>
<p><strong>Metrics explained:</strong></p>
<ul>
<li><strong><code>name</code></strong>: The benchmark identifier (pattern_size_tile format)</li>
<li><strong><code>met (ms)</code></strong>: Total execution time in milliseconds for all iterations</li>
<li><strong><code>iters</code></strong>: Number of iterations performed (typically 100)</li>
</ul>
<p><strong>What to look for:</strong></p>
<ul>
<li><strong>Lower total time</strong>: Better overall performance for the workload</li>
<li><strong>Consistent timing</strong>: Similar execution times indicate stable performance</li>
<li><strong>Relative comparison</strong>: Compare times between patterns for the same problem size</li>
</ul>
<h3 id="performance-analysis-framework"><a class="header" href="#performance-analysis-framework">Performance analysis framework</a></h3>
<p>When analyzing results, consider these factors:</p>
<h4 id="1-thread-utilization-efficiency"><a class="header" href="#1-thread-utilization-efficiency">1. <strong>Thread utilization efficiency</strong></a></h4>
<pre><code>Small problem (SIZE=16):
Elementwise: 16 ÷ 4 = 4 threads
Tiled:       16 ÷ 4 = 4 threads
Manual:      16 ÷ (4×4) = 1 thread
Vectorize:   16 ÷ 4 = 4 threads

Medium problem (SIZE=128):
Elementwise: 128 ÷ 4 = 32 threads
Tiled:       128 ÷ 16 = 8 threads
Manual:      128 ÷ (16×4) = 2 threads
Vectorize:   128 ÷ 16 = 8 threads

Large problem (SIZE=1,048,576):
Elementwise: 1,048,576 ÷ 4 = 262,144 threads
Tiled:       1,048,576 ÷ 1024 = 1,024 threads
Manual:      1,048,576 ÷ (1024×4) = 256 threads
Vectorize:   1,048,576 ÷ 1024 = 1,024 threads
</code></pre>
<p><strong>Real-world observations:</strong></p>
<ul>
<li><strong>Small problems</strong>: Thread count differences don’t matter, overhead dominates</li>
<li><strong>Medium problems</strong>: Still overhead-dominated, patterns converge</li>
<li><strong>Large problems</strong>: Thread utilization becomes meaningful, clear performance differentiation</li>
</ul>
<h4 id="2-memory-access-pattern-impact"><a class="header" href="#2-memory-access-pattern-impact">2. <strong>Memory access pattern impact</strong></a></h4>
<pre><code>Elementwise: Distributed access across entire array
Tiled:       Localized access within small blocks
Manual:      Large sequential chunks
Vectorize:   Automatic optimization within tiles
</code></pre>
<p><strong>Performance indicators:</strong></p>
<ul>
<li><strong>Cache hit rates</strong>: Tiled patterns should show better cache behavior</li>
<li><strong>Memory bandwidth</strong>: Sequential patterns should achieve higher bandwidth</li>
<li><strong>Latency hiding</strong>: More threads should hide memory access latency better</li>
</ul>
<h4 id="3-simd-utilization-analysis"><a class="header" href="#3-simd-utilization-analysis">3. <strong>SIMD utilization analysis</strong></a></h4>
<p>All patterns achieve the same total SIMD operations, but with different organization:</p>
<p><strong>For SIZE=16 (SIMD_WIDTH=4):</strong></p>
<pre><code>Total SIMD ops = 16 ÷ 4 = 4 SIMD operations

Distribution:
- Elementwise: 4 threads × 1 SIMD op each
- Tiled:       4 threads × 1 SIMD op each
- Manual:      1 thread × 4 SIMD ops
- Vectorize:   4 threads × 1 SIMD op each (automatic)
</code></pre>
<p><strong>For SIZE=128 (SIMD_WIDTH=4):</strong></p>
<pre><code>Total SIMD ops = 128 ÷ 4 = 32 SIMD operations

Distribution:
- Elementwise: 32 threads × 1 SIMD op each
- Tiled:       8 threads × 4 SIMD ops each
- Manual:      2 threads × 16 SIMD ops each
- Vectorize:   8 threads × 4 SIMD ops each (automatic)
</code></pre>
<p><strong>For SIZE=1,048,576 (SIMD_WIDTH=4):</strong></p>
<pre><code>Total SIMD ops = 1,048,576 ÷ 4 = 262,144 SIMD operations

Distribution:
- Elementwise: 262,144 threads × 1 SIMD op each
- Tiled:       1,024 threads × 256 SIMD ops each
- Manual:      256 threads × 1,024 SIMD ops each
- Vectorize:   1,024 threads × 256 SIMD ops each (automatic)
</code></pre>
<p><strong>Performance correlation:</strong>
At large scale, the pattern with the highest thread count (elementwise) performs best, suggesting that GPU parallelization outweighs complex memory access optimizations for simple memory-bound operations.</p>
<h2 id="practical-performance-insights"><a class="header" href="#practical-performance-insights">Practical performance insights</a></h2>
<h3 id="observed-performance-patterns"><a class="header" href="#observed-performance-patterns">Observed performance patterns</a></h3>
<p>Based on the empirical benchmark results, here’s what we actually observe:</p>
<h4 id="small-problems-size16"><a class="header" href="#small-problems-size16"><strong>Small problems (SIZE=16)</strong></a></h4>
<ul>
<li><strong>Tiled/Vectorize</strong>: Fastest (~3.16ms) due to lower launch overhead</li>
<li><strong>Elementwise/Manual</strong>: Slower (~4.6ms) due to higher launch overhead</li>
<li><strong>Launch overhead dominates</strong>: Computation time is negligible compared to GPU kernel launch costs</li>
</ul>
<h4 id="medium-problems-size128"><a class="header" href="#medium-problems-size128"><strong>Medium problems (SIZE=128)</strong></a></h4>
<ul>
<li><strong>All patterns converge</strong>: Performance differences nearly disappear (~3.16ms)</li>
<li><strong>Transitional behavior</strong>: Still overhead-dominated but patterns begin to differentiate</li>
<li><strong>Framework optimization</strong>: Iteration counts automatically adjust (80-100 iterations)</li>
</ul>
<h4 id="large-problems-size1048576---where-real-differences-emerge"><a class="header" href="#large-problems-size1048576---where-real-differences-emerge"><strong>Large problems (SIZE=1,048,576) - Where real differences emerge</strong></a></h4>
<ul>
<li><strong>Elementwise wins</strong>: 11.34ms - High parallelism excels for memory-bound operations</li>
<li><strong>Tiled second</strong>: 12.04ms - Good balance of parallelism and locality</li>
<li><strong>Vectorize third</strong>: 13.38ms - Automatic optimization overhead becomes visible</li>
<li><strong>Manual vectorized slowest</strong>: 15.75ms - Complex indexing hurts simple operations</li>
</ul>
<p><strong>Key insight:</strong> For simple memory-bound operations like vector addition, <strong>maximum parallelism (elementwise) outperforms complex memory optimizations</strong> at scale.</p>
<h3 id="hardware-specific-considerations"><a class="header" href="#hardware-specific-considerations">Hardware-specific considerations</a></h3>
<p>Your results will vary based on:</p>
<h4 id="gpu-architecture-factors"><a class="header" href="#gpu-architecture-factors"><strong>GPU architecture factors:</strong></a></h4>
<ul>
<li><strong>SIMD width</strong>: Affects optimal vectorization strategy</li>
<li><strong>Cache size</strong>: Influences optimal tile size</li>
<li><strong>Core count</strong>: Determines benefit of higher thread counts</li>
<li><strong>Memory bandwidth</strong>: Sets theoretical performance ceiling</li>
</ul>
<h4 id="system-factors"><a class="header" href="#system-factors"><strong>System factors:</strong></a></h4>
<ul>
<li><strong>Memory hierarchy</strong>: L1/L2 cache sizes affect tiling benefits</li>
<li><strong>Thermal throttling</strong>: May affect sustained performance</li>
<li><strong>Concurrent workloads</strong>: Other GPU usage impacts results</li>
</ul>
<h2 id="advanced-benchmarking-techniques"><a class="header" href="#advanced-benchmarking-techniques">Advanced benchmarking techniques</a></h2>
<h3 id="custom-benchmark-scenarios"><a class="header" href="#custom-benchmark-scenarios">Custom benchmark scenarios</a></h3>
<p>You can modify the benchmark parameters to test different scenarios:</p>
<pre><code class="language-mojo">// Test different problem sizes
benchmark_elementwise_parameterized[1024, 32]  // Large problem
benchmark_elementwise_parameterized[64, 8]     // Small problem

// Test different tile sizes
benchmark_tiled_parameterized[256, 8]   // Small tiles
benchmark_tiled_parameterized[256, 64]  // Large tiles
</code></pre>
<h3 id="performance-profiling-integration"><a class="header" href="#performance-profiling-integration">Performance profiling integration</a></h3>
<p>For deeper analysis, combine benchmarking with:</p>
<ul>
<li><strong>GPU profilers</strong>: NVIDIA Nsight, AMD ROCProfiler</li>
<li><strong>Memory bandwidth tools</strong>: Check actual vs theoretical bandwidth</li>
<li><strong>Cache analysis</strong>: Measure hit rates and access patterns</li>
</ul>
<p>💡 <strong>Note</strong>: Advanced GPU profiling techniques and tools will be covered in detail in later parts of this book series.</p>
<h2 id="interpreting-your-results"><a class="header" href="#interpreting-your-results">Interpreting your results</a></h2>
<h3 id="performance-ranking-methodology"><a class="header" href="#performance-ranking-methodology">Performance ranking methodology</a></h3>
<p>When comparing results:</p>
<ol>
<li><strong>Normalize by problem size</strong>: Calculate throughput (elements/second)</li>
<li><strong>Consider consistency</strong>: Prefer patterns with low deviation</li>
<li><strong>Account for complexity</strong>: Factor in development and maintenance costs</li>
<li><strong>Test scaling</strong>: Verify performance across different problem sizes</li>
</ol>
<h3 id="making-optimization-decisions"><a class="header" href="#making-optimization-decisions">Making optimization decisions</a></h3>
<p>Use benchmark results to:</p>
<h4 id="choose-optimal-patterns-based-on-empirical-results"><a class="header" href="#choose-optimal-patterns-based-on-empirical-results"><strong>Choose optimal patterns based on empirical results:</strong></a></h4>
<ul>
<li><strong>For simple memory-bound operations</strong>: Elementwise pattern consistently wins at scale</li>
<li><strong>For small/startup workloads</strong>: Tiled or vectorize patterns have lower launch overhead</li>
<li><strong>For development productivity</strong>: Mojo vectorize provides good performance with automatic optimization</li>
<li><strong>Avoid manual vectorization</strong>: For simple operations, the complexity doesn’t pay off</li>
</ul>
<h4 id="problem-size-considerations"><a class="header" href="#problem-size-considerations"><strong>Problem size considerations:</strong></a></h4>
<ul>
<li><strong>Tiny problems (&lt; 1K elements)</strong>: Launch overhead dominates, choose patterns with lower overhead</li>
<li><strong>Medium problems (1K-100K)</strong>: Performance differences are minimal, choose for maintainability</li>
<li><strong>Large problems (&gt; 100K elements)</strong>: Real algorithmic differences emerge, elementwise typically wins</li>
</ul>
<h4 id="performance-insights-from-real-data"><a class="header" href="#performance-insights-from-real-data"><strong>Performance insights from real data:</strong></a></h4>
<ul>
<li><strong>Parallelism beats optimization</strong>: For memory-bound workloads, more threads &gt; complex memory patterns</li>
<li><strong>Launch overhead is significant</strong>: Small problems don’t reveal true algorithmic performance</li>
<li><strong>Framework intelligence</strong>: Mojo’s benchmark framework adapts iteration counts automatically (70-100)</li>
<li><strong>Memory bandwidth ceiling</strong>: All patterns hit similar performance walls at large scales</li>
</ul>
<h2 id="next-steps"><a class="header" href="#next-steps">Next steps</a></h2>
<p>With benchmarking mastery:</p>
<ul>
<li><strong>Profile real applications</strong>: Apply these patterns to actual workloads</li>
<li><strong>Advanced GPU patterns</strong>: Explore reductions, convolutions, and matrix operations</li>
<li><strong>Multi-GPU scaling</strong>: Understand distributed GPU computing patterns</li>
<li><strong>Memory optimization</strong>: Dive deeper into shared memory and advanced caching</li>
</ul>
<p>💡 <strong>Key takeaway</strong>: Benchmarking transforms theoretical understanding into practical performance optimization. Use empirical data to make informed decisions about which patterns work best for your specific hardware and workload characteristics.</p>
<h2 id="best-practices-summary"><a class="header" href="#best-practices-summary">Best practices summary</a></h2>
<p><strong>Benchmarking best practices:</strong></p>
<ul>
<li>Always warm up GPU before measuring</li>
<li>Run multiple iterations for statistical significance</li>
<li>Test across different problem sizes</li>
<li>Consider both peak and average performance</li>
<li>Account for real-world usage patterns</li>
</ul>
<p><strong>Performance optimization workflow:</strong></p>
<ol>
<li><strong>Profile first</strong>: Measure before optimizing</li>
<li><strong>Identify bottlenecks</strong>: Memory vs compute bound analysis</li>
<li><strong>Choose patterns</strong>: Based on workload characteristics</li>
<li><strong>Tune parameters</strong>: Optimize tile sizes and thread counts</li>
<li><strong>Validate</strong>: Confirm improvements with benchmarks</li>
</ol>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../puzzle_20/gpu-thread-vs-simd.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../puzzle_20/gpu-thread-vs-simd.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../theme/mojolang.js"></script>
        <script src="../theme/sidebar.js"></script>
        <script src="../theme/solution.js"></script>
        <script src="../theme/init-amplitude.js"></script>
        <script src="../theme/tabs.js"></script>


    </div>
    </body>
</html>
