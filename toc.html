<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- sidebar iframe generated using mdBook

        This is a frame, and not included directly in the page, to control the total size of the
        book. The TOC contains an entry for each page, so if each page includes a copy of the TOC,
        the total size of the page becomes O(n**2).

        The frame is only used as a fallback when JS is turned off. When it's on, the sidebar is
        instead added to the main page by `toc.js` instead. The JavaScript mode is better
        because, when running in a `file:///` URL, the iframed page would not be Same-Origin as
        the rest of the page, so the sidebar and the main page theme would fall out of sync.
        -->
        <meta charset="UTF-8">
        <meta name="robots" content="noindex">
        <!-- Custom HTML head -->
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,100..700;1,100..700&display=swap"
            rel="stylesheet">
        
        <script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
        
        <link rel="stylesheet" href="theme/css/custom.css">
        <link rel="stylesheet" href="theme/css/highlight.css">
        <link rel="stylesheet" id="theme">
        
        <!-- Additional meta tags -->
        <meta property="og:title" content="MojoğŸ”¥ GPU Puzzles">
        <meta property="og:description" content="Learn GPU Programming in MojoğŸ”¥ Through Interactive Puzzles">
        <meta property="og:image" content="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">
        <meta property="og:url" content="https://puzzles.modular.com/puzzles">
        <meta name="twitter:card" content="summary">
        <meta name="twitter:image:alt" content="Mojo GPU Puzzles Logo">
        <meta name="twitter:title" content="MojoğŸ”¥ GPU Puzzles">
        <meta name="twitter:description" content="Learn GPU Programming in MojoğŸ”¥ Through Interactive Puzzles">
        <meta name="twitter:image" content="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">
        <link rel="icon" type="image/png" href="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="theme/css/custom.css">
        <link rel="stylesheet" href="theme/css/highlight.css">
        <link rel="stylesheet" href="theme/css/tabs.css">
    </head>
    <body class="sidebar-iframe-inner">
        <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">Getting Started</li><li class="chapter-item expanded "><a href="introduction.html" target="_parent">ğŸ”¥ Introduction</a></li><li class="chapter-item expanded "><a href="howto.html" target="_parent">ğŸ§­ Puzzles Usage Guide</a></li><li class="chapter-item expanded affix "><li class="part-title">Part I: GPU Fundamentals</li><li class="chapter-item expanded "><a href="puzzle_01/puzzle_01.html" target="_parent">Puzzle 1: Map</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_01/raw.html" target="_parent">ğŸ”° Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_01/layout_tensor_preview.html" target="_parent">ğŸ’¡ Preview: Modern Approach with LayoutTensor</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_02/puzzle_02.html" target="_parent">Puzzle 2: Zip</a></li><li class="chapter-item expanded "><a href="puzzle_03/puzzle_03.html" target="_parent">Puzzle 3: Guards</a></li><li class="chapter-item expanded "><a href="puzzle_04/puzzle_04.html" target="_parent">Puzzle 4: 2D Map</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_04/raw.html" target="_parent">ğŸ”° Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_04/introduction_layout_tensor.html" target="_parent">ğŸ“š Learn about LayoutTensor</a></li><li class="chapter-item expanded "><a href="puzzle_04/layout_tensor.html" target="_parent">ğŸš€ Modern 2D Operations</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_05/puzzle_05.html" target="_parent">Puzzle 5: Broadcast</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_05/raw.html" target="_parent">ğŸ”° Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_05/layout_tensor.html" target="_parent">ğŸ“ LayoutTensor Version</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_06/puzzle_06.html" target="_parent">Puzzle 6: Blocks</a></li><li class="chapter-item expanded "><a href="puzzle_07/puzzle_07.html" target="_parent">Puzzle 7: 2D Blocks</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_07/raw.html" target="_parent">ğŸ”° Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_07/layout_tensor.html" target="_parent">ğŸ“ LayoutTensor Version</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_08/puzzle_08.html" target="_parent">Puzzle 8: Shared Memory</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_08/raw.html" target="_parent">ğŸ”° Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_08/layout_tensor.html" target="_parent">ğŸ“ LayoutTensor Version</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part II: ğŸ§® GPU Algorithms</li><li class="chapter-item expanded "><a href="puzzle_09/puzzle_09.html" target="_parent">Puzzle 9: Pooling</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_09/raw.html" target="_parent">ğŸ”° Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_09/layout_tensor.html" target="_parent">ğŸ“ LayoutTensor Version</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_10/puzzle_10.html" target="_parent">Puzzle 10: Dot Product</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_10/raw.html" target="_parent">ğŸ”° Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_10/layout_tensor.html" target="_parent">ğŸ“ LayoutTensor Version</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_11/puzzle_11.html" target="_parent">Puzzle 11: 1D Convolution</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_11/simple.html" target="_parent">ğŸ”° Simple Version</a></li><li class="chapter-item expanded "><a href="puzzle_11/block_boundary.html" target="_parent">â­ Block Boundary Version</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_12/puzzle_12.html" target="_parent">Puzzle 12: Prefix Sum</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_12/simple.html" target="_parent">ğŸ”° Simple Version</a></li><li class="chapter-item expanded "><a href="puzzle_12/complete.html" target="_parent">â­ Complete Version</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_13/puzzle_13.html" target="_parent">Puzzle 13: Axis Sum</a></li><li class="chapter-item expanded "><a href="puzzle_14/puzzle_14.html" target="_parent">Puzzle 14: Matrix Multiplication (MatMul)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_14/naÃ¯ve.html" target="_parent">ğŸ”° NaÃ¯ve Version with Global Memory</a></li><li class="chapter-item expanded "><a href="puzzle_14/roofline.html" target="_parent">ğŸ“š Learn about Roofline Model</a></li><li class="chapter-item expanded "><a href="puzzle_14/shared_memory.html" target="_parent">ğŸ¤ Shared Memory Version</a></li><li class="chapter-item expanded "><a href="puzzle_14/tiled.html" target="_parent">ğŸ“ Tiled Version</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part III: ğŸ Interfacing with Python via MAX Graph Custom Ops</li><li class="chapter-item expanded "><a href="puzzle_15/puzzle_15.html" target="_parent">Puzzle 15: 1D Convolution Op</a></li><li class="chapter-item expanded "><a href="puzzle_16/puzzle_16.html" target="_parent">Puzzle 16: Softmax Op</a></li><li class="chapter-item expanded "><a href="puzzle_17/puzzle_17.html" target="_parent">Puzzle 17: Attention Op</a></li><li class="chapter-item expanded "><a href="bonuses/part3.html" target="_parent">ğŸ¯ Bonus Challenges</a></li><li class="chapter-item expanded affix "><li class="part-title">Part IV: ğŸ”¥ PyTorch Custom Ops Integration</li><li class="chapter-item expanded "><a href="puzzle_18/puzzle_18.html" target="_parent">Puzzle 18: 1D Convolution Op</a></li><li class="chapter-item expanded "><a href="puzzle_19/puzzle_19.html" target="_parent">Puzzle 19: Embedding Op</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_19/simple_embedding_kernel.html" target="_parent">ğŸ”° Coaleasced vs non-Coaleasced Kernel</a></li><li class="chapter-item expanded "><a href="puzzle_19/performance.html" target="_parent">ğŸ“Š Performance Comparison</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_20/puzzle_20.html" target="_parent">Puzzle 20: Kernel Fusion and Custom Backward Pass</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_20/forward_pass.html" target="_parent">âš›ï¸ Fused vs Unfused Kernels</a></li><li class="chapter-item expanded "><a href="puzzle_20/backward_pass.html" target="_parent">â›“ï¸ Autograd Integration &amp; Backward Pass</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part V: ğŸŒŠ Mojo Functional Patterns and Benchmarking</li><li class="chapter-item expanded "><a href="puzzle_21/puzzle_21.html" target="_parent">Puzzle 21: GPU Functional Programming Patterns</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_21/elementwise.html" target="_parent">elementwise - Basic GPU Functional Operations</a></li><li class="chapter-item expanded "><a href="puzzle_21/tile.html" target="_parent">tile - Memory-Efficient Tiled Processing</a></li><li class="chapter-item expanded "><a href="puzzle_21/vectorize.html" target="_parent">Vectorization - SIMD Control</a></li><li class="chapter-item expanded "><a href="puzzle_21/gpu-thread-vs-simd.html" target="_parent">ğŸ§  GPU Threading vs SIMD Concepts</a></li><li class="chapter-item expanded "><a href="puzzle_21/benchmarking.html" target="_parent">ğŸ“Š Benchmarking in Mojo</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part VI: âš¡ Warp-Level Programming</li><li class="chapter-item expanded "><a href="puzzle_22/puzzle_22.html" target="_parent">Puzzle 22: Warp Fundamentals</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_22/warp_simt.html" target="_parent">ğŸ§  Warp lanes &amp; SIMT execution</a></li><li class="chapter-item expanded "><a href="puzzle_22/warp_sum.html" target="_parent">ğŸ”° warp.sum() Essentials</a></li><li class="chapter-item expanded "><a href="puzzle_22/warp_extra.html" target="_parent">ğŸ“Š When to Use Warp Programming</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_23/puzzle_23.html" target="_parent">Puzzle 23: Warp Communication</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_23/warp_shuffle_down.html" target="_parent">â¬‡ï¸ warp.shuffle_down()</a></li><li class="chapter-item expanded "><a href="puzzle_23/warp_broadcast.html" target="_parent">ğŸ“¢ warp.broadcast()</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_24/puzzle_24.html" target="_parent">Puzzle 24: Advanced Warp Patterns</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_24/warp_shuffle_xor.html" target="_parent">ğŸ¦‹ warp.shuffle_xor() Butterfly Networks</a></li><li class="chapter-item expanded "><a href="puzzle_24/warp_prefix_sum.html" target="_parent">ğŸ”¢ warp.prefix_sum() Scan Operations</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part VII: Advanced Memory Systems</li><li class="chapter-item expanded "><a href="puzzle_25/puzzle_25.html" target="_parent">Puzzle 25: Async Memory Operations &amp; Copy Overlap</a></li><li class="chapter-item expanded "><div>Puzzle 26: GPU Synchronization Primitives</div></li><li><ol class="section"><li class="chapter-item expanded "><div>ğŸ”„ Block Barriers &amp; Thread Synchronization</div></li><li class="chapter-item expanded "><div>ğŸ”’ Device-Wide Semaphores</div></li><li class="chapter-item expanded "><div>ğŸ›¡ï¸ Memory Fences &amp; Consistency Models</div></li></ol></li><li class="chapter-item expanded "><div>Puzzle 27: Advanced Memory Optimization</div></li><li><ol class="section"><li class="chapter-item expanded "><div>ğŸ’¾ Cache Control &amp; Memory Policies</div></li><li class="chapter-item expanded "><div>ğŸ›¡ï¸ Advanced Memory Fences &amp; Ordering</div></li><li class="chapter-item expanded "><div>âš¡ Essential TMA Operations (H100+)</div></li><li class="chapter-item expanded "><div>ğŸ”¬ Memory Access Pattern Optimization</div></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part VIII: ğŸ“Š Performance Analysis &amp; Optimization</li><li class="chapter-item expanded "><div>Puzzle 28: GPU Profiling Basics</div></li><li class="chapter-item expanded "><div>Puzzle 29: Occupancy Optimization</div></li><li class="chapter-item expanded "><div>Puzzle 30: Bank Conflicts</div></li><li><ol class="section"><li class="chapter-item expanded "><div>ğŸ“š Understanding Shared Memory Banks</div></li><li class="chapter-item expanded "><div>Conflict-Free Patterns</div></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part IX: ğŸš€ Advanced GPU Features</li><li class="chapter-item expanded "><div>Puzzle 31: Tensor Core Operations</div></li><li class="chapter-item expanded "><div>Puzzle 32: Random Number Generation</div></li><li class="chapter-item expanded "><div>Puzzle 33: Advanced Synchronization</div></li><li class="chapter-item expanded affix "><li class="part-title">Part X: ğŸŒ Multi-GPU &amp; Advanced Applications</li><li class="chapter-item expanded "><div>Puzzle 34: Multi-Stream Programming</div></li><li class="chapter-item expanded "><div>Puzzle 35: Multi-GPU Basics</div></li><li class="chapter-item expanded "><div>Puzzle 36: End-to-End Optimization Case Study</div></li><li class="chapter-item expanded "><div>ğŸ¯ Advanced Bonus Challenges</div></li></ol>
    </body>
</html>
