<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>🕵 The Cache Hit Paradox - Mojo 🔥 GPU Puzzles</title>


        <!-- Custom HTML head -->
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,100..700;1,100..700&display=swap"
            rel="stylesheet">
        
        <script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
        
        <link rel="stylesheet" href="../theme/css/custom.css">
        <link rel="stylesheet" href="../theme/css/highlight.css">
        <link rel="stylesheet" id="theme">
        
        <!-- Additional meta tags -->
        <meta property="og:title" content="Mojo🔥 GPU Puzzles">
        <meta property="og:description" content="Learn GPU Programming in Mojo🔥 Through Interactive Puzzles">
        <meta property="og:image" content="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">
        <meta property="og:url" content="https://puzzles.modular.com/">
        <meta name="twitter:card" content="summary">
        <meta name="twitter:image:alt" content="Mojo GPU Puzzles Logo">
        <meta name="twitter:title" content="Mojo🔥 GPU Puzzles">
        <meta name="twitter:description" content="Learn GPU Programming in Mojo🔥 Through Interactive Puzzles">
        <meta name="twitter:image" content="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">
        <link rel="icon" type="image/png" href="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&display=swap" rel="stylesheet">

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../theme/css/custom.css">
        <link rel="stylesheet" href="../theme/css/highlight.css">
        <link rel="stylesheet" href="../theme/css/tabs.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "ayu";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <button class="collapse-sidebar" aria-label="Collapse sidebar"></button>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Toggle color mode and talk to us buttons -->
        <script>
            document.addEventListener('click', function (event) {
                if (!event.target.matches('.theme-toggle')) return;
                event.preventDefault();
                const prevTheme = theme;
                html.classList.remove(theme);
                const newTheme = prevTheme === 'ayu' ? 'light' : 'ayu'
                html.classList.add(newTheme);
                theme = newTheme
                localStorage.setItem('mdbook-theme', theme);
            }, false);
            document.addEventListener('click', function() {
                if (!event.target.matches('.log-in')) return;
                event.preventDefault();
                window.amplitude.logEvent('LoginClickedFromPuzzles');
                window.open('https://developer.modular.com', '_blank');
            });
        </script>

        <div class="page-header">
            <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                <i class="fa fa-bars"></i>
            </label>
            <div id="menu-bar" class="menu-bar">
                <div class="left-buttons">
                    <div class="logo-section">
                        <a class="desktop-logo-link" href="https://modular.com"></a>
                        <a class="mobile-logo-link" href="https://builds.modular.com"></a>
                        <div class="slash">/</div>
                        <a class="internal-link" ref="/">Puzzles</a>
                    </div>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Dark</button></li>
                        </ul>
                    </div>
                <div class="right-buttons">
                    <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                        <i class="fa fa-search"></i>
                    </button>
                    <button id="theme-toggle" class="icon-button theme-toggle-btn" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="false" aria-expanded="false">
                        <i class="theme-toggle"></i>
                    </button>
                    <a class="menu-btn print" href="../print.html" title="Print this book" aria-label="Print this book">
                        <i id="print-button" class="fa fa-print"></i>
                    </a>
                    <a class="menu-btn" href="https://github.com/modular/mojo-gpu-puzzles" title="Git repository" aria-label="Git repository">
                        <i id="git-repository-button" class="fa fa-github"></i>
                    </a>
                    <button class="secondary-btn log-in">Log in</button>
                </div>
            </div>
        </div>

        <div id="page-wrapper" class="page-wrapper">
            <div class="page">

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <div id="content" class="content">
                    <main>
                        <h1 id="-the-cache-hit-paradox"><a class="header" href="#-the-cache-hit-paradox">🕵 The Cache Hit Paradox</a></h1>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Welcome to your first <strong>profiling detective case</strong>! You have three GPU kernels that all compute the same simple vector addition: <code>output[i] = a[i] + b[i]</code>. They should all perform identically, right?</p>
<p><strong>Wrong!</strong> These kernels have dramatically different performance - one is <strong>orders of magnitude slower</strong> than the others. Your mission: use the <a href="./nvidia_profiling_basics.html">profiling tools</a> you just learned to discover <strong>why</strong>.</p>
<h2 id="the-challenge"><a class="header" href="#the-challenge">The challenge</a></h2>
<p>Welcome to a <strong>performance mystery</strong> that will challenge everything you think you know about GPU optimization! You’re confronted with three seemingly identical vector addition kernels that compute the exact same mathematical operation:</p>
<pre><code>output[i] = a[i] + b[i]  // Simple arithmetic - what could go wrong?
</code></pre>
<p><strong>The shocking reality:</strong></p>
<ul>
<li><strong>All three kernels produce identical, correct results</strong></li>
<li><strong>One kernel runs ~50x slower than the others</strong></li>
<li><strong>The slowest kernel has the highest cache hit rates</strong> (counterintuitive!)</li>
<li><strong>Standard performance intuition completely fails</strong></li>
</ul>
<p><strong>Your detective mission:</strong></p>
<ol>
<li><strong>Identify the performance culprit</strong> - Which kernel is catastrophically slow?</li>
<li><strong>Uncover the cache paradox</strong> - Why do high cache hits indicate poor performance?</li>
<li><strong>Decode memory access patterns</strong> - What makes identical operations behave so differently?</li>
<li><strong>Master profiling methodology</strong> - Use NSight tools to gather evidence, not guesses</li>
</ol>
<p><strong>Why this matters:</strong> This puzzle reveals a fundamental GPU performance principle that challenges CPU-based intuition. The skills you develop here apply to real-world GPU optimization where memory access patterns often matter more than algorithmic complexity.</p>
<p><strong>The twist:</strong> We approach this <strong>without looking at the source code first</strong> - using only profiling tools as your guide, just like debugging production performance issues. After we obtained the profiling results, we look at the code for further analysis.</p>
<h2 id="your-detective-toolkit"><a class="header" href="#your-detective-toolkit">Your detective toolkit</a></h2>
<p>From the profiling tutorial, you have:</p>
<ul>
<li><strong>NSight Systems (<code>nsys</code>)</strong> - Find which kernels are slow</li>
<li><strong>NSight Compute (<code>ncu</code>)</strong> - Analyze why kernels are slow</li>
<li><strong>Memory efficiency metrics</strong> - Detect poor access patterns</li>
</ul>
<h2 id="getting-started"><a class="header" href="#getting-started">Getting started</a></h2>
<h3 id="step-1-run-the-benchmark"><a class="header" href="#step-1-run-the-benchmark">Step 1: Run the benchmark</a></h3>
<pre><code class="language-bash">pixi shell -e nvidia
mojo problems/p30/p30.mojo --benchmark
</code></pre>
<p>You’ll see dramatic timing differences between kernels! One kernel is <strong>much slower</strong> than the others. Your job is to figure out why using profiling tools <strong>without</strong> looking at the code.</p>
<p><strong>Example output:</strong></p>
<pre><code>| name    | met (ms)  | iters |
| ------- | --------- | ----- |
| kernel1 | 171.85    | 11    |
| kernel2 | 1546.68   | 11    |  &lt;- This one is much slower!
| kernel3 | 172.18    | 11    |
</code></pre>
<h3 id="step-2-prepare-your-code-for-profiling"><a class="header" href="#step-2-prepare-your-code-for-profiling">Step 2: Prepare your code for profiling</a></h3>
<p><strong>Critical</strong>: For accurate profiling, build with full debug information while keeping optimizations enabled:</p>
<pre><code class="language-bash">mojo build --debug-level=full problems/p30/p30.mojo -o problems/p30/p30_profiler
</code></pre>
<p><strong>Why this matters</strong>:</p>
<ul>
<li><strong>Full debug info</strong>: Provides complete symbol tables, variable names, and source line mapping for profilers</li>
<li><strong>Comprehensive analysis</strong>: Enables NSight tools to correlate performance data with specific code locations</li>
<li><strong>Optimizations enabled</strong>: Ensures realistic performance measurements that match production builds</li>
</ul>
<h2 id="step-3-system-wide-investigation-nsight-systems"><a class="header" href="#step-3-system-wide-investigation-nsight-systems">Step 3: System-wide investigation (NSight Systems)</a></h2>
<p>Profile each kernel to see the big picture:</p>
<pre><code class="language-bash"># Profile each kernel individually using the optimized build (with warmup to avoid cold start effects)
nsys profile --trace=cuda,osrt,nvtx --delay=2 --output=./problems/p30/kernel1_profile ./problems/p30/p30_profiler --kernel1
nsys profile --trace=cuda,osrt,nvtx --delay=2 --output=./problems/p30/kernel2_profile ./problems/p30/p30_profiler --kernel2
nsys profile --trace=cuda,osrt,nvtx --delay=2 --output=./problems/p30/kernel3_profile ./problems/p30/p30_profiler --kernel3

# Analyze the results
nsys stats --force-export=true ./problems/p30/kernel1_profile.nsys-rep &gt; ./problems/p30/kernel1_profile.txt
nsys stats --force-export=true ./problems/p30/kernel2_profile.nsys-rep &gt; ./problems/p30/kernel2_profile.txt
nsys stats --force-export=true ./problems/p30/kernel3_profile.nsys-rep &gt; ./problems/p30/kernel3_profile.txt
</code></pre>
<p><strong>Look for:</strong></p>
<ul>
<li><strong>GPU Kernel Summary</strong> - Which kernels take longest?</li>
<li><strong>Kernel execution times</strong> - How much do they vary?</li>
<li><strong>Memory transfer patterns</strong> - Are they similar across implementations?</li>
</ul>
<h2 id="step-4-kernel-deep-dive-nsight-compute"><a class="header" href="#step-4-kernel-deep-dive-nsight-compute">Step 4: Kernel deep-dive (NSight Compute)</a></h2>
<p>Once you identify the slow kernel, analyze it with NSight Compute:</p>
<pre><code class="language-bash"># Deep-dive into memory patterns for each kernel using the optimized build
ncu --set=@roofline --section=MemoryWorkloadAnalysis -f -o ./problems/p30/kernel1_analysis ./problems/p30/p30_profiler --kernel1
ncu --set=@roofline --section=MemoryWorkloadAnalysis -f -o ./problems/p30/kernel2_analysis ./problems/p30/p30_profiler --kernel2
ncu --set=@roofline --section=MemoryWorkloadAnalysis -f -o ./problems/p30/kernel3_analysis ./problems/p30/p30_profiler --kernel3

# View the results
ncu --import ./problems/p30/kernel1_analysis.ncu-rep --page details
ncu --import ./problems/p30/kernel2_analysis.ncu-rep --page details
ncu --import ./problems/p30/kernel3_analysis.ncu-rep --page details
</code></pre>
<p><strong>When you run these commands, you’ll see output like this:</strong></p>
<pre><code>Kernel1: Memory Throughput: ~308 Gbyte/s, Max Bandwidth: ~51%
Kernel2: Memory Throughput: ~6 Gbyte/s,   Max Bandwidth: ~12%
Kernel3: Memory Throughput: ~310 Gbyte/s, Max Bandwidth: ~52%
</code></pre>
<p><strong>Key metrics to investigate:</strong></p>
<ul>
<li><strong>Memory Throughput (Gbyte/s)</strong> - Actual memory bandwidth achieved</li>
<li><strong>Max Bandwidth (%)</strong> - Percentage of theoretical peak bandwidth utilized</li>
<li><strong>L1/TEX Hit Rate (%)</strong> - L1 cache efficiency</li>
<li><strong>L2 Hit Rate (%)</strong> - L2 cache efficiency</li>
</ul>
<p><strong>🤔 The Counterintuitive Result</strong>: You’ll notice Kernel2 has the <strong>highest</strong> cache hit rates but the <strong>lowest</strong> performance! This is the key mystery to solve.</p>
<h2 id="step-5-detective-questions"><a class="header" href="#step-5-detective-questions">Step 5: Detective questions</a></h2>
<p>Use your profiling evidence to answer these questions by looking at the kernel code <a href="https://github.com/modular/mojo-gpu-puzzles/blob/main/problems/p30/p30.mojo" class="filename">problems/p30/p30.mojo</a>:</p>
<h3 id="performance-analysis"><a class="header" href="#performance-analysis">Performance Analysis</a></h3>
<ol>
<li><strong>Which kernel achieves the highest Memory Throughput?</strong> (Look at Gbyte/s values)</li>
<li><strong>Which kernel has the lowest Max Bandwidth utilization?</strong> (Compare percentages)</li>
<li><strong>What’s the performance gap in memory throughput?</strong> (Factor difference between fastest and slowest)</li>
</ol>
<h3 id="the-cache-paradox"><a class="header" href="#the-cache-paradox">The Cache Paradox</a></h3>
<ol start="4">
<li><strong>Which kernel has the highest L1/TEX Hit Rate?</strong></li>
<li><strong>Which kernel has the highest L2 Hit Rate?</strong></li>
<li><strong>🤯 Why does the kernel with the BEST cache hit rates perform the WORST?</strong></li>
</ol>
<h3 id="memory-access-detective-work"><a class="header" href="#memory-access-detective-work">Memory Access Detective Work</a></h3>
<ol start="7">
<li><strong>Can high cache hit rates actually indicate a performance problem?</strong></li>
<li><strong>What memory access pattern would cause high cache hits but low throughput?</strong></li>
<li><strong>Why might “efficient caching” be a symptom of “inefficient memory access”?</strong></li>
</ol>
<h3 id="the-aha-moment"><a class="header" href="#the-aha-moment">The “Aha!” Moment</a></h3>
<ol start="10">
<li><strong>Based on the profiling evidence, what fundamental GPU memory principle does this demonstrate?</strong></li>
</ol>
<p><strong>Key insight to discover</strong>: Sometimes <strong>high cache hit rates are a red flag</strong>, not a performance victory!</p>
<h2 id="solution"><a class="header" href="#solution">Solution</a></h2>
<p>The mystery reveals a fundamental GPU performance principle: <strong>memory access patterns dominate performance for memory-bound operations</strong>, even when kernels perform identical computations.</p>
<p><strong>The profiling evidence reveals:</strong></p>
<ol>
<li><strong>Performance hierarchy</strong>: Kernel1 and Kernel3 are fast, Kernel2 is catastrophically slow (orders of magnitude difference)</li>
<li><strong>Memory throughput tells the story</strong>: Fast kernels achieve high bandwidth utilization, slow kernel achieves minimal utilization</li>
<li><strong>The cache paradox</strong>: The slowest kernel has the <strong>highest</strong> cache hit rates - revealing that high cache hits can indicate <strong>poor</strong> memory access patterns</li>
<li><strong>Memory access patterns matter more than algorithmic complexity</strong> for memory-bound GPU workloads</li>
</ol>
<details class="solution-details">
<summary><strong>Complete Solution with Enhanced Explanation</strong></summary>
<p>This profiling detective case demonstrates how memory access patterns create orders-of-magnitude performance differences, even when kernels perform identical mathematical operations.</p>
<h2 id="performance-evidence-from-profiling"><a class="header" href="#performance-evidence-from-profiling"><strong>Performance evidence from profiling</strong></a></h2>
<p><strong>NSight Systems Timeline Analysis:</strong></p>
<ul>
<li><strong>Kernel 1</strong>: Short execution time - <strong>EFFICIENT</strong></li>
<li><strong>Kernel 3</strong>: Similar to Kernel 1 - <strong>EFFICIENT</strong></li>
<li><strong>Kernel 2</strong>: Dramatically longer execution time - <strong>INEFFICIENT</strong></li>
</ul>
<p><strong>NSight Compute Memory Analysis (Hardware-Agnostic Patterns):</strong></p>
<ul>
<li><strong>Efficient kernels (1 &amp; 3)</strong>: High memory throughput, good bandwidth utilization, moderate cache hit rates</li>
<li><strong>Inefficient kernel (2)</strong>: Very low memory throughput, poor bandwidth utilization, <strong>extremely high cache hit rates</strong></li>
</ul>
<h2 id="the-cache-paradox-revealed"><a class="header" href="#the-cache-paradox-revealed"><strong>The cache paradox revealed</strong></a></h2>
<p><strong>🤯 The Counterintuitive Discovery:</strong></p>
<ul>
<li><strong>Kernel2 has the HIGHEST cache hit rates</strong> but <strong>WORST performance</strong></li>
<li><strong>This challenges conventional wisdom</strong>: “High cache hits = good performance”</li>
<li><strong>The truth</strong>: High cache hit rates can be a <strong>symptom of inefficient memory access patterns</strong></li>
</ul>
<p><strong>Why the Cache Paradox Occurs:</strong></p>
<p><strong>Traditional CPU intuition (INCORRECT for GPUs):</strong></p>
<ul>
<li>Higher cache hit rates always mean better performance</li>
<li>Cache hits reduce memory traffic, improving efficiency</li>
</ul>
<p><strong>GPU memory reality (CORRECT understanding):</strong></p>
<ul>
<li><strong>Coalescing matters more than caching</strong> for memory-bound workloads</li>
<li><strong>Poor access patterns</strong> can cause artificial cache hit inflation</li>
<li><strong>Memory bandwidth utilization</strong> is the real performance indicator</li>
</ul>
<h2 id="root-cause-analysis---memory-access-patterns"><a class="header" href="#root-cause-analysis---memory-access-patterns"><strong>Root cause analysis - memory access patterns</strong></a></h2>
<p><strong>Actual Kernel Implementations from p30.mojo:</strong></p>
<p><strong>Kernel 1 - Efficient Coalesced Access:</strong></p>
<pre><code class="language-mojo">fn kernel1[
    layout: Layout
](
    output: LayoutTensor[mut=True, dtype, layout],
    a: LayoutTensor[mut=False, dtype, layout],
    b: LayoutTensor[mut=False, dtype, layout],
    size: Int,
):
    i = block_dim.x * block_idx.x + thread_idx.x
    if i &lt; size:
        output[i] = a[i] + b[i]


</code></pre>
<p><em>Standard thread indexing - adjacent threads access adjacent memory</em></p>
<p><strong>Kernel 2 - Inefficient Strided Access:</strong></p>
<pre><code class="language-mojo">fn kernel2[
    layout: Layout
](
    output: LayoutTensor[mut=True, dtype, layout],
    a: LayoutTensor[mut=False, dtype, layout],
    b: LayoutTensor[mut=False, dtype, layout],
    size: Int,
):
    tid = block_idx.x * block_dim.x + thread_idx.x
    stride = 512

    i = tid
    while i &lt; size:
        output[i] = a[i] + b[i]
        i += stride


</code></pre>
<p><em>Large stride=512 creates memory access gaps - same operation but scattered access</em></p>
<p><strong>Kernel 3 - Efficient Reverse Access:</strong></p>
<pre><code class="language-mojo">fn kernel3[
    layout: Layout
](
    output: LayoutTensor[mut=True, dtype, layout],
    a: LayoutTensor[mut=False, dtype, layout],
    b: LayoutTensor[mut=False, dtype, layout],
    size: Int,
):
    tid = block_idx.x * block_dim.x + thread_idx.x
    total_threads = (SIZE // 1024) * 1024

    for step in range(0, size, total_threads):
        forward_i = step + tid
        if forward_i &lt; size:
            reverse_i = size - 1 - forward_i
            output[reverse_i] = a[reverse_i] + b[reverse_i]


</code></pre>
<p><em>Reverse indexing but still predictable - adjacent threads access adjacent addresses (just backwards)</em></p>
<p><strong>Pattern Analysis:</strong></p>
<ul>
<li><strong>Kernel 1</strong>: Classic coalesced access - adjacent threads access adjacent memory</li>
<li><strong>Kernel 2</strong>: Catastrophic strided access - threads jump by 512 elements</li>
<li><strong>Kernel 3</strong>: Reverse but still coalesced within warps - predictable pattern</li>
</ul>
<h2 id="understanding-the-memory-system"><a class="header" href="#understanding-the-memory-system"><strong>Understanding the memory system</strong></a></h2>
<p><strong>GPU Memory Architecture Fundamentals:</strong></p>
<ul>
<li><strong>Warp execution</strong>: 32 threads execute together</li>
<li><strong>Cache line size</strong>: 128 bytes (32 float32 values)</li>
<li><strong>Coalescing requirement</strong>: Adjacent threads should access adjacent memory</li>
</ul>
<p><strong>p30.mojo Configuration Details:</strong></p>
<pre><code class="language-mojo">alias SIZE = 16 * 1024 * 1024          # 16M elements (64MB of float32 data)
alias THREADS_PER_BLOCK = (1024, 1)    # 1024 threads per block
alias BLOCKS_PER_GRID = (SIZE // 1024, 1)  # 16,384 blocks total
alias dtype = DType.float32             # 4 bytes per element
</code></pre>
<p><strong>Why these settings matter:</strong></p>
<ul>
<li><strong>Large dataset (16M)</strong>: Makes memory access patterns clearly visible</li>
<li><strong>1024 threads/block</strong>: Maximum CUDA threads per block</li>
<li><strong>32 warps/block</strong>: Each block contains 32 warps of 32 threads each</li>
</ul>
<p><strong>Memory Access Efficiency Visualization:</strong></p>
<pre><code>KERNEL 1 (Coalesced):           KERNEL 2 (Strided by 512):
Warp threads 0-31:             Warp threads 0-31:
  Thread 0: Memory[0]            Thread 0: Memory[0]
  Thread 1: Memory[1]            Thread 1: Memory[512]
  Thread 2: Memory[2]            Thread 2: Memory[1024]
  ...                           ...
  Thread 31: Memory[31]          Thread 31: Memory[15872]

Result: 1 cache line fetch       Result: 32 separate cache line fetches
Status: ~308 GB/s throughput     Status: ~6 GB/s throughput
Cache: Efficient utilization     Cache: Same lines hit repeatedly!
</code></pre>
<p><strong>KERNEL 3 (Reverse but Coalesced):</strong></p>
<pre><code>Warp threads 0-31 (first iteration):
  Thread 0: Memory[SIZE-1]     (reverse_i = SIZE-1-0)
  Thread 1: Memory[SIZE-2]     (reverse_i = SIZE-1-1)
  Thread 2: Memory[SIZE-3]     (reverse_i = SIZE-1-2)
  ...
  Thread 31: Memory[SIZE-32]   (reverse_i = SIZE-1-31)

Result: Adjacent addresses (just backwards)
Status: ~310 GB/s throughput (nearly identical to Kernel 1)
Cache: Efficient utilization despite reverse order
</code></pre>
<h2 id="the-cache-paradox-explained"><a class="header" href="#the-cache-paradox-explained"><strong>The cache paradox explained</strong></a></h2>
<p><strong>Why Kernel2 (stride=512) has high cache hit rates but poor performance:</strong></p>
<p><strong>The stride=512 disaster explained:</strong></p>
<pre><code class="language-mojo"># Each thread processes multiple elements with huge gaps:
Thread 0: elements [0, 512, 1024, 1536, 2048, ...]
Thread 1: elements [1, 513, 1025, 1537, 2049, ...]
Thread 2: elements [2, 514, 1026, 1538, 2050, ...]
...
</code></pre>
<p><strong>Why this creates the cache paradox:</strong></p>
<ol>
<li><strong>Cache line repetition</strong>: Each 512-element jump stays within overlapping cache line regions</li>
<li><strong>False efficiency illusion</strong>: Same cache lines accessed repeatedly = artificially high “hit rates”</li>
<li><strong>Bandwidth catastrophe</strong>: 32 threads × 32 separate cache lines = massive memory traffic</li>
<li><strong>Warp execution mismatch</strong>: GPU designed for coalesced access, but getting scattered access</li>
</ol>
<p><strong>Concrete example with float32 (4 bytes each):</strong></p>
<ul>
<li><strong>Cache line</strong>: 128 bytes = 32 float32 values</li>
<li><strong>Stride 512</strong>: Thread jumps by 512×4 = 2048 bytes = 16 cache lines apart!</li>
<li><strong>Warp impact</strong>: 32 threads need 32 different cache lines instead of 1</li>
</ul>
<p><strong>The key insight</strong>: High cache hits in Kernel2 are <strong>repeated access to inefficiently fetched data</strong>, not smart caching!</p>
<h2 id="profiling-methodology-insights"><a class="header" href="#profiling-methodology-insights"><strong>Profiling methodology insights</strong></a></h2>
<p><strong>Systematic Detective Approach:</strong></p>
<p><strong>Phase 1: NSight Systems (Big Picture)</strong></p>
<ul>
<li>Identify which kernels are slow</li>
<li>Rule out obvious bottlenecks (memory transfers, API overhead)</li>
<li>Focus on kernel execution time differences</li>
</ul>
<p><strong>Phase 2: NSight Compute (Deep Analysis)</strong></p>
<ul>
<li>Analyze memory throughput metrics</li>
<li>Compare bandwidth utilization percentages</li>
<li>Investigate cache hit rates and patterns</li>
</ul>
<p><strong>Phase 3: Connect Evidence to Theory</strong></p>
<pre><code>PROFILING EVIDENCE → CODE ANALYSIS:

NSight Compute Results:           Actual Code Pattern:
- Kernel1: ~308 GB/s            → i = block_idx*block_dim + thread_idx (coalesced)
- Kernel2: ~6 GB/s, 99% L2 hits → i += 512 (catastrophic stride)
- Kernel3: ~310 GB/s            → reverse_i = size-1-forward_i (reverse coalesced)

The profiler data directly reveals the memory access efficiency!
</code></pre>
<p><strong>Evidence-to-Code Connection:</strong></p>
<ul>
<li><strong>High throughput + normal cache rates</strong> = Coalesced access (Kernels 1 &amp; 3)</li>
<li><strong>Low throughput + high cache rates</strong> = Inefficient strided access (Kernel 2)</li>
<li><strong>Memory bandwidth utilization</strong> reveals true efficiency regardless of cache statistics</li>
</ul>
<h2 id="real-world-performance-implications"><a class="header" href="#real-world-performance-implications"><strong>Real-world performance implications</strong></a></h2>
<p><strong>This pattern affects many GPU applications:</strong></p>
<p><strong>Scientific Computing:</strong></p>
<ul>
<li><strong>Stencil computations</strong>: Neighbor access patterns in grid simulations</li>
<li><strong>Linear algebra</strong>: Matrix traversal order (row-major vs column-major)</li>
<li><strong>PDE solvers</strong>: Grid point access patterns in finite difference methods</li>
</ul>
<p><strong>Graphics and Image Processing:</strong></p>
<ul>
<li><strong>Texture filtering</strong>: Sample access patterns in shaders</li>
<li><strong>Image convolution</strong>: Filter kernel memory access</li>
<li><strong>Color space conversion</strong>: Channel interleaving strategies</li>
</ul>
<p><strong>Machine Learning:</strong></p>
<ul>
<li><strong>Matrix operations</strong>: Memory layout optimization in GEMM</li>
<li><strong>Tensor contractions</strong>: Multi-dimensional array access patterns</li>
<li><strong>Data loading</strong>: Batch processing and preprocessing pipelines</li>
</ul>
<h2 id="fundamental-gpu-optimization-principles"><a class="header" href="#fundamental-gpu-optimization-principles"><strong>Fundamental GPU optimization principles</strong></a></h2>
<p><strong>Memory-First Optimization Strategy:</strong></p>
<ol>
<li><strong>Memory patterns dominate</strong>: Access patterns often matter more than algorithmic complexity</li>
<li><strong>Coalescing is critical</strong>: Design for adjacent threads accessing adjacent memory</li>
<li><strong>Measure bandwidth utilization</strong>: Focus on actual throughput, not just cache statistics</li>
<li><strong>Profile systematically</strong>: Use NSight tools to identify real bottlenecks</li>
</ol>
<p><strong>Key Technical Insights:</strong></p>
<ul>
<li><strong>Memory-bound workloads</strong>: Bandwidth utilization determines performance</li>
<li><strong>Cache metrics can mislead</strong>: High hit rates don’t always indicate efficiency</li>
<li><strong>Warp-level thinking</strong>: Design access patterns for 32-thread execution groups</li>
<li><strong>Hardware-aware programming</strong>: Understanding GPU memory hierarchy is essential</li>
</ul>
<h2 id="key-takeaways"><a class="header" href="#key-takeaways"><strong>Key takeaways</strong></a></h2>
<p>This detective case reveals that <strong>GPU performance optimization requires abandoning CPU intuition</strong> for <strong>memory-centric thinking</strong>:</p>
<p><strong>Critical insights:</strong></p>
<ul>
<li>High cache hit rates can indicate poor memory access patterns (not good performance)</li>
<li>Memory bandwidth utilization matters more than cache statistics</li>
<li>Simple coalesced patterns often outperform complex algorithms</li>
<li>Profiling tools reveal counterintuitive performance truths</li>
</ul>
<p><strong>Practical methodology:</strong></p>
<ul>
<li>Profile systematically with NSight Systems and NSight Compute</li>
<li>Design for adjacent threads accessing adjacent memory (coalescing)</li>
<li>Let profiler evidence guide optimization decisions, not intuition</li>
</ul>
<p>The cache paradox demonstrates that <strong>high-level metrics can mislead without architectural understanding</strong> - applicable far beyond GPU programming.</p>
</details>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../puzzle_30/nvidia_profiling_basics.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../puzzle_31/puzzle_31.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../puzzle_30/nvidia_profiling_basics.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../puzzle_31/puzzle_31.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../theme/mojolang.js"></script>
        <script src="../theme/sidebar.js"></script>
        <script src="../theme/solution.js"></script>
        <script src="../theme/init-amplitude.js"></script>
        <script src="../theme/tabs.js"></script>


    </div>
    </body>
</html>
