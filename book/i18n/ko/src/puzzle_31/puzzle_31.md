<!-- i18n-source-commit: 27670ce1d5fb537c6d9404b9fdb39dfc64468e3f -->

# Puzzle 31: 점유율 최적화

## 이 퍼즐이 중요한 이유

**Puzzle 30의 연장선:** [GPU 프로파일링](../puzzle_30/puzzle_30.md) 도구를 배우고, 메모리 접근 패턴이 어떻게 극적인 성능 차이를 만들어내는지 발견했습니다. 이제 다음 단계로 나아갈 준비가 되었습니다: **리소스 최적화**.

**학습 여정:**

- **Puzzle 30**에서는 NSight 프로파일링(`nsys`와 `ncu`)을 통해 성능 문제를 **진단**하는 법을 배웠습니다
- **Puzzle 31**에서는 리소스 관리를 통해 성능을 **예측하고 제어**하는 법을 배웁니다
- **둘을 합치면** GPU 최적화를 위한 완전한 도구 세트를 갖추게 됩니다

**발견하게 될 것:**
GPU 성능은 단순히 알고리즘 효율의 문제가 아닙니다 - **코드가 한정된 하드웨어 리소스를 어떻게 활용하느냐**가 핵심입니다. 모든 GPU는 유한한 레지스터, 공유 메모리, 실행 유닛을 갖고 있습니다. **점유율(occupancy)** - _SM당 활성 Warp 수 대비 최대 가능 Warp 수의 비율_ - 을 이해하는 것은 다음과 같은 이유로 중요합니다:

- **Latency hiding**: 메모리 대기 시간 동안 GPU가 유휴 상태에 빠지지 않도록 유지
- **리소스 할당**: 레지스터, 공유 메모리, 스레드 블록 간의 균형 조절
- **성능 예측**: 병목이 발생하기 전에 미리 파악
- **최적화 전략**: 점유율에 집중해야 할 때와 다른 요소에 집중해야 할 때 판단

**GPU를 넘어서 적용되는 원리:**
여기서 배우는 원리는 리소스를 여러 실행 유닛이 공유하는 모든 병렬 컴퓨팅 시스템에 적용됩니다 - 하이퍼스레딩을 사용하는 CPU부터 분산 컴퓨팅 클러스터까지.

## 개요

**GPU 점유율**은 SM당 활성 Warp 수 대비 최대 가능 Warp 수의 비율입니다. GPU가 Warp 전환을 통해 메모리 latency를 얼마나 효과적으로 숨길 수 있는지를 결정합니다.

**SAXPY**는 Single-precision Alpha times X plus Y의 약자입니다. 이 퍼즐에서는 수학적으로 동일하지만 리소스 사용이 다른 세 가지 SAXPY 커널(`y[i] = alpha * x[i] + y[i]`)을 탐구합니다:

```mojo
{{#include ../../../../../problems/p31/p31.mojo:minimal_kernel}}
```

<a href="{{#include ../_includes/repo_url.md}}/blob/main/problems/p31/p31.mojo" class="filename">전체 파일 보기: problems/p31/p31.mojo</a>

```mojo
{{#include ../../../../../problems/p31/p31.mojo:sophisticated_kernel}}
```

<a href="{{#include ../_includes/repo_url.md}}/blob/main/problems/p31/p31.mojo" class="filename">전체 파일 보기: problems/p31/p31.mojo</a>

```mojo
{{#include ../../../../../problems/p31/p31.mojo:balanced_kernel}}
```

<a href="{{#include ../_includes/repo_url.md}}/blob/main/problems/p31/p31.mojo" class="filename">전체 파일 보기: problems/p31/p31.mojo</a>

## 도전 과제

프로파일링 도구를 사용하여 세 커널을 조사하고, 점유율 최적화에 대한 분석 질문에 답하세요. 커널들은 동일한 결과를 계산하지만 리소스 사용이 극적으로 다릅니다 - 성능과 점유율이 왜 직관에 어긋나는 방식으로 동작하는지 발견하는 것이 여러분의 임무입니다!

> 이 퍼즐에 표시된 구체적인 수치 결과는 **NVIDIA A10G (Ampere 8.6)** 하드웨어를 기준으로 합니다. 결과는 GPU 제조사와 아키텍처(NVIDIA: Pascal/Turing/Ampere/Ada/Hopper, AMD: RDNA/GCN, Apple: M1/M2/M3/M4/M5)에 따라 달라지지만, **기본 개념, 방법론, 통찰은 모든 최신 GPU에 보편적으로 적용됩니다**. `pixi run gpu-specs`를 실행하여 하드웨어별 수치를 확인하세요.

## 구성

**요구 사항:**

- CUDA 툴킷이 설치된 NVIDIA GPU
- [Puzzle 30](../puzzle_30/puzzle_30.md)의 NSight Compute

> **⚠️ GPU 호환성 참고:**
> 기본 설정은 공격적인 값을 사용하므로 구형이나 저사양 GPU에서는 실패할 수 있습니다:
>
> ```mojo
> comptime SIZE = 32 * 1024 * 1024  # 32M 요소 (배열당 ~256MB 메모리)
> comptime THREADS_PER_BLOCK = (1024, 1)  # 블록당 1024 스레드
> comptime BLOCKS_PER_GRID = (SIZE // 1024, 1)  # 32768 블록
> ```
>
> **실행 실패 시 `problems/p31/p31.mojo`에서 다음 값을 줄이세요:**
>
> - **구형 GPU (Compute Capability < 3.0):** `THREADS_PER_BLOCK = (512, 1)`, `SIZE = 16 * 1024 * 1024` 사용
> - **메모리 제한 GPU (< 2GB):** `SIZE = 8 * 1024 * 1024` 또는 `SIZE = 4 * 1024 * 1024` 사용
> - **그리드 차원 제한:** `BLOCKS_PER_GRID`는 `SIZE`에 맞춰 자동 조정됩니다

**점유율 공식:**

```
이론적 점유율 = min(
    SM당 레지스터 수 / (스레드당 레지스터 수 × 블록당 스레드 수),
    SM당 공유 메모리 / 블록당 공유 메모리,
    SM당 최대 블록 수
) × 블록당 스레드 수 / SM당 최대 스레드 수
```

## 조사 과정

### Step 1: 커널 테스트

```bash
pixi shell -e nvidia
mojo problems/p31/p31.mojo --all
```

세 커널 모두 동일한 결과를 내야 합니다. 미스터리: 왜 성능은 다를까요?

### Step 2: 성능 벤치마크

```bash
mojo problems/p31/p31.mojo --benchmark
```

세 커널 모두 동일한 결과를 내야 합니다. 미스터리: 왜 성능은 다를까요?

### Step 3: 프로파일링용 빌드

```bash
mojo build --debug-level=full problems/p31/p31.mojo -o problems/p31/p31_profiler
```

### Step 4: 리소스 사용량 프로파일링

```bash
# 각 커널의 리소스 사용량 프로파일링
ncu --set=@occupancy --section=LaunchStats problems/p31/p31_profiler --minimal
ncu --set=@occupancy --section=LaunchStats problems/p31/p31_profiler --sophisticated
ncu --set=@occupancy --section=LaunchStats problems/p31/p31_profiler --balanced
```

점유율 분석을 위해 리소스 사용량을 기록하세요.

### Step 5: 이론적 점유율 계산

먼저 GPU 아키텍처와 세부 스펙을 확인합니다:

```bash
pixi run gpu-specs
```

**참고**: `gpu-specs`는 GPU 제조사(NVIDIA/AMD/Apple)를 자동 감지하고 하드웨어에서 파생된 **모든 아키텍처 세부 정보**를 표시합니다 - 별도의 참조표가 필요 없습니다!

**주요 아키텍처 스펙 (참고용):**

| 아키텍처 | Compute Cap | 레지스터/SM | 공유 메모리/SM | 최대 스레드/SM | 최대 블록/SM |
|--------------|-------------|--------------|---------------|----------------|---------------|
| **Hopper (H100)** | 9.0 | 65,536 | 228KB | 2,048 | 32 |
| **Ada (RTX 40xx)** | 8.9 | 65,536 | 128KB | 2,048 | 32 |
| **Ampere (RTX 30xx, A100, A10G)** | 8.0, 8.6 | 65,536 | 164KB | 2,048 | 32 |
| **Turing (RTX 20xx)** | 7.5 | 65,536 | 96KB | 1,024 | 16 |
| **Pascal (GTX 10xx)** | 6.1 | 65,536 | 96KB | 2,048 | 32 |

**📚 공식 문서:**

- [NVIDIA CUDA Compute Capability Table](https://developer.nvidia.com/cuda-gpus)
- [CUDA Programming Guide - Compute Capabilities](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities)
- [Hopper Architecture In-Depth](https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/)
- [Ampere Architecture Whitepaper](https://developer.nvidia.com/ampere-architecture)

**⚠️ 참고:** 이 값들은 이론적 최대치입니다. 실제 점유율은 하드웨어 스케줄링 제약, 드라이버 오버헤드 등의 요인으로 더 낮을 수 있습니다.

GPU 스펙과 점유율 공식을 사용하여:

- **블록당 스레드 수:** 1024 (커널 설정값)

점유율 공식과 하드웨어 스펙을 사용하여 각 커널의 이론적 점유율을 예측하세요.

### Step 6: 실제 점유율 측정

```bash
# 각 커널의 실제 점유율 측정
ncu --metrics=smsp__warps_active.avg.pct_of_peak_sustained_active problems/p31/p31_profiler --minimal
ncu --metrics=smsp__warps_active.avg.pct_of_peak_sustained_active problems/p31/p31_profiler --sophisticated
ncu --metrics=smsp__warps_active.avg.pct_of_peak_sustained_active problems/p31/p31_profiler --balanced
```

이론적 계산과 실제 측정된 점유율을 비교하세요 - 미스터리가 드러나는 순간입니다!

## 핵심 통찰

💡 **점유율 임계값:** 대기 시간을 숨기기에 충분한 점유율(~25-50%)을 확보하면, 그 이상의 점유율은 수확 체감 효과를 보입니다.

💡 **메모리 바운드 vs 연산 바운드:** SAXPY는 메모리 바운드입니다. 메모리 바운드 커널에서는 메모리 대역폭이 점유율보다 더 중요한 경우가 많습니다.

💡 **리소스 효율:** 최신 GPU는 적당한 수준의 레지스터 압박(스레드당 20-40개)을 점유율의 극적인 감소 없이 처리할 수 있습니다.

## 도전 과제: 다음 질문에 답하세요

**위의 조사 단계를 완료한 후, 다음 분석 질문에 답하여 점유율 미스터리를 풀어보세요:**

**성능 분석 (Step 2):**

1. 어떤 커널이 가장 빠르고, 어떤 커널이 가장 느린가요? 실행 시간 차이를 기록하세요.

**리소스 프로파일링 (Step 4):**

2. 각 커널의 스레드당 레지스터 수, 블록당 공유 메모리, SM당 Warp 수를 기록하세요.

**이론적 계산 (Step 5):**

3. GPU 스펙과 점유율 공식을 사용하여 각 커널의 이론적 점유율을 계산하세요. 어떤 커널이 가장 높고/낮아야 하나요?

**측정된 점유율 (Step 6):**

4. 측정된 점유율 값이 계산 결과와 어떻게 비교되나요?

**점유율 미스터리:**

5. 리소스 사용이 극적으로 다른데도 세 커널 모두 비슷한 점유율(~64-66%, GPU 아키텍처에 따라 다를 수 있음)를 달성하는 이유는 무엇인가요?
6. 리소스 사용이 극적으로 차이나는데(19 vs 40 레지스터, 0KB vs 49KB 공유 메모리) 성능이 거의 동일한(<2% 차이) 이유는 무엇인가요?
7. 이론적 점유율 계산과 실제 GPU 동작 사이의 관계에 대해 무엇을 알 수 있나요?
8. 이 SAXPY 워크로드의 실제 성능 병목이 점유율이 아니라면 무엇인가요?

<details>
<summary><strong>팁</strong></summary>

<div class="solution-tips">

**탐정 도구 모음:**

- **NSight Compute (`ncu`)** - 점유율과 리소스 사용량 측정
- **GPU 아키텍처 스펙** - `pixi run gpu-specs`를 사용한 이론적 한계 계산
- **점유율 공식** - 리소스 병목 예측
- **성능 벤치마크** - 이론적 분석 검증

**핵심 최적화 원칙:**

- **최적화 전에 계산하기:** 코드를 작성하기 전에 점유율 공식으로 리소스 한계를 예측
- **측정으로 검증하기:** 이론적 계산은 컴파일러 최적화와 하드웨어 세부 사항을 반영하지 못함
- **워크로드 특성 고려하기:** 메모리 바운드 워크로드는 연산 바운드보다 점유율이 덜 필요
- **최대 점유율을 목표로 하지 않기:** 충분한 점유율 + 다른 성능 요소를 최적화
- **임계값 관점으로 사고하기:** 25-50% 점유율이면 대부분 대기 시간을 숨기기에 충분
- **리소스 사용량 프로파일링하기:** NSight Compute로 실제 레지스터와 공유 메모리 소비량 파악

**조사 접근법:**

1. **벤치마킹부터 시작** - 먼저 성능 차이를 확인
2. **NSight Compute로 프로파일링** - 실제 리소스 사용량과 점유율 데이터 확보
3. **이론적 점유율 계산** - GPU 스펙과 점유율 공식 활용
4. **이론과 현실 비교** - 미스터리가 드러나는 순간!
5. **워크로드 특성 고찰** - 이론과 실제가 왜 다를 수 있는지 생각해보기

</div>
</details>

## 풀이

<details class="solution-details">
<summary><strong>심층 해설이 포함된 완전한 풀이</strong></summary>

이 점유율 탐정 사건은 리소스 사용이 GPU 성능에 어떤 영향을 미치는지 보여주고, 이론적 점유율과 실제 성능 사이의 복잡한 관계를 드러냅니다.

> 아래 구체적인 계산은 **NVIDIA A10G (Ampere 8.6)** - 테스트에 사용된 GPU - 기준입니다. 결과는 GPU 아키텍처에 따라 달라지지만, 방법론과 통찰은 보편적으로 적용됩니다. `pixi run gpu-specs`를 실행하여 하드웨어별 수치를 확인하세요.

## **리소스 분석을 통한 프로파일링 근거**

**NSight Compute 리소스 분석:**

**실제 프로파일링 결과 (NVIDIA A10G - GPU에 따라 결과가 다를 수 있음):**

- **Minimal:** 19 레지스터, ~0KB 공유 메모리 → 점유율 **63.87%**, **327.7ms**
- **Balanced:** 25 레지스터, 16.4KB 공유 메모리 → 점유율 **65.44%**, **329.4ms**
- **Sophisticated:** 40 레지스터, 49.2KB 공유 메모리 → 점유율 **65.61%**, **330.9ms**

**벤치마크 성능 근거:**

- **세 커널 모두 거의 동일한 성능**을 보임 (~327-331ms, <2% 차이)
- 리소스 차이가 크지만 **모두 비슷한 점유율**을 달성 (~64-66%)
- **메모리 대역폭이 제한 요인**으로 작용

## **점유율 계산의 실체**

**이론적 점유율 분석 (NVIDIA A10G, Ampere 8.6):**

**GPU 스펙 (`pixi run gpu-specs` 출력):**

- **SM당 레지스터:** 65,536
- **SM당 공유 메모리:** 164KB (아키텍처 최대치)
- **SM당 최대 스레드:** 1,536 (A10G 하드웨어 제한)
- **블록당 스레드:** 1,024 (커널 설정값)
- **SM당 최대 블록:** 32

**Minimal 커널 계산:**

```
레지스터 제한 = 65,536 / (19 × 1,024) = 3.36 블록/SM
공유 메모리 제한 = 164KB / 0KB = ∞ 블록/SM
하드웨어 블록 제한 = 32 블록/SM

스레드 제한 = 1,536 / 1,024 = 1 블록/SM (내림)
실제 블록 = min(3, ∞, 1) = 1 블록/SM
이론적 점유율 = (1 × 1,024) / 1,536 = 66.7%
```

**Balanced 커널 계산:**

```
레지스터 제한 = 65,536 / (25 × 1,024) = 2.56 블록/SM
공유 메모리 제한 = 164KB / 16.4KB = 10 블록/SM
하드웨어 블록 제한 = 32 블록/SM

스레드 제한 = 1,536 / 1,024 = 1 블록/SM (내림)
실제 블록 = min(2, 10, 1) = 1 블록/SM
이론적 점유율 = (1 × 1,024) / 1,536 = 66.7%
```

**Sophisticated 커널 계산:**

```
레지스터 제한 = 65,536 / (40 × 1,024) = 1.64 블록/SM
공유 메모리 제한 = 164KB / 49.2KB = 3.33 블록/SM
하드웨어 블록 제한 = 32 블록/SM

스레드 제한 = 1,536 / 1,024 = 1 블록/SM (내림)
실제 블록 = min(1, 3, 1) = 1 블록/SM
이론적 점유율 = (1 × 1,024) / 1,536 = 66.7%
```

**핵심 발견: 이론과 현실이 일치한다!**

- **이론적**: 모든 커널 ~66.7% (A10G의 스레드 용량에 의해 제한)
- **실측**: 모두 ~64-66% (매우 근접한 결과!)

이는 **A10G의 스레드 제한이 지배적**임을 보여줍니다 - SM당 최대 스레드가 1,536개이므로 1,024 스레드 블록은 1개만 들어갑니다. 이론(66.7%)과 실측(~65%) 사이의 작은 차이는 하드웨어 스케줄링 오버헤드와 드라이버 제약에서 비롯됩니다.

## **이론과 현실이 근접한 이유**

**이론적(66.7%)과 실측(~65%) 점유율 사이 작은 차이의 원인:**

1. **하드웨어 스케줄링 오버헤드**: 실제 Warp 스케줄러는 이론적 계산을 넘어서는 실질적 제약이 있음
2. **CUDA 런타임 예약**: 드라이버와 런타임 오버헤드가 가용 SM 리소스를 약간 줄임
3. **메모리 컨트롤러 압박**: A10G의 메모리 서브시스템이 약간의 스케줄링 제약을 만듦
4. **전력 및 열 관리**: 동적 주파수 조절이 최대 성능에 영향
5. **명령어 캐시 효과**: 실제 커널은 점유율 계산에 포착되지 않는 명령어 페치 오버헤드가 있음

**핵심 통찰**: 이론과 실측이 근접하다는 것(66.7% vs ~65%)은 레지스터와 공유 메모리 차이와 무관하게 **A10G의 스레드 제한이 세 커널 모두를 지배**한다는 뜻입니다. 진짜 병목을 정확히 짚어낸 좋은 사례입니다!

## **점유율 미스터리 해설**

**미스터리의 진짜 정체:**

- 리소스 차이가 극적인데도 **세 커널 모두 거의 동일한 점유율**을 달성 (~64-66%)
- **성능이 본질적으로 동일** (세 커널 모두 <2% 변동)
- **이론이 점유율을 정확히 예측** (66.7% 이론 ≈ 65% 실측)
- **미스터리는 점유율 불일치가 아닙니다** - 리소스 사용이 크게 다른데도 왜 점유율과 성능이 동일한지가 진짜 미스터리입니다!

**리소스 사용이 다른데 성능이 동일한 이유:**

**SAXPY 워크로드의 특성:**

- **메모리 바운드 연산:** 각 스레드의 연산량이 극히 적음 (`y[i] = alpha * x[i] + y[i]`)
- **높은 메모리 트래픽:** 스레드당 2개 값 읽기, 1개 값 쓰기
- **낮은 산술 강도:** 12바이트 메모리 트래픽당 2 FLOPS만 수행

**메모리 대역폭 분석 (A10G):**

```
단일 커널 패스 분석:
- 입력 배열: 32M × 4바이트 × 2 배열 = 256MB 읽기
- 출력 배열: 32M × 4바이트 × 1 배열 = 128MB 쓰기
- 커널당 총량: 384MB 메모리 트래픽

최대 대역폭 (A10G): 600 GB/s
단일 패스 시간: 384MB / 600 GB/s ≈ 0.64ms 이론적 최소치
벤치마크 시간: ~328ms (여러 반복 + 오버헤드 포함)
```

**실제 성능 결정 요인:**

1. **메모리 대역폭 활용**: 모든 커널이 가용 메모리 대역폭을 포화시킴
2. **연산 오버헤드**: 정교한 커널이 추가 작업을 수행 (레지스터 압박 효과)
3. **공유 메모리 이점**: Balanced 커널이 일부 캐싱 이점을 얻음
4. **컴파일러 최적화**: 최신 컴파일러가 가능한 한 레지스터 사용을 최소화

## **점유율 임계값 개념 이해하기**

**핵심 통찰: 점유율은 "최대"가 아닌 "충분함"의 문제**

**대기 시간 은닉 요구 사항:**

- **메모리 latency:** 최신 GPU에서 ~500-800 사이클
- **Warp 스케줄링:** GPU는 이 latency를 숨기기 위해 충분한 Warp가 필요
- **충분한 임계값:** 보통 25-50% 점유율이면 대기 시간을 효과적으로 숨길 수 있음

**높은 점유율이 항상 도움이 되지 않는 이유:**

**리소스 경쟁:**

- 더 많은 활성 스레드가 동일한 메모리 대역폭을 놓고 경쟁
- 동시 접근이 많아지면 캐시 압박이 증가
- 레지스터/공유 메모리 압박이 개별 스레드 성능을 저하시킬 수 있음

**워크로드별 최적화:**

- **연산 바운드:** 높은 점유율이 ALU 파이프라인 latency를 숨기는 데 도움
- **메모리 바운드:** 점유율과 무관하게 메모리 대역폭이 성능을 제한
- **혼합 워크로드:** 점유율과 다른 최적화 요소 사이에서 균형 필요

## **실전 점유율 최적화 원칙**

**체계적 점유율 분석 접근법:**

**1단계: 이론적 한계 계산**

```bash
# GPU 스펙 확인
pixi run gpu-specs
```

**2단계: 실제 사용량 프로파일링**

```bash
# 리소스 소비량 측정
ncu --set=@occupancy --section=LaunchStats your_kernel

# 달성된 점유율 측정
ncu --metrics=smsp__warps_active.avg.pct_of_peak_sustained_active your_kernel
```

**3단계: 성능 검증**

```bash
# 항상 실제 성능 측정으로 검증
ncu --set=@roofline --section=MemoryWorkloadAnalysis your_kernel
```

**근거 기반 의사결정 프레임워크:**

```
점유율 분석 → 최적화 전략:

높은 점유율 (>70%) + 좋은 성능:
→ 점유율은 충분, 다른 병목에 집중

낮은 점유율 (<30%) + 나쁜 성능:
→ 리소스 최적화를 통해 점유율 향상 필요

적당한 점유율 (50-70%) + 나쁜 성능:
→ 메모리 대역폭, 캐시, 연산 병목 조사 필요

낮은 점유율 (<30%) + 좋은 성능:
→ 워크로드가 높은 점유율을 필요로 하지 않음 (메모리 바운드)
```

## **실용적인 점유율 최적화 기법**

**레지스터 최적화:**

- **적절한 데이터 타입 사용**: `float32` vs `float64`, `int32` vs `int64`
- **중간 변수 최소화**: 컴파일러가 임시 저장소를 최적화하도록 맡기기
- **루프 전개 고려**: 점유율과 명령어 수준 병렬성 사이의 균형

**공유 메모리 최적화:**

- **필요한 크기 계산**: 과다 할당 방지
- **tiling 전략 고려**: 점유율과 데이터 재사용 사이의 균형
- **뱅크 충돌 회피**: 충돌 없는 접근 패턴 설계

**블록 크기 튜닝:**

- **여러 설정 테스트**: 블록당 256, 512, 1024 스레드
- **Warp 활용 고려**: 가능하면 불완전한 Warp 방지
- **점유율과 리소스 사용의 균형**: 블록이 클수록 리소스 한계에 도달할 수 있음

## **핵심 정리: A10G 미스터리에서 보편적 원칙으로**

이 A10G 점유율 조사는 모든 GPU 최적화에 적용되는 명확한 통찰의 진행을 보여줍니다:

**A10G 발견 과정:**

1. **스레드 제한이 모든 것을 지배** - 19 vs 40 레지스터, 0KB vs 49KB 공유 메모리 차이에도 불구하고, A10G의 1,536 스레드 용량 때문에 모든 커널이 SM당 1블록이라는 동일한 제한에 걸림
2. **이론이 현실과 근접하게 일치** - 66.7% 이론 vs ~65% 실측 점유율은 올바른 병목을 식별했을 때 계산이 유효함을 보여줌
3. **메모리 대역폭이 성능을 지배** - 동일한 66.7% 점유율에서, SAXPY의 메모리 바운드 특성(600 GB/s 포화)이 리소스 차이에도 불구하고 동일한 성능을 설명

**보편적인 GPU 최적화 원칙:**

**진짜 병목 식별하기:**

- **모든 리소스**에서 점유율 제한을 계산: 레지스터, 공유 메모리, 스레드 용량
- 가장 제한적인 요소가 결정적 - 레지스터나 공유 메모리가 항상 병목이라고 가정하지 말 것
- 메모리 바운드 워크로드(SAXPY 같은)는 대기 시간을 숨길 만큼 충분한 스레드만 확보되면 점유율이 아닌 대역폭이 제한 요인

**점유율이 중요한 경우 vs 중요하지 않은 경우:**

- **높은 점유율이 중요**: 연산 집약적 커널(GEMM, 과학 시뮬레이션)에서 ALU 파이프라인이 멈추는 시간을 다른 Warp 실행으로 숨겨야 하는 경우
- **점유율이 덜 중요**: 메모리 바운드 연산(BLAS Level 1, 메모리 복사)에서 점유율이 제한 요인이 되기 전에 대역폭이 포화되는 경우
- **적정 수준**: 60-70% 점유율이면 대기 시간을 숨기기에 충분 - 그 이상은 진짜 병목에 집중

**실전 최적화 워크플로우:**

1. **먼저 프로파일링** (`ncu --set=@occupancy`) - 실제 리소스 사용량과 점유율 측정
2. **이론적 한계 계산** - GPU 스펙 활용 (`pixi run gpu-specs`)
3. **지배적 제약 식별** - 레지스터, 공유 메모리, 스레드 용량, 또는 메모리 대역폭
4. **병목 최적화** - 제한 요인이 아닌 리소스에 시간 낭비하지 않기
5. **종단간 성능으로 검증** - 점유율은 성능을 위한 수단이지 목표가 아님

A10G 사례는 **체계적 병목 분석이 직관보다 낫다**는 것을 완벽하게 보여줍니다 - 스레드 용량이 지배적이었기에 정교한 커널의 높은 레지스터 압박은 무관했고, 동일한 점유율과 메모리 대역폭 포화가 성능 미스터리를 완전히 설명해줍니다.

</details>
