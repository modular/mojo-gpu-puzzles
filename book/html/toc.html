<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- sidebar iframe generated using mdBook

        This is a frame, and not included directly in the page, to control the total size of the
        book. The TOC contains an entry for each page, so if each page includes a copy of the TOC,
        the total size of the page becomes O(n**2).

        The frame is only used as a fallback when JS is turned off. When it's on, the sidebar is
        instead added to the main page by `toc.js` instead. The JavaScript mode is better
        because, when running in a `file:///` URL, the iframed page would not be Same-Origin as
        the rest of the page, so the sidebar and the main page theme would fall out of sync.
        -->
        <meta charset="UTF-8">
        <meta name="robots" content="noindex">
        <!-- Custom HTML head -->
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,100..700;1,100..700&display=swap"
            rel="stylesheet">
        
        <script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
        
        <link rel="stylesheet" href="theme/css/custom.css">
        <link rel="stylesheet" href="theme/css/highlight.css">
        <link rel="stylesheet" id="theme">
        
        <!-- Additional meta tags -->
        <meta property="og:title" content="Mojo🔥 GPU Puzzles">
        <meta property="og:description" content="Learn GPU Programming in Mojo🔥 Through Interactive Puzzles">
        <meta property="og:image" content="images/puzzle-logo.png">
        <meta property="og:url" content="https://puzzles.modular.com">
        <meta name="twitter:card" content="summary">
        <meta name="twitter:image:alt" content="Mojo GPU Puzzles Logo">
        <meta name="twitter:title" content="Mojo🔥 GPU Puzzles">
        <meta name="twitter:description" content="Learn GPU Programming in Mojo🔥 Through Interactive Puzzles">
        <meta name="twitter:image" content="images/puzzle-logo.png">
        <link rel="icon" type="image/png" href="images/puzzle-logo.png">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="theme/css/custom.css">
        <link rel="stylesheet" href="theme/css/highlight.css">
    </head>
    <body class="sidebar-iframe-inner">
        <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">Getting Started</li><li class="chapter-item expanded "><a href="introduction.html" target="_parent">Introduction</a></li><li class="chapter-item expanded "><a href="howto.html" target="_parent">🧩 Puzzles Usage Guide</a></li><li class="chapter-item expanded affix "><li class="part-title">Part I: GPU Fundamentals</li><li class="chapter-item expanded "><a href="puzzle_01/puzzle_01.html" target="_parent">Puzzle 1: Map</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_01/raw.html" target="_parent">🔰 Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_01/layout_tensor_preview.html" target="_parent">💡 Preview: Modern Approach with LayoutTensor</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_02/puzzle_02.html" target="_parent">Puzzle 2: Zip</a></li><li class="chapter-item expanded "><a href="puzzle_03/puzzle_03.html" target="_parent">Puzzle 3: Guards</a></li><li class="chapter-item expanded "><a href="puzzle_04/puzzle_04.html" target="_parent">Puzzle 4: 2D Map</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_04/raw.html" target="_parent">🔰 Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_04/introduction_layout_tensor.html" target="_parent">📚 Learn about LayoutTensor</a></li><li class="chapter-item expanded "><a href="puzzle_04/layout_tensor.html" target="_parent">🚀 Modern 2D Operations</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_05/puzzle_05.html" target="_parent">Puzzle 5: Broadcast</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_05/raw.html" target="_parent">🔰 Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_05/layout_tensor.html" target="_parent">📐 LayoutTensor Version</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_06/puzzle_06.html" target="_parent">Puzzle 6: Blocks</a></li><li class="chapter-item expanded "><a href="puzzle_07/puzzle_07.html" target="_parent">Puzzle 7: 2D Blocks</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_07/raw.html" target="_parent">🔰 Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_07/layout_tensor.html" target="_parent">📐 LayoutTensor Version</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_08/puzzle_08.html" target="_parent">Puzzle 8: Shared Memory</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_08/raw.html" target="_parent">🔰 Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_08/layout_tensor.html" target="_parent">📐 LayoutTensor Version</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part II: GPU Algorithms</li><li class="chapter-item expanded "><a href="puzzle_09/puzzle_09.html" target="_parent">Puzzle 9: Pooling</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_09/raw.html" target="_parent">🔰 Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_09/layout_tensor.html" target="_parent">📐 LayoutTensor Version</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_10/puzzle_10.html" target="_parent">Puzzle 10: Dot Product</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_10/raw.html" target="_parent">🔰 Raw Memory Approach</a></li><li class="chapter-item expanded "><a href="puzzle_10/layout_tensor.html" target="_parent">📐 LayoutTensor Version</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_11/puzzle_11.html" target="_parent">Puzzle 11: 1D Convolution</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_11/simple.html" target="_parent">🔰 Simple Version</a></li><li class="chapter-item expanded "><a href="puzzle_11/complete.html" target="_parent">⭐ Complete Version</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_12/puzzle_12.html" target="_parent">Puzzle 12: Prefix Sum</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_12/simple.html" target="_parent">🔰 Simple Version</a></li><li class="chapter-item expanded "><a href="puzzle_12/complete.html" target="_parent">⭐ Complete Version</a></li></ol></li><li class="chapter-item expanded "><a href="puzzle_13/puzzle_13.html" target="_parent">Puzzle 13: Axis Sum</a></li><li class="chapter-item expanded "><a href="puzzle_14/puzzle_14.html" target="_parent">Puzzle 14: Matrix Multiplication (MatMul)</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="puzzle_14/naive.html" target="_parent">🔰 Naive Version with Global Memory</a></li><li class="chapter-item expanded "><div>📚 Learn about Roofline Model</div></li><li class="chapter-item expanded "><a href="puzzle_14/shared_memory.html" target="_parent">🤝 Shared Memory Version</a></li><li class="chapter-item expanded "><a href="puzzle_14/tiled.html" target="_parent">📐 Tiled Version</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part III: Interfacing with Python via MAX Graph Custom Ops</li><li class="chapter-item expanded "><div>Puzzle 15: 1D Convolution Op</div></li><li class="chapter-item expanded "><div>Puzzle 16: Softmax Op</div></li><li class="chapter-item expanded "><div>Puzzle 17: Attention Op</div></li><li class="chapter-item expanded "><div>🎯 Bonus Challenges</div></li><li class="chapter-item expanded affix "><li class="part-title">Part IV: Advanced GPU Algorithms</li><li class="chapter-item expanded "><div>Puzzle 18: 2D Convolution Op</div></li><li class="chapter-item expanded "><div>Puzzle 19: 3D Average Pooling</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about 3D Memory Layout</div></li><li class="chapter-item expanded "><div>Basic Version</div></li><li class="chapter-item expanded "><div>LayoutTensor Version</div></li></ol></li><li class="chapter-item expanded "><div>Puzzle 20: 3D Convolution</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about 3D Convolution</div></li><li class="chapter-item expanded "><div>Basic Version</div></li><li class="chapter-item expanded "><div>Optimized Version</div></li></ol></li><li class="chapter-item expanded "><div>Puzzle 21: 3D Tensor Multiplication</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about Tensor Operations</div></li><li class="chapter-item expanded "><div>Basic Version</div></li><li class="chapter-item expanded "><div>LayoutTensor Version</div></li></ol></li><li class="chapter-item expanded "><div>Puzzle 22: Multi-Head Self-Attention</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about Attention Mechanisms</div></li><li class="chapter-item expanded "><div>Basic Version</div></li><li class="chapter-item expanded "><div>Optimized Version</div></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part V: Performance Optimization Puzzles</li><li class="chapter-item expanded "><div>Puzzle 23: Memory Coalescing</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about Memory Access Patterns</div></li><li class="chapter-item expanded "><div>Basic Version</div></li><li class="chapter-item expanded "><div>Optimized Version</div></li></ol></li><li class="chapter-item expanded "><div>Puzzle 24: Bank Conflicts</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about Shared Memory Banks</div></li><li class="chapter-item expanded "><div>Version 1: With Conflicts</div></li><li class="chapter-item expanded "><div>Version 2: Conflict-Free</div></li></ol></li><li class="chapter-item expanded "><div>Puzzle 25: Warp-Level Optimization</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about Warp Primitives</div></li><li class="chapter-item expanded "><div>Version 1: Shared Memory Reduction</div></li><li class="chapter-item expanded "><div>Version 2: Warp Shuffle Reduction</div></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part VI: Real-world Application Puzzles</li><li class="chapter-item expanded "><div>Puzzle 26: Image Processing Pipeline</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about Kernel Fusion</div></li><li class="chapter-item expanded "><div>Version 1: Separate Kernels</div></li><li class="chapter-item expanded "><div>Version 2: Fused Pipeline</div></li></ol></li><li class="chapter-item expanded "><div>Puzzle 27: Neural Network Layers</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about Layer Fusion</div></li><li class="chapter-item expanded "><div>Version 1: Basic Implementation</div></li><li class="chapter-item expanded "><div>Version 2: Optimized Implementation</div></li></ol></li><li class="chapter-item expanded "><div>Puzzle 28: Multi-Level Tiling</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about Cache Hierarchies</div></li><li class="chapter-item expanded "><div>Version 1: Single-Level MatMul</div></li><li class="chapter-item expanded "><div>Version 2: Multi-Level MatMul</div></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part VII: Debug &amp; Profile Puzzles</li><li class="chapter-item expanded "><div>Puzzle 29: Race Condition Detective</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about Race Conditions</div></li><li class="chapter-item expanded "><div>Version 1: Find the Bug</div></li><li class="chapter-item expanded "><div>Version 2: Fix the Bug</div></li></ol></li><li class="chapter-item expanded "><div>Puzzle 30: Memory Optimization</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about Memory Management</div></li><li class="chapter-item expanded "><div>Version 1: Memory Leaks</div></li><li class="chapter-item expanded "><div>Version 2: Memory Planning</div></li></ol></li><li class="chapter-item expanded "><li class="part-title">Part VIII: Modern GPU Features</li><li class="chapter-item expanded "><div>Puzzle 31: Dynamic Parallelism</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about Nested Parallelism</div></li><li class="chapter-item expanded "><div>Version 1: Flat Implementation</div></li><li class="chapter-item expanded "><div>Version 2: Nested Launch</div></li></ol></li><li class="chapter-item expanded "><div>Puzzle 32: Tensor Core Programming</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about Tensor Cores</div></li><li class="chapter-item expanded "><div>Version 1: Regular MatMul</div></li><li class="chapter-item expanded "><div>Version 2: Tensor Core MatMul</div></li></ol></li><li class="chapter-item expanded "><div>Puzzle 33: Multi-GPU Programming</div></li><li><ol class="section"><li class="chapter-item expanded "><div>📚 Learn about Device Communication</div></li><li class="chapter-item expanded "><div>Version 1: Single GPU</div></li><li class="chapter-item expanded "><div>Version 2: Multi-GPU</div></li></ol></li></ol>
    </body>
</html>
