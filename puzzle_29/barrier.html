<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>ðŸ“¶ Multi-Stage Pipeline Coordination - Mojo ðŸ”¥ GPU Puzzles</title>


        <!-- Custom HTML head -->
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,100..700;1,100..700&display=swap"
            rel="stylesheet">
        
        <script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
        
        <link rel="stylesheet" href="../theme/css/custom.css">
        <link rel="stylesheet" href="../theme/css/highlight.css">
        <link rel="stylesheet" id="theme">
        
        <!-- Additional meta tags -->
        <meta property="og:title" content="MojoðŸ”¥ GPU Puzzles">
        <meta property="og:description" content="Learn GPU Programming in MojoðŸ”¥ Through Interactive Puzzles">
        <meta property="og:image" content="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">
        <meta property="og:url" content="https://puzzles.modular.com/">
        <meta name="twitter:card" content="summary">
        <meta name="twitter:image:alt" content="Mojo GPU Puzzles Logo">
        <meta name="twitter:title" content="MojoðŸ”¥ GPU Puzzles">
        <meta name="twitter:description" content="Learn GPU Programming in MojoðŸ”¥ Through Interactive Puzzles">
        <meta name="twitter:image" content="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">
        <link rel="icon" type="image/png" href="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&display=swap" rel="stylesheet">

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../theme/css/custom.css">
        <link rel="stylesheet" href="../theme/css/highlight.css">
        <link rel="stylesheet" href="../theme/css/tabs.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "ayu";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <button class="collapse-sidebar" aria-label="Collapse sidebar"></button>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Toggle color mode and talk to us buttons -->
        <script>
            document.addEventListener('click', function (event) {
                if (!event.target.matches('.theme-toggle')) return;
                event.preventDefault();
                const prevTheme = theme;
                html.classList.remove(theme);
                const newTheme = prevTheme === 'ayu' ? 'light' : 'ayu'
                html.classList.add(newTheme);
                theme = newTheme
                localStorage.setItem('mdbook-theme', theme);
            }, false);
            document.addEventListener('click', function() {
                if (!event.target.matches('.log-in')) return;
                event.preventDefault();
                window.amplitude.logEvent('LoginClickedFromPuzzles');
                window.open('https://developer.modular.com', '_blank');
            });
        </script>

        <div class="page-header">
            <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                <i class="fa fa-bars"></i>
            </label>
            <div id="menu-bar" class="menu-bar">
                <div class="left-buttons">
                    <div class="logo-section">
                        <a class="desktop-logo-link" href="https://modular.com"></a>
                        <a class="mobile-logo-link" href="https://builds.modular.com"></a>
                        <div class="slash">/</div>
                        <a class="internal-link" ref="/">Puzzles</a>
                    </div>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Dark</button></li>
                        </ul>
                    </div>
                <div class="right-buttons">
                    <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                        <i class="fa fa-search"></i>
                    </button>
                    <button id="theme-toggle" class="icon-button theme-toggle-btn" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="false" aria-expanded="false">
                        <i class="theme-toggle"></i>
                    </button>
                    <a class="menu-btn print" href="../print.html" title="Print this book" aria-label="Print this book">
                        <i id="print-button" class="fa fa-print"></i>
                    </a>
                    <a class="menu-btn" href="https://github.com/modular/mojo-gpu-puzzles" title="Git repository" aria-label="Git repository">
                        <i id="git-repository-button" class="fa fa-github"></i>
                    </a>
                </div>
            </div>
        </div>

        <div id="page-wrapper" class="page-wrapper">
            <div class="page">

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <div id="content" class="content">
                    <main>
                        <h1 id="multi-stage-pipeline-coordination"><a class="header" href="#multi-stage-pipeline-coordination">Multi-Stage Pipeline Coordination</a></h1>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Implement a kernel that processes an image through a coordinated 3-stage pipeline where different thread groups handle specialized processing stages, synchronized with explicit barriers.</p>
<p><strong>Note:</strong> <em>You have specialized thread roles: Stage 1 (threads 0-127) loads and preprocesses data, Stage 2 (threads 128-255) applies blur operations, and Stage 3 (all threads) performs final smoothing.</em></p>
<p><strong>Algorithm architecture:</strong> This puzzle implements a <strong>producer-consumer pipeline</strong> where different thread groups execute completely different algorithms within a single GPU block. Unlike traditional GPU programming where all threads execute the same algorithm on different data, this approach divides threads by <strong>functional specialization</strong>.</p>
<p><strong>Pipeline concept:</strong> The algorithm processes data through three distinct stages, where each stage has specialized thread groups that execute different algorithms. Each stage produces data that the next stage consumes, creating explicit <strong>producer-consumer relationships</strong> that must be carefully synchronized with barriers.</p>
<p><strong>Data dependencies and synchronization:</strong> Each stage produces data that the next stage consumes:</p>
<ul>
<li><strong>Stage 1 â†’ Stage 2</strong>: First stage produces preprocessed data for blur processing</li>
<li><strong>Stage 2 â†’ Stage 3</strong>: Second stage produces blur results for final smoothing</li>
<li><strong>Barriers prevent race conditions</strong> by ensuring complete stage completion before dependent stages begin</li>
</ul>
<p>Concretely, the multi-stage pipeline implements a coordinated image processing algorithm with three mathematical operations:</p>
<p><strong>Stage 1 - Preprocessing Enhancement:</strong></p>
<p>\[P[i] = I[i] \times 1.1\]</p>
<p>where \(P[i]\) is the preprocessed data and \(I[i]\) is the input data.</p>
<p><strong>Stage 2 - Horizontal Blur Filter:</strong></p>
<p>\[B[i] = \frac{1}{N_i} \sum_{k=-2}^{2} P[i+k] \quad \text{where } i+k \in [0, 255]\]</p>
<p>where \(B[i]\) is the blur result, and \(N_i\) is the count of valid neighbors within the tile boundary.</p>
<p><strong>Stage 3 - Cascading Neighbor Smoothing:</strong></p>
<p>\[F[i] = \begin{cases}
(B[i] + B[i+1]) \times 0.6 &amp; \text{if } i = 0 \\
((B[i] + B[i-1]) \times 0.6 + B[i+1]) \times 0.6 &amp; \text{if } 0 &lt; i &lt; 255 \\
(B[i] + B[i-1]) \times 0.6 &amp; \text{if } i = 255
\end{cases}\]</p>
<p>where \(F[i]\) is the final output with cascading smoothing applied.</p>
<p><strong>Thread Specialization:</strong></p>
<ul>
<li><strong>Threads 0-127</strong>: Compute \(P[i]\) for \(i \in \{0, 1, 2, \ldots, 255\}\) (2 elements per thread)</li>
<li><strong>Threads 128-255</strong>: Compute \(B[i]\) for \(i \in \{0, 1, 2, \ldots, 255\}\) (2 elements per thread)</li>
<li><strong>All 256 threads</strong>: Compute \(F[i]\) for \(i \in \{0, 1, 2, \ldots, 255\}\) (1 element per thread)</li>
</ul>
<p><strong>Synchronization Points:</strong></p>
<p>\[\text{barrier}_1 \Rightarrow P[i] \text{ complete} \Rightarrow \text{barrier}_2 \Rightarrow B[i] \text{ complete} \Rightarrow \text{barrier}_3 \Rightarrow F[i] \text{ complete}\]</p>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key concepts</a></h2>
<p>In this puzzle, youâ€™ll learn about:</p>
<ul>
<li>Implementing thread role specialization within a single GPU block</li>
<li>Coordinating producer-consumer relationships between processing stages</li>
<li>Using barriers to synchronize between different algorithms (not just within the same algorithm)</li>
</ul>
<p>The key insight is understanding how to design multi-stage pipelines where different thread groups execute completely different algorithms, coordinated through strategic barrier placement.</p>
<p><strong>Why this matters:</strong> Most GPU tutorials teach barrier usage within a single algorithm - synchronizing threads during reductions or shared memory operations. But real-world GPU algorithms often require <strong>architectural complexity</strong> with multiple distinct processing stages that must be carefully orchestrated. This puzzle demonstrates how to transform monolithic algorithms into specialized, coordinated processing pipelines.</p>
<p><strong>Previous vs. current barrier usage:</strong></p>
<ul>
<li><strong>Previous puzzles (<a href="../puzzle_08/puzzle_08.html">P8</a>, <a href="../puzzle_12/puzzle_12.html">P12</a>, <a href="../puzzle_15/puzzle_15.html">P15</a>):</strong> All threads execute the same algorithm, barriers sync within algorithm steps</li>
<li><strong>This puzzle:</strong> Different thread groups execute different algorithms, barriers coordinate between different algorithms</li>
</ul>
<p><strong>Thread specialization architecture:</strong> Unlike data parallelism where threads differ only in their data indices, this puzzle implements <strong>algorithmic parallelism</strong> where threads execute fundamentally different code paths based on their role in the pipeline.</p>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<p><strong>System parameters:</strong></p>
<ul>
<li><strong>Image size</strong>: <code>SIZE = 1024</code> elements (1D for simplicity)</li>
<li><strong>Threads per block</strong>: <code>TPB = 256</code> threads organized as <code>(256, 1)</code> block dimension</li>
<li><strong>Grid configuration</strong>: <code>(4, 1)</code> blocks to process entire image in tiles (4 blocks total)</li>
<li><strong>Data type</strong>: <code>DType.float32</code> for all computations</li>
</ul>
<p><strong>Thread specialization architecture:</strong></p>
<ul>
<li>
<p><strong>Stage 1 threads</strong>: <code>STAGE1_THREADS = 128</code> (threads 0-127, first half of block)</p>
<ul>
<li><strong>Responsibility</strong>: Load input data from global memory and apply preprocessing</li>
<li><strong>Work distribution</strong>: Each thread processes 2 elements for efficient load balancing</li>
<li><strong>Output</strong>: Populates <code>input_shared[256]</code> with preprocessed data</li>
</ul>
</li>
<li>
<p><strong>Stage 2 threads</strong>: <code>STAGE2_THREADS = 128</code> (threads 128-255, second half of block)</p>
<ul>
<li><strong>Responsibility</strong>: Apply horizontal blur filter on preprocessed data</li>
<li><strong>Work distribution</strong>: Each thread processes 2 blur operations</li>
<li><strong>Output</strong>: Populates <code>blur_shared[256]</code> with blur results</li>
</ul>
</li>
<li>
<p><strong>Stage 3 threads</strong>: All 256 threads collaborate</p>
<ul>
<li><strong>Responsibility</strong>: Final smoothing and output to global memory</li>
<li><strong>Work distribution</strong>: One-to-one mapping (thread <code>i</code> processes element <code>i</code>)</li>
<li><strong>Output</strong>: Writes final results to global <code>output</code> array</li>
</ul>
</li>
</ul>
<h2 id="code-to-complete"><a class="header" href="#code-to-complete">Code to complete</a></h2>
<pre><code class="language-mojo">
alias TPB = 256  # Threads per block for pipeline stages
alias SIZE = 1024  # Image size (1D for simplicity)
alias BLOCKS_PER_GRID = (4, 1)
alias THREADS_PER_BLOCK = (TPB, 1)
alias dtype = DType.float32
alias layout = Layout.row_major(SIZE)

# Multi-stage processing configuration
alias STAGE1_THREADS = TPB // 2
alias STAGE2_THREADS = TPB // 2
alias BLUR_RADIUS = 2


fn multi_stage_image_blur_pipeline[
    layout: Layout
](
    output: LayoutTensor[mut=True, dtype, layout],
    input: LayoutTensor[mut=False, dtype, layout],
    size: Int,
):
    """Multi-stage image blur pipeline with barrier coordination.

    Stage 1 (threads 0-127): Load input data and apply 1.1x preprocessing
    Stage 2 (threads 128-255): Apply 5-point blur with BLUR_RADIUS=2
    Stage 3 (all threads): Final neighbor smoothing and output
    """

    # Shared memory buffers for pipeline stages
    input_shared = LayoutTensor[
        dtype,
        Layout.row_major(TPB),
        MutableAnyOrigin,
        address_space = AddressSpace.SHARED,
    ].stack_allocation()
    blur_shared = LayoutTensor[
        dtype,
        Layout.row_major(TPB),
        MutableAnyOrigin,
        address_space = AddressSpace.SHARED,
    ].stack_allocation()

    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x

    # Stage 1: Load and preprocess (threads 0-127)

    # FILL ME IN (roughly 10 lines)

    barrier()  # Wait for Stage 1 completion

    # Stage 2: Apply blur (threads 128-255)

    # FILL ME IN (roughly 25 lines)

    barrier()  # Wait for Stage 2 completion

    # Stage 3: Final smoothing (all threads)

    # FILL ME IN (roughly 7 lines)

    barrier()  # Ensure all writes complete


</code></pre>
<p><a href="https://github.com/modular/mojo-gpu-puzzles/blob/main/problems/p29/p29.mojo" class="filename">View full file: problems/p29/p29.mojo</a></p>
<details>
<summary><strong>Tips</strong></summary>
<div class="solution-tips">
<h3 id="thread-role-identification"><a class="header" href="#thread-role-identification"><strong>Thread role identification</strong></a></h3>
<ul>
<li>Use thread index comparisons to determine which stage each thread should execute</li>
<li>Stage 1: First half of threads (threads 0-127)</li>
<li>Stage 2: Second half of threads (threads 128-255)</li>
<li>Stage 3: All threads participate</li>
</ul>
<h3 id="stage-1-approach"><a class="header" href="#stage-1-approach"><strong>Stage 1 approach</strong></a></h3>
<ul>
<li>Identify Stage 1 threads using appropriate index comparison</li>
<li>Each thread should handle multiple elements for load balancing</li>
<li>Apply the preprocessing enhancement factor</li>
<li>Implement proper boundary handling with zero-padding</li>
</ul>
<h3 id="stage-2-approach"><a class="header" href="#stage-2-approach"><strong>Stage 2 approach</strong></a></h3>
<ul>
<li>Identify Stage 2 threads and map their indices to processing range</li>
<li>Implement the blur kernel by averaging neighboring elements</li>
<li>Handle boundary conditions by only including valid neighbors</li>
<li>Process multiple elements per thread for efficiency</li>
</ul>
<h3 id="stage-3-approach"><a class="header" href="#stage-3-approach"><strong>Stage 3 approach</strong></a></h3>
<ul>
<li>All threads participate in final processing</li>
<li>Apply neighbor smoothing using the specified scaling factor</li>
<li>Handle edge cases where neighbors may not exist</li>
<li>Write results to global output with bounds checking</li>
</ul>
<h3 id="synchronization-strategy"><a class="header" href="#synchronization-strategy"><strong>Synchronization strategy</strong></a></h3>
<ul>
<li>Place barriers between stages to prevent race conditions</li>
<li>Ensure each stage completes before dependent stages begin</li>
<li>Use final barrier to guarantee completion before block exit</li>
</ul>
</div>
</details>
<h2 id="running-the-code"><a class="header" href="#running-the-code">Running the code</a></h2>
<p>To test your solution, run the following command in your terminal:</p>
<div class="code-tabs" data-tab-group="package-manager">
  <div class="tab-buttons">
    <button class="tab-button">pixi NVIDIA (default)</button>
    <button class="tab-button">pixi AMD</button>
    <button class="tab-button">uv</button>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">pixi run p29 --multi-stage
</code></pre>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">pixi run -e amd p29 --multi-stage
</code></pre>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">uv run poe p29 --multi-stage
</code></pre>
  </div>
</div>
<p>After completing the puzzle successfully, you should see output similar to:</p>
<pre><code>Puzzle 29: GPU Synchronization Primitives
==================================================
TPB: 256
SIZE: 1024
STAGE1_THREADS: 128
STAGE2_THREADS: 128
BLUR_RADIUS: 2

Testing Puzzle 29A: Multi-Stage Pipeline Coordination
============================================================
Multi-stage pipeline blur completed
Input sample: 0.0 1.01 2.02
Output sample: 1.6665002 2.3331003 3.3996604
âœ… Multi-stage pipeline coordination test PASSED!
</code></pre>
<h2 id="solution"><a class="header" href="#solution">Solution</a></h2>
<details class="solution-details">
<summary></summary>
<pre><code class="language-mojo">fn multi_stage_image_blur_pipeline[
    layout: Layout
](
    output: LayoutTensor[mut=True, dtype, layout],
    input: LayoutTensor[mut=False, dtype, layout],
    size: Int,
):
    """Multi-stage image blur pipeline with barrier coordination.

    Stage 1 (threads 0-127): Load input data and apply 1.1x preprocessing
    Stage 2 (threads 128-255): Apply 5-point blur with BLUR_RADIUS=2
    Stage 3 (all threads): Final neighbor smoothing and output
    """

    # Shared memory buffers for pipeline stages
    input_shared = LayoutTensor[
        dtype,
        Layout.row_major(TPB),
        MutableAnyOrigin,
        address_space = AddressSpace.SHARED,
    ].stack_allocation()
    blur_shared = LayoutTensor[
        dtype,
        Layout.row_major(TPB),
        MutableAnyOrigin,
        address_space = AddressSpace.SHARED,
    ].stack_allocation()

    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x

    # Stage 1: Load and preprocess (threads 0-127)
    if local_i &lt; STAGE1_THREADS:
        if global_i &lt; size:
            input_shared[local_i] = input[global_i] * 1.1
            # Each thread loads 2 elements
            if local_i + STAGE1_THREADS &lt; size:
                input_shared[local_i + STAGE1_THREADS] = (
                    input[global_i + STAGE1_THREADS] * 1.1
                )
        else:
            # Zero-padding for out-of-bounds
            input_shared[local_i] = 0.0
            if local_i + STAGE1_THREADS &lt; TPB:
                input_shared[local_i + STAGE1_THREADS] = 0.0

    barrier()  # Wait for Stage 1 completion

    # Stage 2: Apply blur (threads 128-255)
    if local_i &gt;= STAGE1_THREADS:
        blur_idx = local_i - STAGE1_THREADS
        var blur_sum: Scalar[dtype] = 0.0
        blur_count = 0

        # 5-point blur kernel
        for offset in range(-BLUR_RADIUS, BLUR_RADIUS + 1):
            sample_idx = blur_idx + offset
            if sample_idx &gt;= 0 and sample_idx &lt; TPB:
                blur_sum += rebind[Scalar[dtype]](input_shared[sample_idx])
                blur_count += 1

        if blur_count &gt; 0:
            blur_shared[blur_idx] = blur_sum / blur_count
        else:
            blur_shared[blur_idx] = 0.0

        # Process second element
        second_idx = blur_idx + STAGE1_THREADS
        if second_idx &lt; TPB:
            blur_sum = 0.0
            blur_count = 0
            for offset in range(-BLUR_RADIUS, BLUR_RADIUS + 1):
                sample_idx = second_idx + offset
                if sample_idx &gt;= 0 and sample_idx &lt; TPB:
                    blur_sum += rebind[Scalar[dtype]](input_shared[sample_idx])
                    blur_count += 1

            if blur_count &gt; 0:
                blur_shared[second_idx] = blur_sum / blur_count
            else:
                blur_shared[second_idx] = 0.0

    barrier()  # Wait for Stage 2 completion

    # Stage 3: Final smoothing (all threads)
    if global_i &lt; size:
        final_value = blur_shared[local_i]

        # Neighbor smoothing with 0.6 scaling
        if local_i &gt; 0:
            final_value = (final_value + blur_shared[local_i - 1]) * 0.6
        if local_i &lt; TPB - 1:
            final_value = (final_value + blur_shared[local_i + 1]) * 0.6

        output[global_i] = final_value

    barrier()  # Ensure all writes complete


</code></pre>
<div class="solution-explanation">
<p>The key insight is recognizing this as a <strong>pipeline architecture problem</strong> with thread role specialization:</p>
<ol>
<li><strong>Design stage-specific thread groups</strong>: Divide threads by function, not just by data</li>
<li><strong>Implement producer-consumer chains</strong>: Stage 1 produces for Stage 2, Stage 2 produces for Stage 3</li>
<li><strong>Use strategic barrier placement</strong>: Synchronize between different algorithms, not within the same algorithm</li>
<li><strong>Optimize memory access patterns</strong>: Ensure coalesced reads and efficient shared memory usage</li>
</ol>
<p><strong>Complete Solution with Detailed Explanation</strong></p>
<p>The multi-stage pipeline solution demonstrates sophisticated thread specialization and barrier coordination. This approach transforms a traditional monolithic GPU algorithm into a specialized, coordinated processing pipeline.</p>
<h2 id="pipeline-architecture-design"><a class="header" href="#pipeline-architecture-design"><strong>Pipeline architecture design</strong></a></h2>
<p>The fundamental breakthrough in this puzzle is <strong>thread specialization by role</strong> rather than by data:</p>
<p><strong>Traditional approach:</strong> All threads execute the same algorithm on different data</p>
<ul>
<li>Everyone performs identical operations (like reductions or matrix operations)</li>
<li>Barriers synchronize threads within the same algorithm steps</li>
<li>Thread roles differ only by data indices they process</li>
</ul>
<p><strong>This puzzleâ€™s innovation:</strong> Different thread groups execute completely different algorithms</p>
<ul>
<li>Threads 0-127 execute loading and preprocessing algorithms</li>
<li>Threads 128-255 execute blur processing algorithms</li>
<li>All threads collaborate in final smoothing algorithm</li>
<li>Barriers coordinate between different algorithms, not within the same algorithm</li>
</ul>
<h2 id="producer-consumer-coordination"><a class="header" href="#producer-consumer-coordination"><strong>Producer-consumer coordination</strong></a></h2>
<p>Unlike previous puzzles where threads were peers in the same algorithm, this establishes explicit producer-consumer relationships:</p>
<ul>
<li><strong>Stage 1</strong>: Producer (creates preprocessed data for Stage 2)</li>
<li><strong>Stage 2</strong>: Consumer (uses Stage 1 data) + Producer (creates blur data for Stage 3)</li>
<li><strong>Stage 3</strong>: Consumer (uses Stage 2 data)</li>
</ul>
<h2 id="strategic-barrier-placement"><a class="header" href="#strategic-barrier-placement"><strong>Strategic barrier placement</strong></a></h2>
<p>Understanding when barriers are necessary vs. wasteful:</p>
<ul>
<li><strong>Necessary</strong>: Between dependent stages to prevent race conditions</li>
<li><strong>Wasteful</strong>: Within independent operations of the same stage</li>
<li><strong>Performance insight</strong>: Each barrier has a cost - use them strategically</li>
</ul>
<p><strong>Critical synchronization points:</strong></p>
<ol>
<li><strong>After Stage 1</strong>: Prevent Stage 2 from reading incomplete preprocessed data</li>
<li><strong>After Stage 2</strong>: Prevent Stage 3 from reading incomplete blur results</li>
<li><strong>After Stage 3</strong>: Ensure all output writes complete before block termination</li>
</ol>
<h2 id="thread-utilization-patterns"><a class="header" href="#thread-utilization-patterns"><strong>Thread utilization patterns</strong></a></h2>
<ul>
<li><strong>Stage 1</strong>: 50% utilization (128/256 threads active, 128 idle)</li>
<li><strong>Stage 2</strong>: 50% utilization (128 active, 128 idle)</li>
<li><strong>Stage 3</strong>: 100% utilization (all 256 threads active)</li>
</ul>
<p>This demonstrates sophisticated <strong>algorithmic parallelism</strong> where different thread groups specialize in different computational tasks within a coordinated pipeline, moving beyond simple data parallelism to architectural thinking required for real-world GPU algorithms.</p>
<h2 id="memory-hierarchy-optimization"><a class="header" href="#memory-hierarchy-optimization"><strong>Memory hierarchy optimization</strong></a></h2>
<p><strong>Shared memory architecture:</strong></p>
<ul>
<li>Two specialized buffers handle data flow between stages</li>
<li>Global memory access minimized to boundary operations only</li>
<li>All intermediate processing uses fast shared memory</li>
</ul>
<p><strong>Access pattern benefits:</strong></p>
<ul>
<li><strong>Stage 1</strong>: Coalesced global memory reads for input loading</li>
<li><strong>Stage 2</strong>: Fast shared memory reads for blur processing</li>
<li><strong>Stage 3</strong>: Coalesced global memory writes for output</li>
</ul>
<h2 id="real-world-applications"><a class="header" href="#real-world-applications"><strong>Real-world applications</strong></a></h2>
<p>This pipeline architecture pattern is fundamental to:</p>
<p><strong>Image processing pipelines:</strong></p>
<ul>
<li>Multi-stage filters (blur, sharpen, edge detection in sequence)</li>
<li>Color space conversions (RGB â†’ HSV â†’ processing â†’ RGB)</li>
<li>Noise reduction with multiple algorithm passes</li>
</ul>
<p><strong>Scientific computing:</strong></p>
<ul>
<li>Stencil computations with multi-stage finite difference methods</li>
<li>Signal processing with filtering, transformation, and analysis pipelines</li>
<li>Computational fluid dynamics with multi-stage solver iterations</li>
</ul>
<p><strong>Machine learning:</strong></p>
<ul>
<li>Neural network layers with specialized thread groups for different operations</li>
<li>Data preprocessing pipelines (load, normalize, augment in coordinated stages)</li>
<li>Batch processing where different thread groups handle different operations</li>
</ul>
<h2 id="key-technical-insights"><a class="header" href="#key-technical-insights"><strong>Key technical insights</strong></a></h2>
<p><strong>Algorithmic vs. data parallelism:</strong></p>
<ul>
<li><strong>Data parallelism</strong>: Threads execute identical code on different data elements</li>
<li><strong>Algorithmic parallelism</strong>: Threads execute fundamentally different algorithms based on their specialized roles</li>
</ul>
<p><strong>Barrier usage philosophy:</strong></p>
<ul>
<li><strong>Strategic placement</strong>: Barriers only where necessary to prevent race conditions between dependent stages</li>
<li><strong>Performance consideration</strong>: Each barrier incurs synchronization overhead - use sparingly but correctly</li>
<li><strong>Correctness guarantee</strong>: Proper barrier placement ensures deterministic results regardless of thread execution timing</li>
</ul>
<p><strong>Thread specialization benefits:</strong></p>
<ul>
<li><strong>Algorithmic optimization</strong>: Each stage can be optimized for its specific computational pattern</li>
<li><strong>Memory access optimization</strong>: Different stages can use different memory access strategies</li>
<li><strong>Resource utilization</strong>: Complex algorithms can be decomposed into specialized, efficient components</li>
</ul>
<p>This solution demonstrates how to design sophisticated GPU algorithms that leverage thread specialization and strategic synchronization for complex multi-stage computations, moving beyond simple parallel loops to architectural approaches used in production GPU software.</p>
</details>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../puzzle_29/puzzle_29.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../puzzle_29/memory_barrier.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../puzzle_29/puzzle_29.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../puzzle_29/memory_barrier.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../theme/mojolang.js"></script>
        <script src="../theme/sidebar.js"></script>
        <script src="../theme/solution.js"></script>
        <script src="../theme/init-amplitude.js"></script>
        <script src="../theme/tabs.js"></script>


    </div>
    </body>
</html>
