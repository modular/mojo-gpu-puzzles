<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>tile - Memory-Efficient Tiled Processing - Mojo 🔥 GPU Puzzles</title>


        <!-- Custom HTML head -->
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,100..700;1,100..700&display=swap"
            rel="stylesheet">
        
        <script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
        
        <link rel="stylesheet" href="../theme/css/custom.css">
        <link rel="stylesheet" href="../theme/css/highlight.css">
        <link rel="stylesheet" id="theme">
        
        <!-- Additional meta tags -->
        <meta property="og:title" content="Mojo🔥 GPU Puzzles">
        <meta property="og:description" content="Learn GPU Programming in Mojo🔥 Through Interactive Puzzles">
        <meta property="og:image" content="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">
        <meta property="og:url" content="https://puzzles.modular.com/">
        <meta name="twitter:card" content="summary">
        <meta name="twitter:image:alt" content="Mojo GPU Puzzles Logo">
        <meta name="twitter:title" content="Mojo🔥 GPU Puzzles">
        <meta name="twitter:description" content="Learn GPU Programming in Mojo🔥 Through Interactive Puzzles">
        <meta name="twitter:image" content="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">
        <link rel="icon" type="image/png" href="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&display=swap" rel="stylesheet">

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../theme/css/custom.css">
        <link rel="stylesheet" href="../theme/css/highlight.css">
        <link rel="stylesheet" href="../theme/css/tabs.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "ayu";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <button class="collapse-sidebar" aria-label="Collapse sidebar"></button>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Toggle color mode and talk to us buttons -->
        <script>
            document.addEventListener('click', function (event) {
                if (!event.target.matches('.theme-toggle')) return;
                event.preventDefault();
                const prevTheme = theme;
                html.classList.remove(theme);
                const newTheme = prevTheme === 'ayu' ? 'light' : 'ayu'
                html.classList.add(newTheme);
                theme = newTheme
                localStorage.setItem('mdbook-theme', theme);
            }, false);
            document.addEventListener('click', function() {
                if (!event.target.matches('.log-in')) return;
                event.preventDefault();
                window.amplitude.logEvent('LoginClickedFromPuzzles');
                window.open('https://developer.modular.com', '_blank');
            });
        </script>

        <div class="page-header">
            <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                <i class="fa fa-bars"></i>
            </label>
            <div id="menu-bar" class="menu-bar">
                <div class="left-buttons">
                    <div class="logo-section">
                        <a class="desktop-logo-link" href="https://modular.com"></a>
                        <a class="mobile-logo-link" href="https://builds.modular.com"></a>
                        <div class="slash">/</div>
                        <a class="internal-link" ref="/">Puzzles</a>
                    </div>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Dark</button></li>
                        </ul>
                    </div>
                <div class="right-buttons">
                    <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                        <i class="fa fa-search"></i>
                    </button>
                    <button id="theme-toggle" class="icon-button theme-toggle-btn" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="false" aria-expanded="false">
                        <i class="theme-toggle"></i>
                    </button>
                    <a class="menu-btn print" href="../print.html" title="Print this book" aria-label="Print this book">
                        <i id="print-button" class="fa fa-print"></i>
                    </a>
                    <a class="menu-btn" href="https://github.com/modular/mojo-gpu-puzzles" title="Git repository" aria-label="Git repository">
                        <i id="git-repository-button" class="fa fa-github"></i>
                    </a>
                    <button class="secondary-btn log-in">Log in</button>
                </div>
            </div>
        </div>

        <div id="page-wrapper" class="page-wrapper">
            <div class="page">

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <div id="content" class="content">
                    <main>
                        <h1 id="tile---memory-efficient-tiled-processing"><a class="header" href="#tile---memory-efficient-tiled-processing">Tile - Memory-Efficient Tiled Processing</a></h1>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Building on the <strong>elementwise</strong> pattern, this puzzle introduces <strong>tiled processing</strong> - a fundamental technique for optimizing memory access patterns and cache utilization on GPUs. Instead of each thread processing individual SIMD vectors across the entire array, tiling organizes data into smaller, manageable chunks that fit better in cache memory.</p>
<p>You’ve already seen tiling in action with <strong><a href="../puzzle_16/tiled.html">Puzzle 16’s tiled matrix multiplication</a></strong>, where we used tiles to process large matrices efficiently. Here, we apply the same tiling principles to vector operations, demonstrating how this technique scales from 2D matrices to 1D arrays.</p>
<p>Implement the same vector addition operation using Mojo’s tiled approach. Each GPU thread will process an entire tile of data sequentially, demonstrating how memory locality can improve performance for certain workloads.</p>
<p><strong>Key insight:</strong> <em>Tiling trades parallel breadth for memory locality - fewer threads each doing more work with better cache utilization.</em></p>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key concepts</a></h2>
<p>In this puzzle, you’ll master:</p>
<ul>
<li><strong>Tile-based memory organization</strong> for cache optimization</li>
<li><strong>Sequential SIMD processing</strong> within tiles</li>
<li><strong>Memory locality principles</strong> and cache-friendly access patterns</li>
<li><strong>Thread-to-tile mapping</strong> vs thread-to-element mapping</li>
<li><strong>Performance trade-offs</strong> between parallelism and memory efficiency</li>
</ul>
<p>The same mathematical operation as elementwise:
\[\Large \text{output}[i] = a[i] + b[i]\]</p>
<p>But with a completely different execution strategy optimized for memory hierarchy.</p>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<ul>
<li>Vector size: <code>SIZE = 1024</code></li>
<li>Tile size: <code>TILE_SIZE = 32</code></li>
<li>Data type: <code>DType.float32</code></li>
<li>SIMD width: GPU-dependent (for operations within tiles)</li>
<li>Layout: <code>Layout.row_major(SIZE)</code> (1D row-major)</li>
</ul>
<h2 id="code-to-complete"><a class="header" href="#code-to-complete">Code to complete</a></h2>
<pre><code class="language-mojo">alias TILE_SIZE = 32


fn tiled_elementwise_add[
    layout: Layout,
    dtype: DType,
    simd_width: Int,
    rank: Int,
    size: Int,
    tile_size: Int,
](
    output: LayoutTensor[mut=True, dtype, layout, MutableAnyOrigin],
    a: LayoutTensor[mut=False, dtype, layout, MutableAnyOrigin],
    b: LayoutTensor[mut=False, dtype, layout, MutableAnyOrigin],
    ctx: DeviceContext,
) raises:
    @parameter
    @always_inline
    fn process_tiles[
        simd_width: Int, rank: Int, alignment: Int = align_of[dtype]()
    ](indices: IndexList[rank]) capturing -&gt; None:
        tile_id = indices[0]
        print("tile_id:", tile_id)
        output_tile = output.tile[tile_size](tile_id)
        a_tile = a.tile[tile_size](tile_id)
        b_tile = b.tile[tile_size](tile_id)

        # FILL IN (6 lines at most)

    num_tiles = (size + tile_size - 1) // tile_size
    elementwise[process_tiles, 1, target="gpu"](num_tiles, ctx)


</code></pre>
<p><a href="https://github.com/modular/mojo-gpu-puzzles/blob/main/problems/p23/p23.mojo" class="filename">View full file: problems/p23/p23.mojo</a></p>
<details>
<summary><strong>Tips</strong></summary>
<div class="solution-tips">
<h3 id="1-understanding-tile-organization"><a class="header" href="#1-understanding-tile-organization">1. <strong>Understanding tile organization</strong></a></h3>
<p>The tiled approach divides your data into fixed-size chunks:</p>
<pre><code class="language-mojo">num_tiles = (size + tile_size - 1) // tile_size  # Ceiling division
</code></pre>
<p>For a 1024-element vector with <code>TILE_SIZE=32</code>: <code>1024 ÷ 32 = 32</code> tiles exactly.</p>
<h3 id="2-tile-extraction-pattern"><a class="header" href="#2-tile-extraction-pattern">2. <strong>Tile extraction pattern</strong></a></h3>
<p>Check out the <a href="https://docs.modular.com/mojo/kernels/layout/layout_tensor/LayoutTensor/#tile">LayoutTensor <code>.tile</code> documentation</a>.</p>
<pre><code class="language-mojo">tile_id = indices[0]  # Each thread gets one tile to process
out_tile = output.tile[tile_size](tile_id)
a_tile = a.tile[tile_size](tile_id)
b_tile = b.tile[tile_size](tile_id)
</code></pre>
<p>The <code>tile[size](id)</code> method creates a view of <code>size</code> consecutive elements starting at <code>id × size</code>.</p>
<h3 id="3-sequential-processing-within-tiles"><a class="header" href="#3-sequential-processing-within-tiles">3. <strong>Sequential processing within tiles</strong></a></h3>
<p>Unlike elementwise, you process the tile sequentially:</p>
<pre><code class="language-mojo">@parameter
for i in range(tile_size):
    # Process element i within the current tile
</code></pre>
<p>This <code>@parameter</code> loop unrolls at compile-time for optimal performance.</p>
<h3 id="4-simd-operations-within-tile-elements"><a class="header" href="#4-simd-operations-within-tile-elements">4. <strong>SIMD operations within tile elements</strong></a></h3>
<pre><code class="language-mojo">a_vec = a_tile.load[simd_width](i, 0)  # Load from position i in tile
b_vec = b_tile.load[simd_width](i, 0)  # Load from position i in tile
result = a_vec + b_vec                 # SIMD addition (GPU-dependent width)
out_tile.store[simd_width](i, 0, result)  # Store to position i in tile
</code></pre>
<h3 id="5-thread-configuration-difference"><a class="header" href="#5-thread-configuration-difference">5. <strong>Thread configuration difference</strong></a></h3>
<pre><code class="language-mojo">elementwise[process_tiles, 1, target="gpu"](num_tiles, ctx)
</code></pre>
<p>Note the <code>1</code> instead of <code>SIMD_WIDTH</code> - each thread processes one entire tile sequentially.</p>
<h3 id="6-memory-access-pattern-insight"><a class="header" href="#6-memory-access-pattern-insight">6. <strong>Memory access pattern insight</strong></a></h3>
<p>Each thread accesses a contiguous block of memory (the tile), then moves to the next tile. This creates excellent <strong>spatial locality</strong> within each thread’s execution.</p>
<h3 id="7-key-debugging-insight"><a class="header" href="#7-key-debugging-insight">7. <strong>Key debugging insight</strong></a></h3>
<p>With tiling, you’ll see fewer thread launches but each does more work:</p>
<ul>
<li>Elementwise: ~256 threads (for SIMD_WIDTH=4), each processing 4 elements</li>
<li>Tiled: ~32 threads, each processing 32 elements sequentially</li>
</ul>
</div>
</details>
<h2 id="running-the-code"><a class="header" href="#running-the-code">Running the code</a></h2>
<p>To test your solution, run the following command in your terminal:</p>
<div class="code-tabs" data-tab-group="package-manager">
  <div class="tab-buttons">
    <button class="tab-button">uv</button>
    <button class="tab-button">pixi</button>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">uv run poe p23 --tiled
</code></pre>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">pixi run p23 --tiled
</code></pre>
  </div>
</div>
<p>Your output will look like this when not yet solved:</p>
<pre><code class="language-txt">SIZE: 1024
simd_width: 4
tile size: 32
tile_id: 0
tile_id: 1
tile_id: 2
tile_id: 3
...
tile_id: 29
tile_id: 30
tile_id: 31
out: HostBuffer([0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0])
expected: HostBuffer([1.0, 5.0, 9.0, ..., 4085.0, 4089.0, 4093.0])
</code></pre>
<h2 id="solution"><a class="header" href="#solution">Solution</a></h2>
<details class="solution-details">
<summary></summary>
<pre><code class="language-mojo">alias TILE_SIZE = 32


fn tiled_elementwise_add[
    layout: Layout,
    dtype: DType,
    simd_width: Int,
    rank: Int,
    size: Int,
    tile_size: Int,
](
    output: LayoutTensor[mut=True, dtype, layout, MutableAnyOrigin],
    a: LayoutTensor[mut=False, dtype, layout, MutableAnyOrigin],
    b: LayoutTensor[mut=False, dtype, layout, MutableAnyOrigin],
    ctx: DeviceContext,
) raises:
    @parameter
    @always_inline
    fn process_tiles[
        simd_width: Int, rank: Int, alignment: Int = align_of[dtype]()
    ](indices: IndexList[rank]) capturing -&gt; None:
        tile_id = indices[0]

        output_tile = output.tile[tile_size](tile_id)
        a_tile = a.tile[tile_size](tile_id)
        b_tile = b.tile[tile_size](tile_id)

        @parameter
        for i in range(tile_size):
            a_vec = a_tile.load[simd_width](i, 0)
            b_vec = b_tile.load[simd_width](i, 0)
            ret = a_vec + b_vec
            output_tile.store[simd_width](i, 0, ret)

    num_tiles = (size + tile_size - 1) // tile_size
    elementwise[process_tiles, 1, target="gpu"](num_tiles, ctx)


</code></pre>
<div class="solution-explanation">
<p>The tiled processing pattern demonstrates advanced memory optimization techniques for GPU programming:</p>
<h3 id="1-tiling-philosophy-and-memory-hierarchy"><a class="header" href="#1-tiling-philosophy-and-memory-hierarchy">1. <strong>Tiling philosophy and memory hierarchy</strong></a></h3>
<p>Tiling represents a fundamental shift in how we think about parallel processing:</p>
<p><strong>Elementwise approach:</strong></p>
<ul>
<li><strong>Wide parallelism</strong>: Many threads, each doing minimal work</li>
<li><strong>Global memory pressure</strong>: Threads scattered across entire array</li>
<li><strong>Cache misses</strong>: Poor spatial locality across thread boundaries</li>
</ul>
<p><strong>Tiled approach:</strong></p>
<ul>
<li><strong>Deep parallelism</strong>: Fewer threads, each doing substantial work</li>
<li><strong>Localized memory access</strong>: Each thread works on contiguous data</li>
<li><strong>Cache optimization</strong>: Excellent spatial and temporal locality</li>
</ul>
<h3 id="2-tile-organization-and-indexing"><a class="header" href="#2-tile-organization-and-indexing">2. <strong>Tile organization and indexing</strong></a></h3>
<pre><code class="language-mojo">tile_id = indices[0]
out_tile = output.tile[tile_size](tile_id)
a_tile = a.tile[tile_size](tile_id)
b_tile = b.tile[tile_size](tile_id)
</code></pre>
<p><strong>Tile mapping visualization (TILE_SIZE=32):</strong></p>
<pre><code>Original array: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, ..., 1023]

Tile 0 (thread 0): [0, 1, 2, ..., 31]      ← Elements 0-31
Tile 1 (thread 1): [32, 33, 34, ..., 63]   ← Elements 32-63
Tile 2 (thread 2): [64, 65, 66, ..., 95]   ← Elements 64-95
...
Tile 31 (thread 31): [992, 993, ..., 1023] ← Elements 992-1023
</code></pre>
<p><strong>Key insights:</strong></p>
<ul>
<li>Each <code>tile[size](id)</code> creates a <strong>view</strong> into the original tensor</li>
<li>Views are zero-copy - no data movement, just pointer arithmetic</li>
<li>Tile boundaries are always aligned to <code>tile_size</code> boundaries</li>
</ul>
<h3 id="3-sequential-processing-deep-dive"><a class="header" href="#3-sequential-processing-deep-dive">3. <strong>Sequential processing deep dive</strong></a></h3>
<pre><code class="language-mojo">@parameter
for i in range(tile_size):
    a_vec = a_tile.load[simd_width](i, 0)
    b_vec = b_tile.load[simd_width](i, 0)
    ret = a_vec + b_vec
    out_tile.store[simd_width](i, 0, ret)
</code></pre>
<p><strong>Why sequential processing?</strong></p>
<ul>
<li><strong>Cache optimization</strong>: Consecutive memory accesses maximize cache hit rates</li>
<li><strong>Compiler optimization</strong>: <code>@parameter</code> loops unroll completely at compile-time</li>
<li><strong>Memory bandwidth</strong>: Sequential access aligns with memory controller design</li>
<li><strong>Reduced coordination</strong>: No need to synchronize between SIMD groups</li>
</ul>
<p><strong>Execution pattern within one tile (TILE_SIZE=32, SIMD_WIDTH=4):</strong></p>
<pre><code>Thread processes tile sequentially:
Step 0: Process elements [0:4] with SIMD
Step 1: Process elements [4:8] with SIMD
Step 2: Process elements [8:12] with SIMD
...
Step 7: Process elements [28:32] with SIMD
Total: 8 SIMD operations per thread (32 ÷ 4 = 8)
</code></pre>
<h3 id="4-memory-access-pattern-analysis"><a class="header" href="#4-memory-access-pattern-analysis">4. <strong>Memory access pattern analysis</strong></a></h3>
<p><strong>Cache behavior comparison:</strong></p>
<p><strong>Elementwise pattern:</strong></p>
<pre><code>Thread 0: accesses global positions [0, 4, 8, 12, ...]    ← Stride = SIMD_WIDTH
Thread 1: accesses global positions [4, 8, 12, 16, ...]   ← Stride = SIMD_WIDTH
...
Result: Memory accesses spread across entire array
</code></pre>
<p><strong>Tiled pattern:</strong></p>
<pre><code>Thread 0: accesses positions [0:32] sequentially         ← Contiguous 32-element block
Thread 1: accesses positions [32:64] sequentially       ← Next contiguous 32-element block
...
Result: Perfect spatial locality within each thread
</code></pre>
<p><strong>Cache efficiency implications:</strong></p>
<ul>
<li><strong>L1 cache</strong>: Small tiles often fit better in L1 cache, reducing cache misses</li>
<li><strong>Memory bandwidth</strong>: Sequential access maximizes effective bandwidth</li>
<li><strong>TLB efficiency</strong>: Fewer translation lookbook buffer misses</li>
<li><strong>Prefetching</strong>: Hardware prefetchers work optimally with sequential patterns</li>
</ul>
<h3 id="5-thread-configuration-strategy"><a class="header" href="#5-thread-configuration-strategy">5. <strong>Thread configuration strategy</strong></a></h3>
<pre><code class="language-mojo">elementwise[process_tiles, 1, target="gpu"](num_tiles, ctx)
</code></pre>
<p><strong>Why <code>1</code> instead of <code>SIMD_WIDTH</code>?</strong></p>
<ul>
<li><strong>Thread count</strong>: Launch exactly <code>num_tiles</code> threads, not <code>num_tiles × SIMD_WIDTH</code></li>
<li><strong>Work distribution</strong>: Each thread handles one complete tile</li>
<li><strong>Load balancing</strong>: More work per thread, fewer threads total</li>
<li><strong>Memory locality</strong>: Each thread’s work is spatially localized</li>
</ul>
<p><strong>Performance trade-offs:</strong></p>
<ul>
<li><strong>Fewer logical threads</strong>: May not fully utilize all GPU cores at low occupancy</li>
<li><strong>More work per thread</strong>: Better cache utilization and reduced coordination overhead</li>
<li><strong>Sequential access</strong>: Optimal memory bandwidth utilization within each thread</li>
<li><strong>Reduced overhead</strong>: Less thread launch and coordination overhead</li>
</ul>
<p><strong>Important note</strong>: “Fewer threads” refers to the logical programming model. The GPU scheduler can still achieve high hardware utilization by running multiple warps and efficiently switching between them during memory stalls.</p>
<h3 id="6-performance-characteristics"><a class="header" href="#6-performance-characteristics">6. <strong>Performance characteristics</strong></a></h3>
<p><strong>When tiling helps:</strong></p>
<ul>
<li><strong>Memory-bound operations</strong>: When memory bandwidth is the bottleneck</li>
<li><strong>Cache-sensitive workloads</strong>: Operations that benefit from data reuse</li>
<li><strong>Complex operations</strong>: When compute per element is higher</li>
<li><strong>Limited parallelism</strong>: When you have fewer threads than GPU cores</li>
</ul>
<p><strong>When tiling hurts:</strong></p>
<ul>
<li><strong>Highly parallel workloads</strong>: When you need maximum thread utilization</li>
<li><strong>Simple operations</strong>: When memory access dominates over computation</li>
<li><strong>Irregular access patterns</strong>: When tiling doesn’t improve locality</li>
</ul>
<p><strong>For our simple addition example (TILE_SIZE=32):</strong></p>
<ul>
<li><strong>Thread count</strong>: 32 threads instead of 256 (8× fewer)</li>
<li><strong>Work per thread</strong>: 32 elements instead of 4 (8× more)</li>
<li><strong>Memory pattern</strong>: Sequential vs strided access</li>
<li><strong>Cache utilization</strong>: Much better spatial locality</li>
</ul>
<h3 id="7-advanced-tiling-considerations"><a class="header" href="#7-advanced-tiling-considerations">7. <strong>Advanced tiling considerations</strong></a></h3>
<p><strong>Tile size selection:</strong></p>
<ul>
<li><strong>Too small</strong>: Poor cache utilization, more overhead</li>
<li><strong>Too large</strong>: May not fit in cache, reduced parallelism</li>
<li><strong>Sweet spot</strong>: Usually 16-64 elements for L1 cache optimization</li>
<li><strong>Our choice</strong>: 32 elements balances cache usage with parallelism</li>
</ul>
<p><strong>Hardware considerations:</strong></p>
<ul>
<li><strong>Cache size</strong>: Tiles should fit in L1 cache when possible</li>
<li><strong>Memory bandwidth</strong>: Consider memory controller width</li>
<li><strong>Core count</strong>: Ensure enough tiles to utilize all cores</li>
<li><strong>SIMD width</strong>: Tile size should be multiple of SIMD width</li>
</ul>
<p><strong>Comparison summary:</strong></p>
<pre><code>Elementwise: High parallelism, scattered memory access
Tiled:       Moderate parallelism, localized memory access
</code></pre>
<p>The choice between elementwise and tiled patterns depends on your specific workload characteristics, data access patterns, and target hardware capabilities.</p>
</div>
</details>
<h2 id="next-steps"><a class="header" href="#next-steps">Next steps</a></h2>
<p>Now that you understand both elementwise and tiled patterns:</p>
<ul>
<li><strong><a href="./vectorize.html">Vectorization</a></strong>: Fine-grained control over SIMD operations</li>
<li><strong><a href="./gpu-thread-vs-simd.html">🧠 GPU Threading vs SIMD</a></strong>: Understanding the execution hierarchy</li>
<li><strong><a href="./benchmarking.html">📊 Benchmarking</a></strong>: Performance analysis and optimization</li>
</ul>
<p>💡 <strong>Key takeaway</strong>: Tiling demonstrates how memory access patterns often matter more than raw computational throughput. The best GPU code balances parallelism with memory hierarchy optimization.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../puzzle_23/elementwise.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../puzzle_23/vectorize.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../puzzle_23/elementwise.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../puzzle_23/vectorize.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../theme/mojolang.js"></script>
        <script src="../theme/sidebar.js"></script>
        <script src="../theme/solution.js"></script>
        <script src="../theme/init-amplitude.js"></script>
        <script src="../theme/tabs.js"></script>


    </div>
    </body>
</html>
