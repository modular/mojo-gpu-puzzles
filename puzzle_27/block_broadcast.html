<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>📡 block.broadcast() Vector Normalization - Mojo 🔥 GPU Puzzles</title>


        <!-- Custom HTML head -->
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,100..700;1,100..700&display=swap"
            rel="stylesheet">
        
        <script src="https://unpkg.com/@lottiefiles/lottie-player@latest/dist/lottie-player.js"></script>
        
        <link rel="stylesheet" href="../theme/css/custom.css">
        <link rel="stylesheet" href="../theme/css/highlight.css">
        <link rel="stylesheet" id="theme">
        
        <!-- Additional meta tags -->
        <meta property="og:title" content="Mojo🔥 GPU Puzzles">
        <meta property="og:description" content="Learn GPU Programming in Mojo🔥 Through Interactive Puzzles">
        <meta property="og:image" content="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">
        <meta property="og:url" content="https://puzzles.modular.com/">
        <meta name="twitter:card" content="summary">
        <meta name="twitter:image:alt" content="Mojo GPU Puzzles Logo">
        <meta name="twitter:title" content="Mojo🔥 GPU Puzzles">
        <meta name="twitter:description" content="Learn GPU Programming in Mojo🔥 Through Interactive Puzzles">
        <meta name="twitter:image" content="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">
        <link rel="icon" type="image/png" href="https://puzzles.modular.com/puzzles_images/puzzle-mark.png">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&display=swap" rel="stylesheet">

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../theme/css/custom.css">
        <link rel="stylesheet" href="../theme/css/highlight.css">
        <link rel="stylesheet" href="../theme/css/tabs.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "ayu";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <button class="collapse-sidebar" aria-label="Collapse sidebar"></button>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Toggle color mode and talk to us buttons -->
        <script>
            document.addEventListener('click', function (event) {
                if (!event.target.matches('.theme-toggle')) return;
                event.preventDefault();
                const prevTheme = theme;
                html.classList.remove(theme);
                const newTheme = prevTheme === 'ayu' ? 'light' : 'ayu'
                html.classList.add(newTheme);
                theme = newTheme
                localStorage.setItem('mdbook-theme', theme);
            }, false);
            document.addEventListener('click', function() {
                if (!event.target.matches('.log-in')) return;
                event.preventDefault();
                window.amplitude.logEvent('LoginClickedFromPuzzles');
                window.open('https://developer.modular.com', '_blank');
            });
        </script>

        <div class="page-header">
            <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                <i class="fa fa-bars"></i>
            </label>
            <div id="menu-bar" class="menu-bar">
                <div class="left-buttons">
                    <div class="logo-section">
                        <a class="desktop-logo-link" href="https://modular.com"></a>
                        <a class="mobile-logo-link" href="https://builds.modular.com"></a>
                        <div class="slash">/</div>
                        <a class="internal-link" ref="/">Puzzles</a>
                    </div>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Dark</button></li>
                        </ul>
                    </div>
                <div class="right-buttons">
                    <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                        <i class="fa fa-search"></i>
                    </button>
                    <button id="theme-toggle" class="icon-button theme-toggle-btn" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="false" aria-expanded="false">
                        <i class="theme-toggle"></i>
                    </button>
                    <a class="menu-btn print" href="../print.html" title="Print this book" aria-label="Print this book">
                        <i id="print-button" class="fa fa-print"></i>
                    </a>
                    <a class="menu-btn" href="https://github.com/modular/mojo-gpu-puzzles" title="Git repository" aria-label="Git repository">
                        <i id="git-repository-button" class="fa fa-github"></i>
                    </a>
                    <button class="secondary-btn log-in">Log in</button>
                </div>
            </div>
        </div>

        <div id="page-wrapper" class="page-wrapper">
            <div class="page">

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <div id="content" class="content">
                    <main>
                        <h1 id="blockbroadcast-vector-normalization"><a class="header" href="#blockbroadcast-vector-normalization">block.broadcast() Vector Normalization</a></h1>
<p>Implement vector mean normalization by combining <a href="https://docs.modular.com/mojo/stdlib/gpu/block/sum">block.sum</a> and <a href="https://docs.modular.com/mojo/stdlib/gpu/block/broadcast">block.broadcast</a> operations to demonstrate the complete block-level communication workflow. Each thread will contribute to computing the mean, then receive the broadcast mean to normalize its element, showcasing how block operations work together to solve real parallel algorithms.</p>
<p><strong>Key insight:</strong> <em>The <a href="https://docs.modular.com/mojo/stdlib/gpu/block/broadcast">block.broadcast()</a> operation enables one-to-all communication, completing the fundamental block communication patterns: reduction (all→one), scan (all→each), and broadcast (one→all).</em></p>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key concepts</a></h2>
<p>In this puzzle, you’ll learn:</p>
<ul>
<li><strong>Block-level broadcast</strong> with <code>block.broadcast()</code></li>
<li><strong>One-to-all communication</strong> patterns</li>
<li><strong>Source thread specification</strong> and parameter control</li>
<li><strong>Complete block operations workflow</strong> combining multiple operations</li>
<li><strong>Real-world algorithm implementation</strong> using coordinated block primitives</li>
</ul>
<p>The algorithm demonstrates vector mean normalization:
\[\Large \text{output}[i] = \frac{\text{input}[i]}{\frac{1}{N}\sum_{j=0}^{N-1} \text{input}[j]}\]</p>
<p>Each thread contributes to the mean calculation, then receives the broadcast mean to normalize its element.</p>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<ul>
<li>Vector size: <code>SIZE = 128</code> elements</li>
<li>Data type: <code>DType.float32</code></li>
<li>Block configuration: <code>(128, 1)</code> threads per block (<code>TPB = 128</code>)</li>
<li>Grid configuration: <code>(1, 1)</code> blocks per grid</li>
<li>Layout: <code>Layout.row_major(SIZE)</code> (1D row-major for input and output)</li>
<li>Test data: Values cycling 1-8, so mean = 4.5</li>
<li>Expected output: Normalized vector with mean = 1.0</li>
</ul>
<h2 id="the-challenge-coordinating-block-wide-computation-and-distribution"><a class="header" href="#the-challenge-coordinating-block-wide-computation-and-distribution">The challenge: Coordinating block-wide computation and distribution</a></h2>
<p>Traditional approaches to mean normalization require complex coordination:</p>
<pre><code class="language-python"># Sequential approach - doesn't utilize parallelism
total = sum(input_array)
mean = total / len(input_array)
output_array = [x / mean for x in input_array]
</code></pre>
<p><strong>Problems with naive GPU parallelization:</strong></p>
<ul>
<li><strong>Multiple kernel launches</strong>: One pass to compute mean, another to normalize</li>
<li><strong>Global memory round-trip</strong>: Store mean to global memory, read back later</li>
<li><strong>Synchronization complexity</strong>: Need barriers between computation phases</li>
<li><strong>Thread divergence</strong>: Different threads doing different tasks</li>
</ul>
<p><strong>Traditional GPU solution complexity:</strong></p>
<pre><code class="language-mojo"># Phase 1: Reduce to find sum (complex shared memory + barriers)
shared_sum[local_i] = my_value
barrier()
# Manual tree reduction with multiple barrier() calls...

# Phase 2: Thread 0 computes mean
if local_i == 0:
    mean = shared_sum[0] / size
    shared_mean[0] = mean

barrier()

# Phase 3: All threads read mean and normalize
mean = shared_mean[0]  # Everyone reads the same value
output[global_i] = my_value / mean
</code></pre>
<h2 id="the-advanced-approach-blocksum--blockbroadcast-coordination"><a class="header" href="#the-advanced-approach-blocksum--blockbroadcast-coordination">The advanced approach: <code>block.sum()</code> + <code>block.broadcast()</code> coordination</a></h2>
<p>Transform the multi-phase coordination into elegant block operations workflow:</p>
<h2 id="code-to-complete"><a class="header" href="#code-to-complete">Code to complete</a></h2>
<h3 id="complete-block-operations-workflow"><a class="header" href="#complete-block-operations-workflow">Complete block operations workflow</a></h3>
<p>Implement sophisticated vector mean normalization using the full block operations toolkit:</p>
<pre><code class="language-mojo">
alias vector_layout = Layout.row_major(SIZE)


fn block_normalize_vector[
    in_layout: Layout, out_layout: Layout, tpb: Int
](
    input_data: LayoutTensor[mut=False, dtype, in_layout],
    output_data: LayoutTensor[mut=True, dtype, out_layout],
    size: Int,
):
    """Vector mean normalization using block.sum() + block.broadcast() combination.

    This demonstrates the complete block operations workflow:
    1. Use block.sum() to compute sum of all elements (all → one)
    2. Thread 0 computes mean = sum / size
    3. Use block.broadcast() to share mean to all threads (one → all)
    4. Each thread normalizes: output[i] = input[i] / mean
    """

    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x

    # Step 1: Each thread loads its element

    # FILL IN (roughly 3 lines)

    # Step 2: Use block.sum() to compute total sum (familiar from earlier!)

    # FILL IN (1 line)

    # Step 3: Thread 0 computes mean value

    # FILL IN (roughly 4 lines)

    # Step 4: block.broadcast() shares mean to ALL threads!
    # This completes the block operations trilogy demonstration

    # FILL IN (1 line)

    # Step 5: Each thread normalizes by the mean

    # FILL IN (roughly 3 lines)


</code></pre>
<p><a href="https://github.com/modular/mojo-gpu-puzzles/blob/main/problems/p27/p27.mojo" class="filename">View full file: problems/p27/p27.mojo</a></p>
<details>
<summary><strong>Tips</strong></summary>
<div class="solution-tips">
<h3 id="1-complete-workflow-structure-builds-on-all-previous-operations"><a class="header" href="#1-complete-workflow-structure-builds-on-all-previous-operations">1. <strong>Complete workflow structure (builds on all previous operations)</strong></a></h3>
<p>The algorithm follows the perfect block operations pattern:</p>
<ol>
<li>Each thread loads its element (familiar from all previous puzzles)</li>
<li>Use <code>block.sum()</code> to compute total (from earlier in this puzzle)</li>
<li>Thread 0 computes mean from the sum</li>
<li>Use <code>block.broadcast()</code> to share mean to all threads (NEW!)</li>
<li>Each thread normalizes using the broadcast mean</li>
</ol>
<h3 id="2-data-loading-and-sum-computation-familiar-patterns"><a class="header" href="#2-data-loading-and-sum-computation-familiar-patterns">2. <strong>Data loading and sum computation (familiar patterns)</strong></a></h3>
<p>Load your element using the established LayoutTensor pattern:</p>
<pre><code class="language-mojo">var my_value: Scalar[dtype] = 0.0
if global_i &lt; size:
    my_value = input_data[global_i][0]  # SIMD extraction
</code></pre>
<p>Then use <code>block.sum()</code> exactly like the dot product earlier:</p>
<pre><code class="language-mojo">total_sum = block.sum[block_size=tpb, broadcast=False](...)
</code></pre>
<h3 id="3-mean-computation-thread-0-only"><a class="header" href="#3-mean-computation-thread-0-only">3. <strong>Mean computation (thread 0 only)</strong></a></h3>
<p>Only thread 0 should compute the mean:</p>
<pre><code class="language-mojo">var mean_value: Scalar[dtype] = 1.0  # Safe default
if local_i == 0:
    # Compute mean from total_sum and size
</code></pre>
<p><strong>Why thread 0?</strong> Consistent with <code>block.sum()</code> pattern where thread 0 receives the result.</p>
<h3 id="4-blockbroadcast-api-concepts"><a class="header" href="#4-blockbroadcast-api-concepts">4. <strong><a href="https://docs.modular.com/mojo/stdlib/gpu/block/broadcast">block.broadcast()</a> API concepts</strong></a></h3>
<p>Study the function signature - it needs:</p>
<ul>
<li>Template parameters: <code>dtype</code>, <code>width</code>, <code>block_size</code></li>
<li>Runtime parameters: <code>val</code> (SIMD value to broadcast), <code>src_thread</code> (default=0)</li>
</ul>
<p>The call pattern follows the established template style:</p>
<pre><code class="language-mojo">result = block.broadcast[
    dtype = DType.float32,
    width = 1,
    block_size = tpb
](val=SIMD[DType.float32, 1](value_to_broadcast), src_thread=UInt(0))
</code></pre>
<h3 id="5-understanding-the-broadcast-pattern"><a class="header" href="#5-understanding-the-broadcast-pattern">5. <strong>Understanding the broadcast pattern</strong></a></h3>
<p><strong>Key insight</strong>: <code>block.broadcast()</code> takes a value from ONE thread and gives it to ALL threads:</p>
<ul>
<li><strong>Thread 0</strong> has the computed mean value</li>
<li><strong>All threads</strong> need that same mean value</li>
<li><strong><code>block.broadcast()</code></strong> copies thread 0’s value to everyone</li>
</ul>
<p>This is the opposite of <code>block.sum()</code> (all→one) and different from <code>block.prefix_sum()</code> (all→each position).</p>
<h3 id="6-final-normalization-step"><a class="header" href="#6-final-normalization-step">6. <strong>Final normalization step</strong></a></h3>
<p>Once every thread has the broadcast mean, normalize your element:</p>
<pre><code class="language-mojo">if global_i &lt; size:
    normalized_value = my_value / broadcasted_mean[0]  # Extract SIMD
    output_data[global_i] = normalized_value
</code></pre>
<p><strong>SIMD extraction</strong>: Remember that <code>block.broadcast()</code> returns SIMD, so use <code>[0]</code> to extract the scalar.</p>
<h3 id="7-pattern-recognition-from-previous-puzzles"><a class="header" href="#7-pattern-recognition-from-previous-puzzles">7. <strong>Pattern recognition from previous puzzles</strong></a></h3>
<ul>
<li><strong>Thread indexing</strong>: Same <code>global_i</code>, <code>local_i</code> pattern as always</li>
<li><strong>Bounds checking</strong>: Same <code>if global_i &lt; size</code> validation</li>
<li><strong>SIMD handling</strong>: Same <code>[0]</code> extraction patterns</li>
<li><strong>Block operations</strong>: Same template parameter style as <code>block.sum()</code></li>
</ul>
<p>The beauty is that each block operation follows consistent patterns!</p>
</div>
</details>
<p><strong>Test the block.broadcast() approach:</strong></p>
<div class="code-tabs" data-tab-group="package-manager">
  <div class="tab-buttons">
    <button class="tab-button">pixi NVIDIA (default)</button>
    <button class="tab-button">pixi AMD</button>
    <button class="tab-button">uv</button>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">pixi run p27 --normalize
</code></pre>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">pixi run p27 --normalize -e amd
</code></pre>
  </div>
  <div class="tab-content">
<pre><code class="language-bash">uv run poe p27 --normalize
</code></pre>
  </div>
</div>
<p>Expected output when solved:</p>
<pre><code class="language-txt">SIZE: 128
TPB: 128

Input sample: 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 ...
Sum value: 576.0
Mean value: 4.5

Mean Normalization Results:
Normalized sample: 0.22222222 0.44444445 0.6666667 0.8888889 1.1111112 1.3333334 1.5555556 1.7777778 ...

Output sum: 128.0
Output mean: 1.0
✅ Success: Output mean is 1.0 (should be close to 1.0)
</code></pre>
<h2 id="solution"><a class="header" href="#solution">Solution</a></h2>
<details class="solution-details">
<summary></summary>
<pre><code class="language-mojo">fn block_normalize_vector[
    in_layout: Layout, out_layout: Layout, tpb: Int
](
    input_data: LayoutTensor[mut=False, dtype, in_layout],
    output_data: LayoutTensor[mut=True, dtype, out_layout],
    size: Int,
):
    """Vector mean normalization using block.sum() + block.broadcast() combination.

    This demonstrates the complete block operations workflow:
    1. Use block.sum() to compute sum of all elements (all → one)
    2. Thread 0 computes mean = sum / size
    3. Use block.broadcast() to share mean to all threads (one → all)
    4. Each thread normalizes: output[i] = input[i] / mean
    """

    global_i = block_dim.x * block_idx.x + thread_idx.x
    local_i = thread_idx.x

    # Step 1: Each thread loads its element
    var my_value: Scalar[dtype] = 0.0
    if global_i &lt; size:
        my_value = input_data[global_i][0]  # Extract SIMD value

    # Step 2: Use block.sum() to compute total sum (familiar from earlier!)
    total_sum = block.sum[block_size=tpb, broadcast=False](
        val=SIMD[DType.float32, 1](my_value)
    )

    # Step 3: Thread 0 computes mean value
    var mean_value: Scalar[dtype] = 1.0  # Default to avoid division by zero
    if local_i == 0:
        if total_sum[0] &gt; 0.0:
            mean_value = total_sum[0] / Float32(size)

    # Step 4: block.broadcast() shares mean to ALL threads!
    # This completes the block operations trilogy demonstration
    broadcasted_mean = block.broadcast[
        dtype = DType.float32, width=1, block_size=tpb
    ](val=SIMD[DType.float32, 1](mean_value), src_thread=UInt(0))

    # Step 5: Each thread normalizes by the mean
    if global_i &lt; size:
        normalized_value = my_value / broadcasted_mean[0]
        output_data[global_i] = normalized_value


</code></pre>
<div class="solution-explanation">
<p>The <code>block.broadcast()</code> kernel demonstrates the complete block operations workflow by combining all three fundamental communication patterns in a real algorithm that produces mathematically verifiable results:</p>
<h2 id="complete-algorithm-walkthrough-with-concrete-execution"><a class="header" href="#complete-algorithm-walkthrough-with-concrete-execution"><strong>Complete algorithm walkthrough with concrete execution:</strong></a></h2>
<h3 id="phase-1-parallel-data-loading-established-patterns-from-all-previous-puzzles"><a class="header" href="#phase-1-parallel-data-loading-established-patterns-from-all-previous-puzzles"><strong>Phase 1: Parallel data loading (established patterns from all previous puzzles)</strong></a></h3>
<pre><code>Thread indexing (consistent across all puzzles):
  global_i = block_dim.x * block_idx.x + thread_idx.x  // Maps to input array position
  local_i = thread_idx.x                              // Position within block (0-127)

Parallel element loading using LayoutTensor pattern:
  Thread 0:   my_value = input_data[0][0] = 1.0    // First cycle value
  Thread 1:   my_value = input_data[1][0] = 2.0    // Second cycle value
  Thread 7:   my_value = input_data[7][0] = 8.0    // Last cycle value
  Thread 8:   my_value = input_data[8][0] = 1.0    // Cycle repeats: 1,2,3,4,5,6,7,8,1,2...
  Thread 15:  my_value = input_data[15][0] = 8.0   // 15 % 8 = 7, so 8th value
  Thread 127: my_value = input_data[127][0] = 8.0  // 127 % 8 = 7, so 8th value

All 128 threads load simultaneously - perfect parallel efficiency!
</code></pre>
<h3 id="phase-2-block-wide-sum-reduction-leveraging-earlier-blocksum-knowledge"><a class="header" href="#phase-2-block-wide-sum-reduction-leveraging-earlier-blocksum-knowledge"><strong>Phase 2: Block-wide sum reduction (leveraging earlier block.sum() knowledge)</strong></a></h3>
<pre><code>block.sum() coordination across all 128 threads:
  Contribution analysis:
    - Values 1,2,3,4,5,6,7,8 repeat 16 times each (128/8 = 16)
    - Thread contributions: 16×1 + 16×2 + 16×3 + 16×4 + 16×5 + 16×6 + 16×7 + 16×8
    - Mathematical sum: 16 × (1+2+3+4+5+6+7+8) = 16 × 36 = 576.0

block.sum() hardware execution:
  All threads → [reduction tree] → Thread 0
  total_sum = SIMD[DType.float32, 1](576.0)  // Only thread 0 receives this

Threads 1-127: Have no access to total_sum (broadcast=False in block.sum)
</code></pre>
<h3 id="phase-3-exclusive-mean-computation-single-thread-processing"><a class="header" href="#phase-3-exclusive-mean-computation-single-thread-processing"><strong>Phase 3: Exclusive mean computation (single-thread processing)</strong></a></h3>
<pre><code>Thread 0 performs critical computation:
  Input: total_sum[0] = 576.0, size = 128
  Computation: mean_value = 576.0 / 128.0 = 4.5

  Verification: Expected mean = (1+2+3+4+5+6+7+8)/8 = 36/8 = 4.5 ✓

All other threads (1-127):
  mean_value = 1.0 (default safety value)
  These values are irrelevant - will be overwritten by broadcast

Critical insight: Only thread 0 has the correct mean value at this point!
</code></pre>
<h3 id="phase-4-block-wide-broadcast-distribution-one--all-communication"><a class="header" href="#phase-4-block-wide-broadcast-distribution-one--all-communication"><strong>Phase 4: Block-wide broadcast distribution (one → all communication)</strong></a></h3>
<pre><code>block.broadcast() API execution:
  Source: src_thread = UInt(0) → Thread 0's mean_value = 4.5
  Target: All 128 threads in block

Before broadcast:
  Thread 0:   mean_value = 4.5  ← Source of truth
  Thread 1:   mean_value = 1.0  ← Will be overwritten
  Thread 2:   mean_value = 1.0  ← Will be overwritten
  ...
  Thread 127: mean_value = 1.0  ← Will be overwritten

After block.broadcast() execution:
  Thread 0:   broadcasted_mean[0] = 4.5  ← Receives own value back
  Thread 1:   broadcasted_mean[0] = 4.5  ← Now has correct value!
  Thread 2:   broadcasted_mean[0] = 4.5  ← Now has correct value!
  ...
  Thread 127: broadcasted_mean[0] = 4.5  ← Now has correct value!

Result: Perfect synchronization - all threads have identical mean value!
</code></pre>
<h3 id="phase-5-parallel-mean-normalization-coordinated-processing"><a class="header" href="#phase-5-parallel-mean-normalization-coordinated-processing"><strong>Phase 5: Parallel mean normalization (coordinated processing)</strong></a></h3>
<pre><code>Each thread independently normalizes using broadcast mean:
  Thread 0:   normalized = 1.0 / 4.5 = 0.22222222...
  Thread 1:   normalized = 2.0 / 4.5 = 0.44444444...
  Thread 2:   normalized = 3.0 / 4.5 = 0.66666666...
  Thread 7:   normalized = 8.0 / 4.5 = 1.77777777...
  Thread 8:   normalized = 1.0 / 4.5 = 0.22222222...  (pattern repeats)
  ...

Mathematical verification:
  Output sum = (0.222... + 0.444... + ... + 1.777...) × 16 = 4.5 × 16 × 2 = 128.0
  Output mean = 128.0 / 128 = 1.0  Perfect normalization!

Each value divided by original mean gives output with mean = 1.0
</code></pre>
<h3 id="phase-6-verification-of-correctness"><a class="header" href="#phase-6-verification-of-correctness"><strong>Phase 6: Verification of correctness</strong></a></h3>
<pre><code>Input analysis:
  - Sum: 576.0, Mean: 4.5
  - Max: 8.0, Min: 1.0
  - Range: [1.0, 8.0]

Output analysis:
  - Sum: 128.0, Mean: 1.0 ✓
  - Max: 1.777..., Min: 0.222...
  - Range: [0.222, 1.777] (all values scaled by factor 1/4.5)

Proportional relationships preserved:
  - Original 8:1 ratio becomes 1.777:0.222 = 8:1 ✓
  - All relative magnitudes maintained perfectly
</code></pre>
<h2 id="why-this-complete-workflow-is-mathematically-and-computationally-superior"><a class="header" href="#why-this-complete-workflow-is-mathematically-and-computationally-superior"><strong>Why this complete workflow is mathematically and computationally superior:</strong></a></h2>
<h3 id="technical-accuracy-and-verification"><a class="header" href="#technical-accuracy-and-verification"><strong>Technical accuracy and verification:</strong></a></h3>
<pre><code>Mathematical proof of correctness:
  Input: x₁, x₂, ..., xₙ where n = 128
  Mean: μ = (∑xᵢ)/n = 576/128 = 4.5

  Normalization: yᵢ = xᵢ/μ
  Output mean: (∑yᵢ)/n = (∑xᵢ/μ)/n = (1/μ)(∑xᵢ)/n = (1/μ)μ = 1 ✓

Algorithm produces provably correct mathematical result.
</code></pre>
<h3 id="connection-to-puzzle-12-foundational-patterns"><a class="header" href="#connection-to-puzzle-12-foundational-patterns"><strong>Connection to <a href="../puzzle_12/layout_tensor.html">Puzzle 12</a> (foundational patterns):</strong></a></h3>
<ul>
<li><strong>Thread coordination evolution</strong>: Same <code>global_i</code>, <code>local_i</code> patterns but with block primitives</li>
<li><strong>Memory access patterns</strong>: Same LayoutTensor SIMD extraction <code>[0]</code> but optimized workflow</li>
<li><strong>Complexity elimination</strong>: Replaces 20+ lines of manual barriers with 2 block operations</li>
<li><strong>Educational progression</strong>: Manual → automated, complex → simple, error-prone → reliable</li>
</ul>
<h3 id="connection-to-blocksum-perfect-integration"><a class="header" href="#connection-to-blocksum-perfect-integration"><strong>Connection to <a href="./block_sum.html"><code>block.sum()</code></a> (perfect integration):</strong></a></h3>
<ul>
<li><strong>API consistency</strong>: Identical template structure <code>[block_size=tpb, broadcast=False]</code></li>
<li><strong>Result flow design</strong>: Thread 0 receives sum, naturally computes derived parameter</li>
<li><strong>Seamless composition</strong>: Output of <code>block.sum()</code> becomes input for computation + broadcast</li>
<li><strong>Performance optimization</strong>: Single-kernel workflow vs multi-pass approaches</li>
</ul>
<h3 id="connection-to-blockprefix_sum-complementary-communication"><a class="header" href="#connection-to-blockprefix_sum-complementary-communication"><strong>Connection to <a href="./block_prefix_sum.html"><code>block.prefix_sum()</code></a> (complementary communication):</strong></a></h3>
<ul>
<li><strong>Distribution patterns</strong>: <code>prefix_sum</code> gives unique positions, <code>broadcast</code> gives shared values</li>
<li><strong>Usage scenarios</strong>: <code>prefix_sum</code> for parallel partitioning, <code>broadcast</code> for parameter sharing</li>
<li><strong>Template consistency</strong>: Same <code>dtype</code>, <code>block_size</code> parameter patterns across all operations</li>
<li><strong>SIMD handling uniformity</strong>: All block operations return SIMD requiring <code>[0]</code> extraction</li>
</ul>
<h3 id="advanced-algorithmic-insights"><a class="header" href="#advanced-algorithmic-insights"><strong>Advanced algorithmic insights:</strong></a></h3>
<pre><code>Communication pattern comparison:
  Traditional approach:
    1. Manual reduction:     O(log n) with explicit barriers
    2. Shared memory write:  O(1) with synchronization
    3. Shared memory read:   O(1) with potential bank conflicts
    Total: Multiple synchronization points, error-prone

  Block operations approach:
    1. block.sum():          O(log n) hardware-optimized, automatic barriers
    2. Computation:          O(1) single thread
    3. block.broadcast():    O(log n) hardware-optimized, automatic distribution
    Total: Two primitives, automatic synchronization, provably correct
</code></pre>
<h3 id="real-world-algorithm-patterns-demonstrated"><a class="header" href="#real-world-algorithm-patterns-demonstrated"><strong>Real-world algorithm patterns demonstrated:</strong></a></h3>
<pre><code>Common parallel algorithm structure:
  Phase 1: Parallel data processing      → All threads contribute
  Phase 2: Global parameter computation  → One thread computes
  Phase 3: Parameter distribution        → All threads receive
  Phase 4: Coordinated parallel output   → All threads process

This exact pattern appears in:
  - Batch normalization (deep learning)
  - Histogram equalization (image processing)
  - Iterative numerical methods (scientific computing)
  - Lighting calculations (computer graphics)

Mean normalization is the perfect educational example of this fundamental pattern.
</code></pre>
<h2 id="block-operations-trilogy-completed"><a class="header" href="#block-operations-trilogy-completed"><strong>Block operations trilogy completed:</strong></a></h2>
<h3 id="1-blocksum---all-to-one-reduction"><a class="header" href="#1-blocksum---all-to-one-reduction"><strong>1. <code>block.sum()</code> - All to One (Reduction)</strong></a></h3>
<ul>
<li><strong>Input</strong>: All threads provide values</li>
<li><strong>Output</strong>: Thread 0 receives aggregated result</li>
<li><strong>Use case</strong>: Computing totals, finding maximums, etc.</li>
</ul>
<h3 id="2-blockprefix_sum---all-to-each-scan"><a class="header" href="#2-blockprefix_sum---all-to-each-scan"><strong>2. <code>block.prefix_sum()</code> - All to Each (Scan)</strong></a></h3>
<ul>
<li><strong>Input</strong>: All threads provide values</li>
<li><strong>Output</strong>: Each thread receives cumulative position</li>
<li><strong>Use case</strong>: Computing write positions, parallel partitioning</li>
</ul>
<h3 id="3-blockbroadcast---one-to-all-broadcast"><a class="header" href="#3-blockbroadcast---one-to-all-broadcast"><strong>3. <code>block.broadcast()</code> - One to All (Broadcast)</strong></a></h3>
<ul>
<li><strong>Input</strong>: One thread provides value (typically thread 0)</li>
<li><strong>Output</strong>: All threads receive the same value</li>
<li><strong>Use case</strong>: Sharing computed parameters, configuration values</li>
</ul>
</div>
</details>
<p><strong>Complete block operations progression:</strong></p>
<ol>
<li><strong>Manual coordination</strong> (<a href="../puzzle_12/layout_tensor.html">Puzzle 12</a>): Understand parallel fundamentals</li>
<li><strong>Warp primitives</strong> (<a href="../puzzle_24/warp_sum.html">Puzzle 24</a>): Learn hardware-accelerated patterns</li>
<li><strong>Block reduction</strong> (<a href="./block_sum.html"><code>block.sum()</code></a>): Learn all→one communication</li>
<li><strong>Block scan</strong> (<a href="./block_prefix_sum.html"><code>block.prefix_sum()</code></a>): Learn all→each communication</li>
<li><strong>Block broadcast</strong> (<code>block.broadcast()</code>): Learn one→all communication</li>
</ol>
<p><strong>The complete picture:</strong> Block operations provide the fundamental communication building blocks for sophisticated parallel algorithms, replacing complex manual coordination with clean, composable primitives.</p>
<h2 id="performance-insights-and-technical-analysis"><a class="header" href="#performance-insights-and-technical-analysis">Performance insights and technical analysis</a></h2>
<h3 id="quantitative-performance-comparison"><a class="header" href="#quantitative-performance-comparison"><strong>Quantitative performance comparison:</strong></a></h3>
<p><strong><code>block.broadcast()</code> vs Traditional shared memory approach (for demonstration):</strong></p>
<p><strong>Traditional Manual Approach:</strong></p>
<pre><code>Phase 1: Manual reduction
  • Shared memory allocation: ~5 cycles
  • Barrier synchronization: ~10 cycles
  • Tree reduction loop: ~15 cycles
  • Error-prone manual indexing

Phase 2: Mean computation: ~2 cycles

Phase 3: Shared memory broadcast
  • Manual write to shared: ~2 cycles
  • Barrier synchronization: ~10 cycles
  • All threads read: ~3 cycles

Total: ~47 cycles
  + synchronization overhead
  + potential race conditions
  + manual error debugging
</code></pre>
<p><strong>Block Operations Approach:</strong></p>
<pre><code>Phase 1: block.sum()
  • Hardware-optimized: ~3 cycles
  • Automatic barriers: 0 explicit cost
  • Optimized reduction: ~8 cycles
  • Verified correct implementation

Phase 2: Mean computation: ~2 cycles

Phase 3: block.broadcast()
  • Hardware-optimized: ~4 cycles
  • Automatic distribution: 0 explicit cost
  • Verified correct implementation

Total: ~17 cycles
  + automatic optimization
  + guaranteed correctness
  + composable design
</code></pre>
<h3 id="memory-hierarchy-advantages"><a class="header" href="#memory-hierarchy-advantages"><strong>Memory hierarchy advantages:</strong></a></h3>
<p><strong>Cache efficiency:</strong></p>
<ul>
<li><strong>block.sum()</strong>: Optimized memory access patterns reduce cache misses</li>
<li><strong>block.broadcast()</strong>: Efficient distribution minimizes memory bandwidth usage</li>
<li><strong>Combined workflow</strong>: Single kernel reduces global memory round-trips by 100%</li>
</ul>
<p><strong>Memory bandwidth utilization:</strong></p>
<pre><code>Traditional multi-kernel approach:
  Kernel 1: Input → Reduction → Global memory write
  Kernel 2: Global memory read → Broadcast → Output
  Total global memory transfers: 3× array size

Block operations single-kernel:
  Input → block.sum() → block.broadcast() → Output
  Total global memory transfers: 2× array size (33% improvement)
</code></pre>
<h3 id="when-to-use-each-block-operation"><a class="header" href="#when-to-use-each-block-operation"><strong>When to use each block operation:</strong></a></h3>
<p><strong><code>block.sum()</code> optimal scenarios:</strong></p>
<ul>
<li><strong>Data aggregation</strong>: Computing totals, averages, maximum/minimum values</li>
<li><strong>Reduction patterns</strong>: Any all-to-one communication requirement</li>
<li><strong>Statistical computation</strong>: Mean, variance, correlation calculations</li>
</ul>
<p><strong><code>block.prefix_sum()</code> optimal scenarios:</strong></p>
<ul>
<li><strong>Parallel partitioning</strong>: Stream compaction, histogram binning</li>
<li><strong>Write position calculation</strong>: Parallel output generation</li>
<li><strong>Parallel algorithms</strong>: Sorting, searching, data reorganization</li>
</ul>
<p><strong><code>block.broadcast()</code> optimal scenarios:</strong></p>
<ul>
<li><strong>Parameter distribution</strong>: Sharing computed values to all threads</li>
<li><strong>Configuration propagation</strong>: Mode flags, scaling factors, thresholds</li>
<li><strong>Coordinated processing</strong>: When all threads need the same computed parameter</li>
</ul>
<h3 id="composition-benefits"><a class="header" href="#composition-benefits"><strong>Composition benefits:</strong></a></h3>
<pre><code>Individual operations: Good performance, limited scope
Combined operations:   Excellent performance, comprehensive algorithms

Example combinations seen in real applications:
• block.sum() + block.broadcast():       Normalization algorithms
• block.prefix_sum() + block.sum():      Advanced partitioning
• All three together:                    Complex parallel algorithms
• With traditional patterns:             Hybrid optimization strategies
</code></pre>
<h2 id="next-steps"><a class="header" href="#next-steps">Next steps</a></h2>
<p>Once you’ve learned about the complete block operations trilogy, you’re ready for:</p>
<ul>
<li><strong>Multi-block algorithms</strong>: Coordinating operations across multiple thread blocks</li>
<li><strong>Advanced parallel patterns</strong>: Combining block operations for complex algorithms</li>
<li><strong>Memory hierarchy optimization</strong>: Efficient data movement patterns</li>
<li><strong>Algorithm design</strong>: Structuring parallel algorithms using block operation building blocks</li>
<li><strong>Performance optimization</strong>: Choosing optimal block sizes and operation combinations</li>
</ul>
<p>💡 <strong>Key Takeaway</strong>: The block operations trilogy (<code>sum</code>, <code>prefix_sum</code>, <code>broadcast</code>) provides complete communication primitives for block-level parallel programming. By composing these operations, you can implement sophisticated parallel algorithms with clean, maintainable code that leverages GPU hardware optimizations. Mean normalization demonstrates how these operations work together to solve real computational problems efficiently.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../puzzle_27/block_prefix_sum.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../puzzle_28/puzzle_28.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../puzzle_27/block_prefix_sum.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../puzzle_28/puzzle_28.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../theme/mojolang.js"></script>
        <script src="../theme/sidebar.js"></script>
        <script src="../theme/solution.js"></script>
        <script src="../theme/init-amplitude.js"></script>
        <script src="../theme/tabs.js"></script>


    </div>
    </body>
</html>
